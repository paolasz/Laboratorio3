{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ef974c8e",
   "metadata": {},
   "source": [
    "Combinacion de resultados - Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "548a088b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Librerías importadas correctamente\n"
     ]
    }
   ],
   "source": [
    "# Importar librerías necesarias\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "print(\"Librerías importadas correctamente\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "48bc80df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cargando archivos de predicciones...\n",
      "AutoGluon - Shape: (780, 2)\n",
      "AutoGluon - Primeras filas:\n",
      "   product_id           tn\n",
      "0       20001  1322.782727\n",
      "1       20002  1076.158858\n",
      "2       20003   696.172870\n",
      "3       20004   519.217793\n",
      "4       20005   501.010270\n",
      "\n",
      "==================================================\n",
      "\n",
      "Regresión Lineal - Shape: (780, 2)\n",
      "Regresión Lineal - Primeras filas:\n",
      "   product_id           tn\n",
      "0       20001  1162.707525\n",
      "1       20002  1183.640604\n",
      "2       20003   684.763931\n",
      "3       20004   580.484961\n",
      "4       20005   563.560780\n"
     ]
    }
   ],
   "source": [
    "# Cargar los archivos de predicciones\n",
    "print(\"Cargando archivos de predicciones...\")\n",
    "\n",
    "# Cargar predicciones de AutoGluon\n",
    "pred_autogluon = pd.read_csv('data/pred_autogluon_01.csv')\n",
    "print(f\"AutoGluon - Shape: {pred_autogluon.shape}\")\n",
    "print(\"AutoGluon - Primeras filas:\")\n",
    "print(pred_autogluon.head())\n",
    "\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "\n",
    "# Cargar predicciones de Regresión Lineal\n",
    "pred_regresion = pd.read_csv('data/pred_regresion_lineal01.csv')\n",
    "print(f\"Regresión Lineal - Shape: {pred_regresion.shape}\")\n",
    "print(\"Regresión Lineal - Primeras filas:\")\n",
    "print(pred_regresion.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "07533161",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Verificando consistencia de datos...\n",
      "Productos únicos en AutoGluon: 780\n",
      "Productos únicos en Regresión Lineal: 780\n",
      "✅ Ambos archivos tienen exactamente los mismos productos\n",
      "\n",
      "Productos en común: 780\n"
     ]
    }
   ],
   "source": [
    "# Verificar que ambos archivos tienen los mismos productos\n",
    "print(\"Verificando consistencia de datos...\")\n",
    "print(f\"Productos únicos en AutoGluon: {pred_autogluon['product_id'].nunique()}\")\n",
    "print(f\"Productos únicos en Regresión Lineal: {pred_regresion['product_id'].nunique()}\")\n",
    "\n",
    "# Verificar si tienen exactamente los mismos product_ids\n",
    "productos_autogluon = set(pred_autogluon['product_id'])\n",
    "productos_regresion = set(pred_regresion['product_id'])\n",
    "\n",
    "if productos_autogluon == productos_regresion:\n",
    "    print(\"✅ Ambos archivos tienen exactamente los mismos productos\")\n",
    "else:\n",
    "    print(\"⚠️ Los archivos NO tienen los mismos productos\")\n",
    "    en_autogluon_no_en_regresion = productos_autogluon - productos_regresion\n",
    "    en_regresion_no_en_autogluon = productos_regresion - productos_autogluon\n",
    "    \n",
    "    if en_autogluon_no_en_regresion:\n",
    "        print(f\"Productos en AutoGluon pero no en Regresión: {len(en_autogluon_no_en_regresion)}\")\n",
    "    if en_regresion_no_en_autogluon:\n",
    "        print(f\"Productos en Regresión pero no en AutoGluon: {len(en_regresion_no_en_autogluon)}\")\n",
    "\n",
    "print(f\"\\nProductos en común: {len(productos_autogluon & productos_regresion)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a3fe8171",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creando ensemble ponderado (40% AutoGluon + 60% Regresión)...\n",
      "Datos después del merge: (780, 3)\n",
      "\n",
      "Primeras filas del merge:\n",
      "   product_id  tn_autogluon  tn_regresion\n",
      "0       20001   1322.782727   1162.707525\n",
      "1       20002   1076.158858   1183.640604\n",
      "2       20003    696.172870    684.763931\n",
      "3       20004    519.217793    580.484961\n",
      "4       20005    501.010270    563.560780\n",
      "\n",
      "Estadísticas del ensemble ponderado (25% AutoGluon + 75% Regresión):\n",
      "Promedio de tn: 35.82\n",
      "Mediana de tn: 9.19\n",
      "Std de tn: 92.48\n",
      "\n",
      "Comparación de predicciones para los primeros 5 productos:\n",
      "(AutoGluon: 25%, Regresión: 75%)\n",
      "   product_id  tn_autogluon  tn_regresion           tn\n",
      "0       20001   1322.782727   1162.707525  1202.726326\n",
      "1       20002   1076.158858   1183.640604  1156.770168\n",
      "2       20003    696.172870    684.763931   687.616165\n",
      "3       20004    519.217793    580.484961   565.168169\n",
      "4       20005    501.010270    563.560780   547.923153\n"
     ]
    }
   ],
   "source": [
    "# Crear ensemble con ponderación específica\n",
    "print(\"Creando ensemble ponderado (40% AutoGluon + 60% Regresión)...\")\n",
    "\n",
    "# Renombrar las columnas tn para distinguir los modelos\n",
    "pred_autogluon_renamed = pred_autogluon.rename(columns={'tn': 'tn_autogluon'})\n",
    "pred_regresion_renamed = pred_regresion.rename(columns={'tn': 'tn_regresion'})\n",
    "\n",
    "# Hacer merge por product_id\n",
    "ensemble_data = pd.merge(\n",
    "    pred_autogluon_renamed, \n",
    "    pred_regresion_renamed, \n",
    "    on='product_id', \n",
    "    how='inner'\n",
    ")\n",
    "\n",
    "print(f\"Datos después del merge: {ensemble_data.shape}\")\n",
    "print(\"\\nPrimeras filas del merge:\")\n",
    "print(ensemble_data.head())\n",
    "\n",
    "# Calcular el promedio ponderado de las predicciones\n",
    "# 25% AutoGluon + 75% Regresión Lineal\n",
    "peso_autogluon = 0.25\n",
    "peso_regresion = 0.75\n",
    "\n",
    "ensemble_data['tn'] = (ensemble_data['tn_autogluon'] * peso_autogluon + \n",
    "                       ensemble_data['tn_regresion'] * peso_regresion)\n",
    "\n",
    "print(f\"\\nEstadísticas del ensemble ponderado (25% AutoGluon + 75% Regresión):\")\n",
    "print(f\"Promedio de tn: {ensemble_data['tn'].mean():.2f}\")\n",
    "print(f\"Mediana de tn: {ensemble_data['tn'].median():.2f}\")\n",
    "print(f\"Std de tn: {ensemble_data['tn'].std():.2f}\")\n",
    "\n",
    "# Mostrar comparación de los primeros productos\n",
    "print(f\"\\nComparación de predicciones para los primeros 5 productos:\")\n",
    "print(f\"(AutoGluon: {peso_autogluon*100:.0f}%, Regresión: {peso_regresion*100:.0f}%)\")\n",
    "comparison = ensemble_data[['product_id', 'tn_autogluon', 'tn_regresion', 'tn']].head()\n",
    "print(comparison)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d7a6345a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparando datos finales para guardar...\n",
      "Valores nulos en el resultado final: 0\n",
      "Shape del resultado final: (780, 2)\n",
      "\n",
      "Primeras 10 filas del resultado final:\n",
      "   product_id           tn\n",
      "0       20001  1202.726326\n",
      "1       20002  1156.770168\n",
      "2       20003   687.616165\n",
      "3       20004   565.168169\n",
      "4       20005   547.923153\n",
      "5       20006   475.010816\n",
      "6       20007   392.568311\n",
      "7       20008   414.211320\n",
      "8       20009   460.561362\n",
      "9       20010   409.796967\n",
      "\n",
      "Últimas 5 filas del resultado final:\n",
      "     product_id        tn\n",
      "775       20962  3.479425\n",
      "776       20975  3.196880\n",
      "777       20995  3.052063\n",
      "778       21087  1.231390\n",
      "779       21214  0.745201\n"
     ]
    }
   ],
   "source": [
    "# Crear el archivo final con solo product_id y tn promediado\n",
    "print(\"Preparando datos finales para guardar...\")\n",
    "\n",
    "# Seleccionar solo las columnas necesarias para el archivo final\n",
    "resultado_final = ensemble_data[['product_id', 'tn']].copy()\n",
    "\n",
    "# Verificar que no hay valores nulos\n",
    "print(f\"Valores nulos en el resultado final: {resultado_final.isnull().sum().sum()}\")\n",
    "print(f\"Shape del resultado final: {resultado_final.shape}\")\n",
    "\n",
    "print(\"\\nPrimeras 10 filas del resultado final:\")\n",
    "print(resultado_final.head(10))\n",
    "\n",
    "print(f\"\\nÚltimas 5 filas del resultado final:\")\n",
    "print(resultado_final.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "463b7774",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Guardando resultado en: data/pred_autogluon_rl_03.csv\n",
      "✅ Archivo guardado exitosamente: data/pred_autogluon_rl_03.csv\n",
      "Total de productos en el ensemble: 780\n",
      "Tamaño del archivo: 19910 bytes\n",
      "\n",
      "Verificación - Primeras 3 líneas del archivo guardado:\n",
      "   product_id           tn\n",
      "0       20001  1202.726326\n",
      "1       20002  1156.770168\n",
      "2       20003   687.616165\n"
     ]
    }
   ],
   "source": [
    "# Guardar el archivo final\n",
    "archivo_salida = \"data/pred_autogluon_rl_03.csv\"\n",
    "\n",
    "print(f\"Guardando resultado en: {archivo_salida}\")\n",
    "\n",
    "# Guardar el archivo\n",
    "resultado_final.to_csv(archivo_salida, index=False)\n",
    "\n",
    "print(f\"✅ Archivo guardado exitosamente: {archivo_salida}\")\n",
    "print(f\"Total de productos en el ensemble: {len(resultado_final)}\")\n",
    "\n",
    "# Verificar que el archivo se guardó correctamente\n",
    "import os\n",
    "if os.path.exists(archivo_salida):\n",
    "    tamaño_archivo = os.path.getsize(archivo_salida)\n",
    "    print(f\"Tamaño del archivo: {tamaño_archivo} bytes\")\n",
    "    \n",
    "    # Leer las primeras líneas del archivo guardado para verificar\n",
    "    verificacion = pd.read_csv(archivo_salida, nrows=3)\n",
    "    print(f\"\\nVerificación - Primeras 3 líneas del archivo guardado:\")\n",
    "    print(verificacion)\n",
    "else:\n",
    "    print(\"⚠️ Error: No se pudo crear el archivo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8f046dd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RESUMEN DEL ENSEMBLE\n",
      "==================================================\n",
      "Estadísticas de AutoGluon:\n",
      "  Promedio: 36.25\n",
      "  Mediana:  9.06\n",
      "  Std:      93.69\n",
      "\n",
      "Estadísticas de Regresión Lineal:\n",
      "  Promedio: 35.67\n",
      "  Mediana:  9.04\n",
      "  Std:      92.24\n",
      "\n",
      "Estadísticas del Ensemble Ponderado (40% AutoGluon + 60% Regresión):\n",
      "  Promedio: 35.82\n",
      "  Mediana:  9.19\n",
      "  Std:      92.48\n",
      "\n",
      "Correlación entre modelos: 0.9931\n",
      "\n",
      "Pesos aplicados:\n",
      "  AutoGluon: 25%\n",
      "  Regresión Lineal: 75%\n",
      "\n",
      "✅ Ensemble ponderado completado exitosamente!\n",
      "Archivo final: pred_autogluon_rl_03.csv\n",
      "Total de productos: 780\n"
     ]
    }
   ],
   "source": [
    "# Análisis final del ensemble\n",
    "print(\"RESUMEN DEL ENSEMBLE\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Estadísticas descriptivas de cada modelo\n",
    "print(\"Estadísticas de AutoGluon:\")\n",
    "print(f\"  Promedio: {ensemble_data['tn_autogluon'].mean():.2f}\")\n",
    "print(f\"  Mediana:  {ensemble_data['tn_autogluon'].median():.2f}\")\n",
    "print(f\"  Std:      {ensemble_data['tn_autogluon'].std():.2f}\")\n",
    "\n",
    "print(\"\\nEstadísticas de Regresión Lineal:\")\n",
    "print(f\"  Promedio: {ensemble_data['tn_regresion'].mean():.2f}\")\n",
    "print(f\"  Mediana:  {ensemble_data['tn_regresion'].median():.2f}\")\n",
    "print(f\"  Std:      {ensemble_data['tn_regresion'].std():.2f}\")\n",
    "\n",
    "print(\"\\nEstadísticas del Ensemble Ponderado (40% AutoGluon + 60% Regresión):\")\n",
    "print(f\"  Promedio: {ensemble_data['tn'].mean():.2f}\")\n",
    "print(f\"  Mediana:  {ensemble_data['tn'].median():.2f}\")\n",
    "print(f\"  Std:      {ensemble_data['tn'].std():.2f}\")\n",
    "\n",
    "# Correlación entre modelos\n",
    "correlacion = ensemble_data['tn_autogluon'].corr(ensemble_data['tn_regresion'])\n",
    "print(f\"\\nCorrelación entre modelos: {correlacion:.4f}\")\n",
    "\n",
    "# Mostrar pesos utilizados\n",
    "print(f\"\\nPesos aplicados:\")\n",
    "print(f\"  AutoGluon: {peso_autogluon*100:.0f}%\")\n",
    "print(f\"  Regresión Lineal: {peso_regresion*100:.0f}%\")\n",
    "\n",
    "print(f\"\\n✅ Ensemble ponderado completado exitosamente!\")\n",
    "print(f\"Archivo final: pred_autogluon_rl_03.csv\")\n",
    "print(f\"Total de productos: {len(resultado_final)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ldi2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
