{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6ae32ff4",
   "metadata": {},
   "source": [
    "Varios LGBM y regresion lineal y media 093 - ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "756f7819",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Librerías importadas correctamente\n",
      "Ensemble de 6 modelos: LGBM + Regresión Lineal + Media 12 093 + Autogluon\n"
     ]
    }
   ],
   "source": [
    "# Importar librerías necesarias\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "print(\"Librerías importadas correctamente\")\n",
    "print(\"Ensemble de 6 modelos: LGBM + Regresión Lineal + Media 12 093 + Autogluon\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7dbf4b43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cargando archivos de predicciones...\n",
      "LGBM - Shape: (780, 2)\n",
      "LGBM - Primeras filas:\n",
      "   product_id           tn\n",
      "0       20001  1282.319435\n",
      "1       20002  1009.995347\n",
      "2       20003   667.117963\n",
      "\n",
      "==================================================\n",
      "\n",
      "LGBM2 - Shape: (780, 2)\n",
      "LGBM2 - Primeras filas:\n",
      "   product_id           tn\n",
      "0       20001  1300.846482\n",
      "1       20002  1007.214398\n",
      "2       20003   679.601498\n",
      "\n",
      "==================================================\n",
      "\n",
      "LGBM3 - Shape: (780, 2)\n",
      "LGBM3 - Primeras filas:\n",
      "   product_id           tn\n",
      "0       20001  1352.622594\n",
      "1       20002  1179.363975\n",
      "2       20003   696.798612\n",
      "\n",
      "==================================================\n",
      "\n",
      "Regresión Lineal - Shape: (780, 2)\n",
      "Regresión Lineal - Primeras filas:\n",
      "   product_id           tn\n",
      "0       20001  1162.707525\n",
      "1       20002  1183.640604\n",
      "2       20003   684.763931\n",
      "\n",
      "==================================================\n",
      "\n",
      "Media 12 093 - Shape: (780, 2)\n",
      "Media 12 093 - Primeras filas:\n",
      "   product_id           tn\n",
      "0       20001  1352.901430\n",
      "1       20002  1093.156542\n",
      "2       20003   730.028059\n",
      "\n",
      "==================================================\n",
      "\n",
      "Autogluon - Shape: (780, 2)\n",
      "Autogluon - Primeras filas:\n",
      "   product_id           tn\n",
      "0       20001  1322.782727\n",
      "1       20002  1076.158858\n",
      "2       20003   696.172870\n",
      "\n",
      "Resumen de shapes de todos los archivos cargados:\n",
      "LGBM: (780, 2)\n",
      "LGBM2: (780, 2)\n",
      "LGBM3: (780, 2)\n",
      "Regresión Lineal: (780, 2)\n",
      "Media 12 093: (780, 2)\n",
      "Autogluon: (780, 2)\n"
     ]
    }
   ],
   "source": [
    "# Cargar los seis archivos de predicciones\n",
    "print(\"Cargando archivos de predicciones...\")\n",
    "\n",
    "# Cargar predicciones de LGBM (sem_1_promedio)\n",
    "pred_lgbm = pd.read_csv('data/pred_lgbm_v3_FE_02_v3_linear_tree_opt_03_36lags_producto_sem_1_promedio.csv')\n",
    "print(f\"LGBM - Shape: {pred_lgbm.shape}\")\n",
    "print(\"LGBM - Primeras filas:\")\n",
    "print(pred_lgbm.head(3))\n",
    "\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "\n",
    "# Cargar predicciones de LGBM2 (producto)\n",
    "pred_lgbm2 = pd.read_csv('data/pred_lgbm_v3_FE_02_v3_linear_tree_opt_03_36lags_producto.csv')\n",
    "print(f\"LGBM2 - Shape: {pred_lgbm2.shape}\")\n",
    "print(\"LGBM2 - Primeras filas:\")\n",
    "print(pred_lgbm2.head(3))\n",
    "\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "\n",
    "# Cargar predicciones de LGBM3\n",
    "pred_lgbm3 = pd.read_csv('data/pred_lgbm_v3_FE_03_linear_tree_opt_03_36lags_producto.csv')\n",
    "print(f\"LGBM3 - Shape: {pred_lgbm3.shape}\")\n",
    "print(\"LGBM3 - Primeras filas:\")\n",
    "print(pred_lgbm3.head(3))\n",
    "\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "\n",
    "# Cargar predicciones de Regresión Lineal\n",
    "pred_regresion = pd.read_csv('data/pred_regresion_lineal01.csv')\n",
    "print(f\"Regresión Lineal - Shape: {pred_regresion.shape}\")\n",
    "print(\"Regresión Lineal - Primeras filas:\")\n",
    "print(pred_regresion.head(3))\n",
    "\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "\n",
    "# Cargar predicciones de Media 12 093\n",
    "pred_media = pd.read_csv('data/pred_medias_12_093.csv')\n",
    "print(f\"Media 12 093 - Shape: {pred_media.shape}\")\n",
    "print(\"Media 12 093 - Primeras filas:\")\n",
    "print(pred_media.head(3))\n",
    "\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "\n",
    "# Cargar predicciones de Autogluon\n",
    "pred_autogluon = pd.read_csv('data/pred_autogluon_01.csv')\n",
    "print(f\"Autogluon - Shape: {pred_autogluon.shape}\")\n",
    "print(\"Autogluon - Primeras filas:\")\n",
    "print(pred_autogluon.head(3))\n",
    "\n",
    "# Resumen de shapes de todos los archivos cargados\n",
    "print(\"\\nResumen de shapes de todos los archivos cargados:\")\n",
    "print(f\"LGBM: {pred_lgbm.shape}\")\n",
    "print(f\"LGBM2: {pred_lgbm2.shape}\")\n",
    "print(f\"LGBM3: {pred_lgbm3.shape}\")\n",
    "print(f\"Regresión Lineal: {pred_regresion.shape}\")\n",
    "print(f\"Media 12 093: {pred_media.shape}\")\n",
    "print(f\"Autogluon: {pred_autogluon.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "54da73f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cargando archivos de predicciones...\n",
      "LGBM - Shape: (780, 2)\n",
      "LGBM - Primeras filas:\n",
      "   product_id           tn\n",
      "0       20001  1282.319435\n",
      "1       20002  1009.995347\n",
      "2       20003   667.117963\n",
      "\n",
      "==================================================\n",
      "\n",
      "LGBM2 - Shape: (780, 2)\n",
      "LGBM2 - Primeras filas:\n",
      "   product_id           tn\n",
      "0       20001  1300.846482\n",
      "1       20002  1007.214398\n",
      "2       20003   679.601498\n",
      "\n",
      "==================================================\n",
      "\n",
      "LGBM3 - Shape: (780, 2)\n",
      "LGBM3 - Primeras filas:\n",
      "   product_id           tn\n",
      "0       20001  1352.622594\n",
      "1       20002  1179.363975\n",
      "2       20003   696.798612\n",
      "\n",
      "==================================================\n",
      "\n",
      "Regresión Lineal - Shape: (780, 2)\n",
      "Regresión Lineal - Primeras filas:\n",
      "   product_id           tn\n",
      "0       20001  1162.707525\n",
      "1       20002  1183.640604\n",
      "2       20003   684.763931\n",
      "\n",
      "==================================================\n",
      "\n",
      "Media 12 093 - Shape: (780, 2)\n",
      "Media 12 093 - Primeras filas:\n",
      "   product_id           tn\n",
      "0       20001  1352.901430\n",
      "1       20002  1093.156542\n",
      "2       20003   730.028059\n",
      "\n",
      "Resumen de shapes de todos los archivos cargados:\n",
      "LGBM: (780, 2)\n",
      "LGBM2: (780, 2)\n",
      "LGBM3: (780, 2)\n",
      "Regresión Lineal: (780, 2)\n",
      "Media 12 093: (780, 2)\n"
     ]
    }
   ],
   "source": [
    "# Cargar los cinco archivos de predicciones\n",
    "print(\"Cargando archivos de predicciones...\")\n",
    "\n",
    "# Cargar predicciones de LGBM (sem_1_promedio)\n",
    "pred_lgbm = pd.read_csv('data/pred_lgbm_v3_FE_02_v3_linear_tree_opt_03_36lags_producto_sem_1_promedio.csv')\n",
    "print(f\"LGBM - Shape: {pred_lgbm.shape}\")\n",
    "print(\"LGBM - Primeras filas:\")\n",
    "print(pred_lgbm.head(3))\n",
    "\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "\n",
    "# Cargar predicciones de LGBM2 (producto)\n",
    "pred_lgbm2 = pd.read_csv('data/pred_lgbm_v3_FE_02_v3_linear_tree_opt_03_36lags_producto.csv')\n",
    "print(f\"LGBM2 - Shape: {pred_lgbm2.shape}\")\n",
    "print(\"LGBM2 - Primeras filas:\")\n",
    "print(pred_lgbm2.head(3))\n",
    "\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "\n",
    "# Cargar predicciones de LGBM3\n",
    "pred_lgbm3 = pd.read_csv('data/pred_lgbm_v3_FE_03_linear_tree_opt_03_36lags_producto.csv')\n",
    "print(f\"LGBM3 - Shape: {pred_lgbm3.shape}\")\n",
    "print(\"LGBM3 - Primeras filas:\")\n",
    "print(pred_lgbm3.head(3))\n",
    "\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "\n",
    "# Cargar predicciones de Regresión Lineal\n",
    "pred_regresion = pd.read_csv('data/pred_regresion_lineal01.csv')\n",
    "print(f\"Regresión Lineal - Shape: {pred_regresion.shape}\")\n",
    "print(\"Regresión Lineal - Primeras filas:\")\n",
    "print(pred_regresion.head(3))\n",
    "\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "\n",
    "# Cargar predicciones de Media 12 093\n",
    "pred_media = pd.read_csv('data/pred_medias_12_093.csv')\n",
    "print(f\"Media 12 093 - Shape: {pred_media.shape}\")\n",
    "print(\"Media 12 093 - Primeras filas:\")\n",
    "print(pred_media.head(3))\n",
    "\n",
    "# Resumen de shapes de todos los archivos cargados\n",
    "print(\"\\nResumen de shapes de todos los archivos cargados:\")\n",
    "print(f\"LGBM: {pred_lgbm.shape}\")\n",
    "print(f\"LGBM2: {pred_lgbm2.shape}\")\n",
    "print(f\"LGBM3: {pred_lgbm3.shape}\")\n",
    "print(f\"Regresión Lineal: {pred_regresion.shape}\")\n",
    "print(f\"Media 12 093: {pred_media.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f9f62889",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Verificando consistencia de datos...\n",
      "Productos únicos en LGBM: 780\n",
      "Productos únicos en Regresión Lineal: 780\n",
      "Productos únicos en Media 12 093: 780\n",
      "\n",
      "Productos en común entre los 3 modelos: 780\n",
      "✅ Los tres archivos tienen exactamente los mismos productos\n",
      "\n",
      "Usaremos los 780 productos comunes para el ensemble\n"
     ]
    }
   ],
   "source": [
    "# Verificar que los tres archivos tienen los mismos productos\n",
    "print(\"Verificando consistencia de datos...\")\n",
    "print(f\"Productos únicos en LGBM: {pred_lgbm['product_id'].nunique()}\")\n",
    "print(f\"Productos únicos en Regresión Lineal: {pred_regresion['product_id'].nunique()}\")\n",
    "print(f\"Productos únicos en Media 12 093: {pred_media['product_id'].nunique()}\")\n",
    "\n",
    "# Verificar si tienen exactamente los mismos product_ids\n",
    "productos_lgbm = set(pred_lgbm['product_id'])\n",
    "productos_regresion = set(pred_regresion['product_id'])\n",
    "productos_media = set(pred_media['product_id'])\n",
    "\n",
    "# Verificar intersecciones\n",
    "productos_comunes = productos_lgbm & productos_regresion & productos_media\n",
    "print(f\"\\nProductos en común entre los 3 modelos: {len(productos_comunes)}\")\n",
    "\n",
    "if len(productos_comunes) == len(productos_lgbm) == len(productos_regresion) == len(productos_media):\n",
    "    print(\"✅ Los tres archivos tienen exactamente los mismos productos\")\n",
    "else:\n",
    "    print(\"⚠️ Los archivos NO tienen exactamente los mismos productos\")\n",
    "    \n",
    "    # Verificar diferencias\n",
    "    solo_lgbm = productos_lgbm - productos_regresion - productos_media\n",
    "    solo_regresion = productos_regresion - productos_lgbm - productos_media\n",
    "    solo_media = productos_media - productos_lgbm - productos_regresion\n",
    "    \n",
    "    if solo_lgbm:\n",
    "        print(f\"Solo en LGBM: {len(solo_lgbm)} productos\")\n",
    "    if solo_regresion:\n",
    "        print(f\"Solo en Regresión: {len(solo_regresion)} productos\")\n",
    "    if solo_media:\n",
    "        print(f\"Solo en Media: {len(solo_media)} productos\")\n",
    "\n",
    "print(f\"\\nUsaremos los {len(productos_comunes)} productos comunes para el ensemble\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "246e8c41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creando ensemble de 6 modelos...\n",
      "Haciendo merge de los seis modelos...\n",
      "Datos después del merge: (780, 7)\n",
      "\n",
      "Primeras filas del merge:\n",
      "   product_id      tn_lgbm     tn_lgbm2     tn_lgbm3  tn_regresion  \\\n",
      "0       20001  1282.319435  1300.846482  1352.622594   1162.707525   \n",
      "1       20002  1009.995347  1007.214398  1179.363975   1183.640604   \n",
      "2       20003   667.117963   679.601498   696.798612    684.763931   \n",
      "3       20004   528.675142   557.937422   539.329044    580.484961   \n",
      "4       20005   558.755442   556.942803   564.775686    563.560780   \n",
      "\n",
      "      tn_media  tn_autogluon  \n",
      "0  1352.901430   1322.782727  \n",
      "1  1093.156542   1076.158858  \n",
      "2   730.028059    696.172870  \n",
      "3   583.310255    519.217793  \n",
      "4   621.491197    501.010270  \n",
      "\n",
      "Estadísticas del ensemble:\n",
      "Promedio de tn: 35.45\n",
      "Mediana de tn: 8.95\n",
      "Std de tn: 91.19\n",
      "\n",
      "Comparación de predicciones para los primeros 5 productos:\n",
      "   product_id      tn_lgbm     tn_lgbm2     tn_lgbm3  tn_regresion  \\\n",
      "0       20001  1282.319435  1300.846482  1352.622594   1162.707525   \n",
      "1       20002  1009.995347  1007.214398  1179.363975   1183.640604   \n",
      "2       20003   667.117963   679.601498   696.798612    684.763931   \n",
      "3       20004   528.675142   557.937422   539.329044    580.484961   \n",
      "4       20005   558.755442   556.942803   564.775686    563.560780   \n",
      "\n",
      "      tn_media  tn_autogluon           tn  \n",
      "0  1352.901430   1322.782727  1295.696699  \n",
      "1  1093.156542   1076.158858  1091.588287  \n",
      "2   730.028059    696.172870   692.413822  \n",
      "3   583.310255    519.217793   551.492436  \n",
      "4   621.491197    501.010270   561.089363  \n"
     ]
    }
   ],
   "source": [
    "# Crear ensemble promediando las seis predicciones\n",
    "print(\"Creando ensemble de 6 modelos...\")\n",
    "\n",
    "# Renombrar las columnas tn para distinguir los modelos\n",
    "pred_lgbm_renamed = pred_lgbm.rename(columns={'tn': 'tn_lgbm'})\n",
    "pred_lgbm2_renamed = pred_lgbm2.rename(columns={'tn': 'tn_lgbm2'})\n",
    "pred_lgbm3_renamed = pred_lgbm3.rename(columns={'tn': 'tn_lgbm3'})\n",
    "pred_regresion_renamed = pred_regresion.rename(columns={'tn': 'tn_regresion'})\n",
    "pred_media_renamed = pred_media.rename(columns={'tn': 'tn_media'})\n",
    "pred_autogluon_renamed = pred_autogluon.rename(columns={'tn': 'tn_autogluon'})\n",
    "\n",
    "# Hacer merge de los seis dataframes por product_id\n",
    "print(\"Haciendo merge de los seis modelos...\")\n",
    "ensemble_step1 = pd.merge(pred_lgbm_renamed, pred_lgbm2_renamed, on='product_id', how='inner')\n",
    "ensemble_step2 = pd.merge(ensemble_step1, pred_lgbm3_renamed, on='product_id', how='inner')\n",
    "ensemble_step3 = pd.merge(ensemble_step2, pred_regresion_renamed, on='product_id', how='inner')\n",
    "ensemble_step4 = pd.merge(ensemble_step3, pred_media_renamed, on='product_id', how='inner')\n",
    "ensemble_data = pd.merge(ensemble_step4, pred_autogluon_renamed, on='product_id', how='inner')\n",
    "\n",
    "print(f\"Datos después del merge: {ensemble_data.shape}\")\n",
    "print(\"\\nPrimeras filas del merge:\")\n",
    "print(ensemble_data.head())\n",
    "\n",
    "# Calcular el promedio de las seis predicciones\n",
    "ensemble_data['tn'] = (ensemble_data['tn_lgbm'] + ensemble_data['tn_lgbm2'] + ensemble_data['tn_lgbm3'] + ensemble_data['tn_regresion'] + ensemble_data['tn_media'] + ensemble_data['tn_autogluon']) / 6\n",
    "\n",
    "print(f\"\\nEstadísticas del ensemble:\")\n",
    "print(f\"Promedio de tn: {ensemble_data['tn'].mean():.2f}\")\n",
    "print(f\"Mediana de tn: {ensemble_data['tn'].median():.2f}\")\n",
    "print(f\"Std de tn: {ensemble_data['tn'].std():.2f}\")\n",
    "\n",
    "# Mostrar comparación de los primeros productos\n",
    "print(f\"\\nComparación de predicciones para los primeros 5 productos:\")\n",
    "comparison = ensemble_data[['product_id', 'tn_lgbm', 'tn_lgbm2', 'tn_lgbm3', 'tn_regresion', 'tn_media', 'tn_autogluon', 'tn']].head()\n",
    "print(comparison)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6746b642",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparando datos finales para guardar...\n",
      "Valores nulos en el resultado final: 0\n",
      "Shape del resultado final: (780, 2)\n",
      "\n",
      "Primeras 10 filas del resultado final:\n",
      "   product_id           tn\n",
      "0       20001  1295.696699\n",
      "1       20002  1091.588287\n",
      "2       20003   692.413822\n",
      "3       20004   551.492436\n",
      "4       20005   561.089363\n",
      "5       20006   430.278767\n",
      "6       20007   375.547096\n",
      "7       20008   370.279843\n",
      "8       20009   443.810569\n",
      "9       20010   373.301518\n",
      "\n",
      "Últimas 5 filas del resultado final:\n",
      "     product_id        tn\n",
      "775       21263  0.790199\n",
      "776       21265  0.780330\n",
      "777       21266  0.760981\n",
      "778       21267  0.857844\n",
      "779       21276  0.826689\n"
     ]
    }
   ],
   "source": [
    "# Crear el archivo final con solo product_id y tn promediado\n",
    "print(\"Preparando datos finales para guardar...\")\n",
    "\n",
    "# Seleccionar solo las columnas necesarias para el archivo final\n",
    "resultado_final = ensemble_data[['product_id', 'tn']].copy()\n",
    "\n",
    "# Verificar que no hay valores nulos\n",
    "print(f\"Valores nulos en el resultado final: {resultado_final.isnull().sum().sum()}\")\n",
    "print(f\"Shape del resultado final: {resultado_final.shape}\")\n",
    "\n",
    "# Ordenar por product_id para consistencia\n",
    "resultado_final = resultado_final.sort_values('product_id').reset_index(drop=True)\n",
    "\n",
    "print(\"\\nPrimeras 10 filas del resultado final:\")\n",
    "print(resultado_final.head(10))\n",
    "\n",
    "print(f\"\\nÚltimas 5 filas del resultado final:\")\n",
    "print(resultado_final.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ce6fa510",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Guardando resultado en: data/pred_ensemble06_lgbm_rl_media12_09301_autogluon.csv\n",
      "✅ Archivo guardado exitosamente: data/pred_ensemble06_lgbm_rl_media12_09301_autogluon.csv\n",
      "Total de productos en el ensemble: 780\n",
      "Tamaño del archivo: 19853 bytes\n",
      "\n",
      "Verificación - Primeras 5 líneas del archivo guardado:\n",
      "   product_id           tn\n",
      "0       20001  1295.696699\n",
      "1       20002  1091.588287\n",
      "2       20003   692.413822\n",
      "3       20004   551.492436\n",
      "4       20005   561.089363\n"
     ]
    }
   ],
   "source": [
    "# Guardar el archivo final\n",
    "archivo_salida = \"data/pred_ensemble06_lgbm_rl_media12_09301_autogluon.csv\"\n",
    "\n",
    "print(f\"Guardando resultado en: {archivo_salida}\")\n",
    "\n",
    "# Crear directorio data si no existe\n",
    "import os\n",
    "os.makedirs(\"data\", exist_ok=True)\n",
    "\n",
    "# Guardar el archivo\n",
    "resultado_final = ensemble_data[['product_id', 'tn']].copy()\n",
    "resultado_final.to_csv(archivo_salida, index=False)\n",
    "\n",
    "print(f\"✅ Archivo guardado exitosamente: {archivo_salida}\")\n",
    "print(f\"Total de productos en el ensemble: {len(resultado_final)}\")\n",
    "\n",
    "# Verificar que el archivo se guardó correctamente\n",
    "if os.path.exists(archivo_salida):\n",
    "    tamaño_archivo = os.path.getsize(archivo_salida)\n",
    "    print(f\"Tamaño del archivo: {tamaño_archivo} bytes\")\n",
    "    \n",
    "    # Leer las primeras líneas del archivo guardado para verificar\n",
    "    verificacion = pd.read_csv(archivo_salida, nrows=5)\n",
    "    print(f\"\\nVerificación - Primeras 5 líneas del archivo guardado:\")\n",
    "    print(verificacion)\n",
    "else:\n",
    "    print(\"⚠️ Error: No se pudo crear el archivo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5a74bbaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RESUMEN DEL ENSEMBLE DE 6 MODELOS\n",
      "============================================================\n",
      "Estadísticas de LGBM:\n",
      "  Promedio: 34.87\n",
      "  Mediana:  8.85\n",
      "  Std:      87.64\n",
      "  Min:      0.59\n",
      "  Max:      1282.32\n",
      "\n",
      "Estadísticas de LGBM2:\n",
      "  Promedio: 34.70\n",
      "  Mediana:  8.67\n",
      "  Std:      87.83\n",
      "  Min:      0.69\n",
      "  Max:      1300.85\n",
      "\n",
      "Estadísticas de LGBM3:\n",
      "  Promedio: 34.69\n",
      "  Mediana:  8.72\n",
      "  Std:      91.32\n",
      "  Min:      0.88\n",
      "  Max:      1352.62\n",
      "\n",
      "Estadísticas de Regresión Lineal:\n",
      "  Promedio: 35.67\n",
      "  Mediana:  9.04\n",
      "  Std:      92.24\n",
      "  Min:      0.23\n",
      "  Max:      1183.64\n",
      "\n",
      "Estadísticas de Media 12 093:\n",
      "  Promedio: 36.54\n",
      "  Mediana:  8.86\n",
      "  Std:      95.81\n",
      "  Min:      0.02\n",
      "  Max:      1352.90\n",
      "\n",
      "Estadísticas de Autogluon:\n",
      "  Promedio: 36.25\n",
      "  Mediana:  9.06\n",
      "  Std:      93.69\n",
      "  Min:      0.03\n",
      "  Max:      1322.78\n",
      "\n",
      "Estadísticas del Ensemble (Promedio de 6 modelos):\n",
      "  Promedio: 35.45\n",
      "  Mediana:  8.95\n",
      "  Std:      91.19\n",
      "  Min:      0.50\n",
      "  Max:      1295.70\n",
      "\n",
      "Matriz de correlaciones:\n",
      "              tn_lgbm  tn_lgbm2  tn_lgbm3  tn_regresion  tn_media  \\\n",
      "tn_lgbm        1.0000    0.9985    0.9961        0.9912    0.9957   \n",
      "tn_lgbm2       0.9985    1.0000    0.9961        0.9901    0.9951   \n",
      "tn_lgbm3       0.9961    0.9961    1.0000        0.9898    0.9934   \n",
      "tn_regresion   0.9912    0.9901    0.9898        1.0000    0.9942   \n",
      "tn_media       0.9957    0.9951    0.9934        0.9942    1.0000   \n",
      "tn_autogluon   0.9944    0.9934    0.9921        0.9931    0.9975   \n",
      "\n",
      "              tn_autogluon  \n",
      "tn_lgbm             0.9944  \n",
      "tn_lgbm2            0.9934  \n",
      "tn_lgbm3            0.9921  \n",
      "tn_regresion        0.9931  \n",
      "tn_media            0.9975  \n",
      "tn_autogluon        1.0000  \n",
      "\n",
      "✅ Ensemble de 6 modelos completado exitosamente!\n",
      "Archivo final: data/pred_ensemble06_lgbm_rl_media12_09301_autogluon.csv\n",
      "Total de productos: 780\n",
      "Método: Promedio simple de 6 modelos\n"
     ]
    }
   ],
   "source": [
    "# Análisis estadístico final del ensemble\n",
    "print(\"RESUMEN DEL ENSEMBLE DE 6 MODELOS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Estadísticas descriptivas de cada modelo\n",
    "print(\"Estadísticas de LGBM:\")\n",
    "print(f\"  Promedio: {ensemble_data['tn_lgbm'].mean():.2f}\")\n",
    "print(f\"  Mediana:  {ensemble_data['tn_lgbm'].median():.2f}\")\n",
    "print(f\"  Std:      {ensemble_data['tn_lgbm'].std():.2f}\")\n",
    "print(f\"  Min:      {ensemble_data['tn_lgbm'].min():.2f}\")\n",
    "print(f\"  Max:      {ensemble_data['tn_lgbm'].max():.2f}\")\n",
    "\n",
    "print(\"\\nEstadísticas de LGBM2:\")\n",
    "print(f\"  Promedio: {ensemble_data['tn_lgbm2'].mean():.2f}\")\n",
    "print(f\"  Mediana:  {ensemble_data['tn_lgbm2'].median():.2f}\")\n",
    "print(f\"  Std:      {ensemble_data['tn_lgbm2'].std():.2f}\")\n",
    "print(f\"  Min:      {ensemble_data['tn_lgbm2'].min():.2f}\")\n",
    "print(f\"  Max:      {ensemble_data['tn_lgbm2'].max():.2f}\")\n",
    "\n",
    "print(\"\\nEstadísticas de LGBM3:\")\n",
    "print(f\"  Promedio: {ensemble_data['tn_lgbm3'].mean():.2f}\")\n",
    "print(f\"  Mediana:  {ensemble_data['tn_lgbm3'].median():.2f}\")\n",
    "print(f\"  Std:      {ensemble_data['tn_lgbm3'].std():.2f}\")\n",
    "print(f\"  Min:      {ensemble_data['tn_lgbm3'].min():.2f}\")\n",
    "print(f\"  Max:      {ensemble_data['tn_lgbm3'].max():.2f}\")\n",
    "\n",
    "print(\"\\nEstadísticas de Regresión Lineal:\")\n",
    "print(f\"  Promedio: {ensemble_data['tn_regresion'].mean():.2f}\")\n",
    "print(f\"  Mediana:  {ensemble_data['tn_regresion'].median():.2f}\")\n",
    "print(f\"  Std:      {ensemble_data['tn_regresion'].std():.2f}\")\n",
    "print(f\"  Min:      {ensemble_data['tn_regresion'].min():.2f}\")\n",
    "print(f\"  Max:      {ensemble_data['tn_regresion'].max():.2f}\")\n",
    "\n",
    "print(\"\\nEstadísticas de Media 12 093:\")\n",
    "print(f\"  Promedio: {ensemble_data['tn_media'].mean():.2f}\")\n",
    "print(f\"  Mediana:  {ensemble_data['tn_media'].median():.2f}\")\n",
    "print(f\"  Std:      {ensemble_data['tn_media'].std():.2f}\")\n",
    "print(f\"  Min:      {ensemble_data['tn_media'].min():.2f}\")\n",
    "print(f\"  Max:      {ensemble_data['tn_media'].max():.2f}\")\n",
    "\n",
    "print(\"\\nEstadísticas de Autogluon:\")\n",
    "print(f\"  Promedio: {ensemble_data['tn_autogluon'].mean():.2f}\")\n",
    "print(f\"  Mediana:  {ensemble_data['tn_autogluon'].median():.2f}\")\n",
    "print(f\"  Std:      {ensemble_data['tn_autogluon'].std():.2f}\")\n",
    "print(f\"  Min:      {ensemble_data['tn_autogluon'].min():.2f}\")\n",
    "print(f\"  Max:      {ensemble_data['tn_autogluon'].max():.2f}\")\n",
    "\n",
    "print(\"\\nEstadísticas del Ensemble (Promedio de 6 modelos):\")\n",
    "print(f\"  Promedio: {ensemble_data['tn'].mean():.2f}\")\n",
    "print(f\"  Mediana:  {ensemble_data['tn'].median():.2f}\")\n",
    "print(f\"  Std:      {ensemble_data['tn'].std():.2f}\")\n",
    "print(f\"  Min:      {ensemble_data['tn'].min():.2f}\")\n",
    "print(f\"  Max:      {ensemble_data['tn'].max():.2f}\")\n",
    "\n",
    "# Correlaciones entre modelos\n",
    "print(\"\\nMatriz de correlaciones:\")\n",
    "correlaciones = ensemble_data[['tn_lgbm', 'tn_lgbm2', 'tn_lgbm3', 'tn_regresion', 'tn_media', 'tn_autogluon']].corr()\n",
    "print(correlaciones.round(4))\n",
    "\n",
    "print(f\"\\n✅ Ensemble de 6 modelos completado exitosamente!\")\n",
    "print(f\"Archivo final: {archivo_salida}\")\n",
    "print(f\"Total de productos: {len(resultado_final)}\")\n",
    "print(f\"Método: Promedio simple de 6 modelos\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ldi2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
