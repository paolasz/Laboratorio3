{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5907ba2e",
   "metadata": {},
   "source": [
    "cr la optimizacion de los parametros recomendados en virtual 2025"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d70a5edb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Librer√≠as importadas correctamente\n"
     ]
    }
   ],
   "source": [
    "# üì¶ Importar librer√≠as necesarias\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "print(\"‚úÖ Librer√≠as importadas correctamente\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4317525b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cargando datasets...\n",
      "‚úÖ Sales data cargado: (2945818, 7)\n",
      "‚úÖ Stocks data cargado: (13691, 3)\n",
      "‚úÖ Product info cargado: (1251, 7)\n",
      "‚úÖ Productos a predecir cargados: (780, 1)\n",
      "\n",
      "üéØ Todos los datasets cargados exitosamente\n",
      "‚úÖ Sales data cargado: (2945818, 7)\n",
      "‚úÖ Stocks data cargado: (13691, 3)\n",
      "‚úÖ Product info cargado: (1251, 7)\n",
      "‚úÖ Productos a predecir cargados: (780, 1)\n",
      "\n",
      "üéØ Todos los datasets cargados exitosamente\n"
     ]
    }
   ],
   "source": [
    "# üìÑ Cargar todos los datasets\n",
    "print(\"Cargando datasets...\")\n",
    "\n",
    "# Load the sales data (tab-delimited)\n",
    "sales = pd.read_csv(\"datasets/sell-in.txt\", sep=\"\\t\", dtype={\"periodo\": str})\n",
    "print(f\"‚úÖ Sales data cargado: {sales.shape}\")\n",
    "\n",
    "# Load the stocks data (tab-delimited) \n",
    "stocks = pd.read_csv(\"datasets/tb_stocks.txt\", sep=\"\\t\", dtype={\"periodo\": str})\n",
    "print(f\"‚úÖ Stocks data cargado: {stocks.shape}\")\n",
    "\n",
    "# Load the product information data (tab-delimited)\n",
    "product_info = pd.read_csv(\"datasets/tb_productos.txt\", sep=\"\\t\")\n",
    "print(f\"‚úÖ Product info cargado: {product_info.shape}\")\n",
    "\n",
    "# Carga productos a predecir\n",
    "product_predict = pd.read_csv(\"datasets/product_id_apredecir201912.txt\", sep=\"\\t\", header=0)\n",
    "print(f\"‚úÖ Productos a predecir cargados: {product_predict.shape}\")\n",
    "\n",
    "print(\"\\nüéØ Todos los datasets cargados exitosamente\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1f236a4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EXPLORACI√ìN DE DATOS\n",
      "==================================================\n",
      "\n",
      "üìä SALES DATA:\n",
      "Columnas: ['periodo', 'customer_id', 'product_id', 'plan_precios_cuidados', 'cust_request_qty', 'cust_request_tn', 'tn']\n",
      "Per√≠odos √∫nicos: 36\n",
      "Productos √∫nicos: 1233\n",
      "Primeras filas:\n",
      "  periodo  customer_id  product_id  plan_precios_cuidados  cust_request_qty  \\\n",
      "0  201701        10234       20524                      0                 2   \n",
      "1  201701        10032       20524                      0                 1   \n",
      "2  201701        10217       20524                      0                 1   \n",
      "3  201701        10125       20524                      0                 1   \n",
      "4  201701        10012       20524                      0                11   \n",
      "\n",
      "   cust_request_tn       tn  \n",
      "0          0.05300  0.05300  \n",
      "1          0.13628  0.13628  \n",
      "2          0.03028  0.03028  \n",
      "3          0.02271  0.02271  \n",
      "4          1.54452  1.54452  \n",
      "\n",
      "üì¶ STOCKS DATA:\n",
      "Columnas: ['periodo', 'product_id', 'stock_final']\n",
      "Per√≠odos √∫nicos: 15\n",
      "Productos √∫nicos: 1095\n",
      "Primeras filas:\n",
      "  periodo  product_id  stock_final\n",
      "0  201810       20524      1.61267\n",
      "1  201810       20311      2.93657\n",
      "2  201810       20654      6.83269\n",
      "3  201810       21005      1.01338\n",
      "4  201810       20974      0.34595\n",
      "\n",
      "üè∑Ô∏è PRODUCT INFO:\n",
      "Columnas: ['cat1', 'cat2', 'cat3', 'brand', 'sku_size', 'product_id', 'descripcion']\n",
      "Productos √∫nicos: 1251\n",
      "Primeras filas:\n",
      "    cat1      cat2         cat3   brand  sku_size  product_id  \\\n",
      "0  FOODS  ADEREZOS  Aji Picante  NATURA       240       20609   \n",
      "1  FOODS  ADEREZOS     Barbacoa  NATURA       250       20266   \n",
      "2  FOODS  ADEREZOS     Barbacoa  NATURA       400       20325   \n",
      "3  FOODS  ADEREZOS     Barbacoa  NATURA       500       20503   \n",
      "4  FOODS  ADEREZOS  Chimichurri  NATURA       350       20797   \n",
      "\n",
      "         descripcion  \n",
      "0  Salsa Aji Picante  \n",
      "1     Salsa Barbacoa  \n",
      "2     Salsa Barbacoa  \n",
      "3     Salsa Barbacoa  \n",
      "4        Chimichurri  \n",
      "\n",
      "üéØ PRODUCTOS A PREDECIR:\n",
      "Columnas: ['product_id']\n",
      "Total productos a predecir: 780\n",
      "Primeras filas:\n",
      "   product_id\n",
      "0       20001\n",
      "1       20002\n",
      "2       20003\n",
      "3       20004\n",
      "4       20005\n"
     ]
    }
   ],
   "source": [
    "# üîç Explorar estructura de los datos\n",
    "print(\"EXPLORACI√ìN DE DATOS\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "print(\"\\nüìä SALES DATA:\")\n",
    "print(f\"Columnas: {list(sales.columns)}\")\n",
    "print(f\"Per√≠odos √∫nicos: {sales['periodo'].nunique()}\")\n",
    "print(f\"Productos √∫nicos: {sales['product_id'].nunique()}\")\n",
    "print(\"Primeras filas:\")\n",
    "print(sales.head())\n",
    "\n",
    "print(\"\\nüì¶ STOCKS DATA:\")\n",
    "print(f\"Columnas: {list(stocks.columns)}\")\n",
    "print(f\"Per√≠odos √∫nicos: {stocks['periodo'].nunique()}\")\n",
    "print(f\"Productos √∫nicos: {stocks['product_id'].nunique()}\")\n",
    "print(\"Primeras filas:\")\n",
    "print(stocks.head())\n",
    "\n",
    "print(\"\\nüè∑Ô∏è PRODUCT INFO:\")\n",
    "print(f\"Columnas: {list(product_info.columns)}\")\n",
    "print(f\"Productos √∫nicos: {product_info['product_id'].nunique()}\")\n",
    "print(\"Primeras filas:\")\n",
    "print(product_info.head())\n",
    "\n",
    "print(\"\\nüéØ PRODUCTOS A PREDECIR:\")\n",
    "print(f\"Columnas: {list(product_predict.columns)}\")\n",
    "print(f\"Total productos a predecir: {len(product_predict)}\")\n",
    "print(\"Primeras filas:\")\n",
    "print(product_predict.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d647da4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VERIFICACI√ìN DE CONSISTENCIA\n",
      "==================================================\n",
      "üìä Productos en sales: 1233\n",
      "üì¶ Productos en stocks: 1095\n",
      "üè∑Ô∏è Productos en product_info: 1251\n",
      "üéØ Productos a predecir: 780\n",
      "\n",
      "üîç INTERSECCIONES:\n",
      "Sales ‚à© Stocks: 1095\n",
      "Sales ‚à© Product_info: 1188\n",
      "Sales ‚à© Productos_predict: 780\n",
      "Stocks ‚à© Productos_predict: 779\n",
      "Product_info ‚à© Productos_predict: 780\n",
      "\n",
      "üìÖ RANGOS DE FECHAS:\n",
      "Sales - per√≠odos: 201701 a 201912\n",
      "Stocks - per√≠odos: 201810 a 201912\n",
      "Sales - per√≠odos: 201701 a 201912\n",
      "Stocks - per√≠odos: 201810 a 201912\n"
     ]
    }
   ],
   "source": [
    "# üîó Verificar consistencia entre datasets\n",
    "print(\"VERIFICACI√ìN DE CONSISTENCIA\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Productos √∫nicos en cada dataset\n",
    "productos_sales = set(sales['product_id'].unique())\n",
    "productos_stocks = set(stocks['product_id'].unique())\n",
    "productos_info = set(product_info['product_id'].unique())\n",
    "\n",
    "# Si product_predict tiene columna product_id\n",
    "if 'product_id' in product_predict.columns:\n",
    "    productos_predict = set(product_predict['product_id'].unique())\n",
    "else:\n",
    "    # Si la primera columna contiene los product_ids\n",
    "    primera_columna = product_predict.columns[0]\n",
    "    productos_predict = set(product_predict[primera_columna].unique())\n",
    "    print(f\"‚ö†Ô∏è Usando columna '{primera_columna}' como product_id\")\n",
    "\n",
    "print(f\"üìä Productos en sales: {len(productos_sales)}\")\n",
    "print(f\"üì¶ Productos en stocks: {len(productos_stocks)}\")\n",
    "print(f\"üè∑Ô∏è Productos en product_info: {len(productos_info)}\")\n",
    "print(f\"üéØ Productos a predecir: {len(productos_predict)}\")\n",
    "\n",
    "# Verificar intersecciones\n",
    "print(f\"\\nüîç INTERSECCIONES:\")\n",
    "print(f\"Sales ‚à© Stocks: {len(productos_sales & productos_stocks)}\")\n",
    "print(f\"Sales ‚à© Product_info: {len(productos_sales & productos_info)}\")\n",
    "print(f\"Sales ‚à© Productos_predict: {len(productos_sales & productos_predict)}\")\n",
    "print(f\"Stocks ‚à© Productos_predict: {len(productos_stocks & productos_predict)}\")\n",
    "print(f\"Product_info ‚à© Productos_predict: {len(productos_info & productos_predict)}\")\n",
    "\n",
    "# Verificar rangos de fechas\n",
    "print(f\"\\nüìÖ RANGOS DE FECHAS:\")\n",
    "print(f\"Sales - per√≠odos: {sales['periodo'].min()} a {sales['periodo'].max()}\")\n",
    "print(f\"Stocks - per√≠odos: {stocks['periodo'].min()} a {stocks['periodo'].max()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4e08be3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ LightGBM, Optuna y librer√≠as ML importadas correctamente\n"
     ]
    }
   ],
   "source": [
    "# üì¶ Instalar e importar LightGBM, Optuna y librer√≠as adicionales\n",
    "# %pip install lightgbm optuna\n",
    "\n",
    "import lightgbm as lgb\n",
    "import optuna\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"‚úÖ LightGBM, Optuna y librer√≠as ML importadas correctamente\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "715202b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PREPARACI√ìN DE DATOS PARA LGBM - GRANULARIDAD POR PRODUCTO\n",
      "============================================================\n",
      "üéØ Productos objetivo: 780\n",
      "üìä Sales filtradas: (2293481, 8)\n",
      "üì¶ Stocks filtradas: (10727, 4)\n",
      "üìä Sales filtradas: (2293481, 8)\n",
      "üì¶ Stocks filtradas: (10727, 4)\n",
      "üìà Sales agregadas por producto: (22349, 7)\n",
      "Primeras filas de sales agregadas:\n",
      "   product_id      fecha periodo          tn  num_customers  \\\n",
      "0       20001 2017-01-01  201701   934.77222            186   \n",
      "1       20001 2017-02-01  201702   798.01620            185   \n",
      "2       20001 2017-03-01  201703  1303.35771            188   \n",
      "3       20001 2017-04-01  201704  1069.96130            104   \n",
      "4       20001 2017-05-01  201705  1502.20132            238   \n",
      "\n",
      "   total_request_qty  total_request_tn  \n",
      "0                479         937.72717  \n",
      "1                432         833.72187  \n",
      "2                509        1330.74697  \n",
      "3                279        1132.94430  \n",
      "4                701        1550.68936  \n",
      "\n",
      "üìä Estad√≠sticas por producto:\n",
      "  Promedio tn por producto-per√≠odo: 50.23\n",
      "  Promedio clientes por producto-per√≠odo: 102.62\n",
      "  Productos √∫nicos: 780\n",
      "  Per√≠odos √∫nicos: 36\n",
      "üìà Sales agregadas por producto: (22349, 7)\n",
      "Primeras filas de sales agregadas:\n",
      "   product_id      fecha periodo          tn  num_customers  \\\n",
      "0       20001 2017-01-01  201701   934.77222            186   \n",
      "1       20001 2017-02-01  201702   798.01620            185   \n",
      "2       20001 2017-03-01  201703  1303.35771            188   \n",
      "3       20001 2017-04-01  201704  1069.96130            104   \n",
      "4       20001 2017-05-01  201705  1502.20132            238   \n",
      "\n",
      "   total_request_qty  total_request_tn  \n",
      "0                479         937.72717  \n",
      "1                432         833.72187  \n",
      "2                509        1330.74697  \n",
      "3                279        1132.94430  \n",
      "4                701        1550.68936  \n",
      "\n",
      "üìä Estad√≠sticas por producto:\n",
      "  Promedio tn por producto-per√≠odo: 50.23\n",
      "  Promedio clientes por producto-per√≠odo: 102.62\n",
      "  Productos √∫nicos: 780\n",
      "  Per√≠odos √∫nicos: 36\n"
     ]
    }
   ],
   "source": [
    "# üßπ Preparaci√≥n de datos para el modelo LightGBM\n",
    "print(\"PREPARACI√ìN DE DATOS PARA LGBM - GRANULARIDAD POR PRODUCTO\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Convertir per√≠odo a datetime para facilitar manipulaci√≥n\n",
    "sales['fecha'] = pd.to_datetime(sales['periodo'], format='%Y%m')\n",
    "stocks['fecha'] = pd.to_datetime(stocks['periodo'], format='%Y%m')\n",
    "\n",
    "# Filtrar solo productos que necesitamos predecir\n",
    "if 'product_id' in product_predict.columns:\n",
    "    productos_objetivo = product_predict['product_id'].tolist()\n",
    "else:\n",
    "    productos_objetivo = product_predict[product_predict.columns[0]].tolist()\n",
    "\n",
    "print(f\"üéØ Productos objetivo: {len(productos_objetivo)}\")\n",
    "\n",
    "# Filtrar sales y stocks para productos objetivo\n",
    "sales_filtered = sales[sales['product_id'].isin(productos_objetivo)].copy()\n",
    "stocks_filtered = stocks[stocks['product_id'].isin(productos_objetivo)].copy()\n",
    "\n",
    "print(f\"üìä Sales filtradas: {sales_filtered.shape}\")\n",
    "print(f\"üì¶ Stocks filtradas: {stocks_filtered.shape}\")\n",
    "\n",
    "# AGREGACI√ìN POR PRODUCTO: Sumar por producto y per√≠odo (agregando todos los clientes)\n",
    "sales_agg = sales_filtered.groupby(['product_id', 'fecha', 'periodo']).agg({\n",
    "    'tn': 'sum',                    # Total toneladas por producto\n",
    "    'customer_id': 'nunique',       # N√∫mero de clientes √∫nicos\n",
    "    'cust_request_qty': 'sum',      # Total cantidad solicitada\n",
    "    'cust_request_tn': 'sum'        # Total toneladas solicitadas\n",
    "}).reset_index()\n",
    "\n",
    "# Renombrar columnas para claridad\n",
    "sales_agg.rename(columns={\n",
    "    'customer_id': 'num_customers',\n",
    "    'cust_request_qty': 'total_request_qty', \n",
    "    'cust_request_tn': 'total_request_tn'\n",
    "}, inplace=True)\n",
    "\n",
    "print(f\"üìà Sales agregadas por producto: {sales_agg.shape}\")\n",
    "print(\"Primeras filas de sales agregadas:\")\n",
    "print(sales_agg.head())\n",
    "\n",
    "print(f\"\\nüìä Estad√≠sticas por producto:\")\n",
    "print(f\"  Promedio tn por producto-per√≠odo: {sales_agg['tn'].mean():.2f}\")\n",
    "print(f\"  Promedio clientes por producto-per√≠odo: {sales_agg['num_customers'].mean():.2f}\")\n",
    "print(f\"  Productos √∫nicos: {sales_agg['product_id'].nunique()}\")\n",
    "print(f\"  Per√≠odos √∫nicos: {sales_agg['periodo'].nunique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "511ecf79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CREACI√ìN DE FEATURES POR PRODUCTO\n",
      "==================================================\n",
      "üìä Sales con lags por producto: (22349, 18)\n",
      "üì¶ Datos combinados con stock por producto: (22349, 26)\n",
      "Columnas disponibles: 26\n",
      "\n",
      "Primeras columnas:\n",
      "['product_id', 'fecha', 'periodo', 'tn', 'num_customers', 'total_request_qty', 'total_request_tn', 'tn_lag_1', 'tn_lag_2', 'tn_lag_3', 'tn_lag_6', 'tn_lag_12', 'num_customers_lag_1', 'num_customers_lag_2', 'num_customers_lag_3']\n",
      "√öltimas columnas:\n",
      "['total_request_tn_lag_2', 'total_request_tn_lag_3', 'stock_tn_mean', 'stock_tn_sum', 'stock_tn_std', 'stock_tn_mean_lag_1', 'stock_tn_mean_lag_2', 'stock_tn_mean_lag_3', 'stock_tn_sum_lag_1', 'stock_tn_sum_lag_2']\n"
     ]
    }
   ],
   "source": [
    "# üîß Crear features de lag y combinar con stocks - GRANULARIDAD POR PRODUCTO\n",
    "print(\"CREACI√ìN DE FEATURES POR PRODUCTO\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Crear features de lag para cada producto\n",
    "def create_lag_features(df, product_col, value_col, date_col, lags=[1, 2, 3, 6, 12]):\n",
    "    \"\"\"Crear features de lag para series temporales por producto\"\"\"\n",
    "    df_features = df.copy()\n",
    "    df_features = df_features.sort_values([product_col, date_col])\n",
    "    \n",
    "    for lag in lags:\n",
    "        df_features[f'{value_col}_lag_{lag}'] = df_features.groupby(product_col)[value_col].shift(lag)\n",
    "    \n",
    "    return df_features\n",
    "\n",
    "# Crear lags para ventas (tn) por producto\n",
    "sales_with_lags = create_lag_features(\n",
    "    sales_agg, \n",
    "    'product_id', \n",
    "    'tn', \n",
    "    'fecha', \n",
    "    lags=[1, 2, 3, 6, 12]\n",
    ")\n",
    "\n",
    "# Crear lags para n√∫mero de clientes por producto\n",
    "sales_with_lags = create_lag_features(\n",
    "    sales_with_lags, \n",
    "    'product_id', \n",
    "    'num_customers', \n",
    "    'fecha', \n",
    "    lags=[1, 2, 3]\n",
    ")\n",
    "\n",
    "# Crear lags para solicitudes de clientes\n",
    "sales_with_lags = create_lag_features(\n",
    "    sales_with_lags, \n",
    "    'product_id', \n",
    "    'total_request_tn', \n",
    "    'fecha', \n",
    "    lags=[1, 2, 3]\n",
    ")\n",
    "\n",
    "print(f\"üìä Sales con lags por producto: {sales_with_lags.shape}\")\n",
    "\n",
    "# Agregar datos de stock por producto\n",
    "stocks_agg = stocks_filtered.groupby(['product_id', 'fecha', 'periodo']).agg({\n",
    "    'stock_final': ['mean', 'sum', 'std']  # Stock promedio, total y desviaci√≥n est√°ndar por producto\n",
    "}).reset_index()\n",
    "\n",
    "# Aplanar columnas multinivel\n",
    "stocks_agg.columns = ['product_id', 'fecha', 'periodo', 'stock_tn_mean', 'stock_tn_sum', 'stock_tn_std']\n",
    "stocks_agg['stock_tn_std'] = stocks_agg['stock_tn_std'].fillna(0)  # Rellenar NaN en std\n",
    "\n",
    "# Combinar sales y stocks por producto\n",
    "data_combined = pd.merge(\n",
    "    sales_with_lags, \n",
    "    stocks_agg[['product_id', 'fecha', 'stock_tn_mean', 'stock_tn_sum', 'stock_tn_std']], \n",
    "    on=['product_id', 'fecha'], \n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# Crear lags para stock por producto\n",
    "data_combined = create_lag_features(\n",
    "    data_combined, \n",
    "    'product_id', \n",
    "    'stock_tn_mean', \n",
    "    'fecha', \n",
    "    lags=[1, 2, 3]\n",
    ")\n",
    "\n",
    "data_combined = create_lag_features(\n",
    "    data_combined, \n",
    "    'product_id', \n",
    "    'stock_tn_sum', \n",
    "    'fecha', \n",
    "    lags=[1, 2]\n",
    ")\n",
    "\n",
    "print(f\"üì¶ Datos combinados con stock por producto: {data_combined.shape}\")\n",
    "print(f\"Columnas disponibles: {len(data_combined.columns)}\")\n",
    "print(\"\\nPrimeras columnas:\")\n",
    "print(data_combined.columns.tolist()[:15])\n",
    "print(\"√öltimas columnas:\")\n",
    "print(data_combined.columns.tolist()[-10:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a7e73cfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CREACI√ìN DE TARGET Y FEATURES ADICIONALES\n",
      "==================================================\n",
      "‚úÖ Informaci√≥n de productos agregada\n",
      "üìä Dataset final: (22349, 40)\n",
      "üìà Registros con target v√°lido: 20789\n",
      "\n",
      "üìä Estad√≠sticas del target:\n",
      "count    20789.000000\n",
      "mean        50.931444\n",
      "std        127.140873\n",
      "min          0.000890\n",
      "25%          3.009870\n",
      "50%         11.928920\n",
      "75%         36.636220\n",
      "max       2295.198320\n",
      "Name: target, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# üéØ Crear target y features adicionales\n",
    "print(\"CREACI√ìN DE TARGET Y FEATURES ADICIONALES\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Crear target: tn de 2 per√≠odos a futuro\n",
    "data_combined = data_combined.sort_values(['product_id', 'fecha'])\n",
    "data_combined['target'] = data_combined.groupby('product_id')['tn'].shift(-2)\n",
    "\n",
    "# Crear features temporales\n",
    "data_combined['mes'] = data_combined['fecha'].dt.month\n",
    "data_combined['trimestre'] = data_combined['fecha'].dt.quarter\n",
    "data_combined['a√±o'] = data_combined['fecha'].dt.year\n",
    "\n",
    "# Crear features estad√≠sticas m√≥viles\n",
    "def create_rolling_features(df, product_col, value_col, date_col, windows=[3, 6, 12]):\n",
    "    \"\"\"Crear features de ventanas m√≥viles\"\"\"\n",
    "    df = df.sort_values([product_col, date_col])\n",
    "    \n",
    "    for window in windows:\n",
    "        df[f'{value_col}_rolling_mean_{window}'] = df.groupby(product_col)[value_col].rolling(window, min_periods=1).mean().reset_index(level=0, drop=True)\n",
    "        df[f'{value_col}_rolling_std_{window}'] = df.groupby(product_col)[value_col].rolling(window, min_periods=1).std().reset_index(level=0, drop=True)\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Crear rolling features para ventas\n",
    "data_combined = create_rolling_features(data_combined, 'product_id', 'tn', 'fecha', windows=[3, 6])\n",
    "\n",
    "# Agregar informaci√≥n de productos si est√° disponible\n",
    "if len(product_info) > 0:\n",
    "    data_combined = pd.merge(\n",
    "        data_combined, \n",
    "        product_info, \n",
    "        on='product_id', \n",
    "        how='left'\n",
    "    )\n",
    "    print(f\"‚úÖ Informaci√≥n de productos agregada\")\n",
    "\n",
    "print(f\"üìä Dataset final: {data_combined.shape}\")\n",
    "print(f\"üìà Registros con target v√°lido: {data_combined['target'].notna().sum()}\")\n",
    "\n",
    "# Mostrar algunas estad√≠sticas del target\n",
    "target_stats = data_combined['target'].describe()\n",
    "print(f\"\\nüìä Estad√≠sticas del target:\")\n",
    "print(target_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5c228b6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PREPARACI√ìN DE DATOS DE ENTRENAMIENTO POR PRODUCTO\n",
      "============================================================\n",
      "üìä Registros v√°lidos para entrenamiento: 20789\n",
      "‚úÖ Features disponibles: 29\n",
      "‚ö†Ô∏è Features faltantes: 0\n",
      "üìä Shape de X: (20789, 29)\n",
      "üìà Shape de y: (20789,)\n",
      "üîç Valores nulos en X: 0\n",
      "üîç Valores nulos en y: 0\n",
      "\n",
      "üìä DIVISI√ìN TEMPORAL:\n",
      "Entrenamiento: 16970 registros (hasta 2019-05)\n",
      "Validaci√≥n: 3819 registros (desde 2019-05)\n",
      "\n",
      "üéØ PRODUCTOS EN ENTRENAMIENTO:\n",
      "Productos √∫nicos en entrenamiento: 718\n",
      "Productos √∫nicos en validaci√≥n: 780\n",
      "\n",
      "Features seleccionadas para granularidad por producto:\n",
      "   1. tn_lag_1\n",
      "   2. tn_lag_2\n",
      "   3. tn_lag_3\n",
      "   4. tn_lag_6\n",
      "   5. tn_lag_12\n",
      "   6. num_customers_lag_1\n",
      "   7. num_customers_lag_2\n",
      "   8. num_customers_lag_3\n",
      "   9. total_request_tn_lag_1\n",
      "  10. total_request_tn_lag_2\n",
      "  11. total_request_tn_lag_3\n",
      "  12. stock_tn_mean_lag_1\n",
      "  13. stock_tn_mean_lag_2\n",
      "  14. stock_tn_mean_lag_3\n",
      "  15. stock_tn_sum_lag_1\n",
      "  16. stock_tn_sum_lag_2\n",
      "  17. mes\n",
      "  18. trimestre\n",
      "  19. a√±o\n",
      "  20. tn_rolling_mean_3\n",
      "  21. tn_rolling_mean_6\n",
      "  22. tn_rolling_std_3\n",
      "  23. tn_rolling_std_6\n",
      "  24. num_customers\n",
      "  25. total_request_qty\n",
      "  26. total_request_tn\n",
      "  27. stock_tn_mean\n",
      "  28. stock_tn_sum\n",
      "  29. stock_tn_std\n"
     ]
    }
   ],
   "source": [
    "# üìã Preparar datos para entrenamiento - GRANULARIDAD POR PRODUCTO\n",
    "print(\"PREPARACI√ìN DE DATOS DE ENTRENAMIENTO POR PRODUCTO\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Filtrar registros con target v√°lido\n",
    "train_data = data_combined[data_combined['target'].notna()].copy()\n",
    "print(f\"üìä Registros v√°lidos para entrenamiento: {len(train_data)}\")\n",
    "\n",
    "# Seleccionar features para el modelo con granularidad por producto\n",
    "feature_columns = [\n",
    "    # Lags de ventas (tn) por producto\n",
    "    'tn_lag_1', 'tn_lag_2', 'tn_lag_3', 'tn_lag_6', 'tn_lag_12',\n",
    "    \n",
    "    # Lags de clientes por producto\n",
    "    'num_customers_lag_1', 'num_customers_lag_2', 'num_customers_lag_3',\n",
    "    \n",
    "    # Lags de solicitudes por producto\n",
    "    'total_request_tn_lag_1', 'total_request_tn_lag_2', 'total_request_tn_lag_3',\n",
    "    \n",
    "    # Lags de stock por producto\n",
    "    'stock_tn_mean_lag_1', 'stock_tn_mean_lag_2', 'stock_tn_mean_lag_3',\n",
    "    'stock_tn_sum_lag_1', 'stock_tn_sum_lag_2',\n",
    "    \n",
    "    # Features temporales\n",
    "    'mes', 'trimestre', 'a√±o',\n",
    "    \n",
    "    # Rolling features por producto\n",
    "    'tn_rolling_mean_3', 'tn_rolling_mean_6',\n",
    "    'tn_rolling_std_3', 'tn_rolling_std_6',\n",
    "    \n",
    "    # Features actuales por producto\n",
    "    'num_customers', 'total_request_qty', 'total_request_tn',\n",
    "    'stock_tn_mean', 'stock_tn_sum', 'stock_tn_std'\n",
    "]\n",
    "\n",
    "# Verificar qu√© features existen\n",
    "available_features = [col for col in feature_columns if col in train_data.columns]\n",
    "missing_features = [col for col in feature_columns if col not in train_data.columns]\n",
    "\n",
    "print(f\"‚úÖ Features disponibles: {len(available_features)}\")\n",
    "print(f\"‚ö†Ô∏è Features faltantes: {len(missing_features)}\")\n",
    "if missing_features:\n",
    "    print(f\"Features faltantes: {missing_features}\")\n",
    "\n",
    "# Usar solo features disponibles\n",
    "feature_columns = available_features\n",
    "\n",
    "# Preparar X e y\n",
    "X = train_data[feature_columns].copy()\n",
    "y = train_data['target'].copy()\n",
    "\n",
    "# Rellenar valores nulos con 0 (para lags iniciales y stocks faltantes)\n",
    "X = X.fillna(0)\n",
    "\n",
    "print(f\"üìä Shape de X: {X.shape}\")\n",
    "print(f\"üìà Shape de y: {y.shape}\")\n",
    "print(f\"üîç Valores nulos en X: {X.isnull().sum().sum()}\")\n",
    "print(f\"üîç Valores nulos en y: {y.isnull().sum()}\")\n",
    "\n",
    "# Divisi√≥n temporal para validaci√≥n (√∫ltimos per√≠odos como validaci√≥n)\n",
    "train_data_sorted = train_data.sort_values('fecha')\n",
    "split_date = train_data_sorted['fecha'].quantile(0.8)  # 80% entrenamiento, 20% validaci√≥n\n",
    "\n",
    "train_mask = train_data_sorted['fecha'] <= split_date\n",
    "X_train = X.loc[train_mask]\n",
    "X_val = X.loc[~train_mask] \n",
    "y_train = y.loc[train_mask]\n",
    "y_val = y.loc[~train_mask]\n",
    "\n",
    "print(f\"\\nüìä DIVISI√ìN TEMPORAL:\")\n",
    "print(f\"Entrenamiento: {len(X_train)} registros (hasta {split_date.strftime('%Y-%m')})\")\n",
    "print(f\"Validaci√≥n: {len(X_val)} registros (desde {split_date.strftime('%Y-%m')})\")\n",
    "\n",
    "print(f\"\\nüéØ PRODUCTOS EN ENTRENAMIENTO:\")\n",
    "productos_train = train_data.loc[train_mask, 'product_id'].nunique()\n",
    "productos_val = train_data.loc[~train_mask, 'product_id'].nunique()\n",
    "print(f\"Productos √∫nicos en entrenamiento: {productos_train}\")\n",
    "print(f\"Productos √∫nicos en validaci√≥n: {productos_val}\")\n",
    "\n",
    "print(f\"\\nFeatures seleccionadas para granularidad por producto:\")\n",
    "for i, feat in enumerate(feature_columns):\n",
    "    print(f\"  {i+1:2d}. {feat}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c842ebac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-09 11:05:22,112] A new study created in memory with name: no-name-af20972a-786e-435c-878e-eb46e28ddcad\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OPTIMIZACI√ìN DE HIPERPAR√ÅMETROS CON OPTUNA\n",
      "============================================================\n",
      "üîç Iniciando optimizaci√≥n de hiperpar√°metros...\n",
      "üöÄ Ejecutando 50 trials de optimizaci√≥n...\n",
      "üöÄ Ejecutando 50 trials de optimizaci√≥n...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e15858af3f54be5981834ee4a9b10a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[337]\tvalid_0's l1: 11.1105\n",
      "[I 2025-08-09 11:05:23,706] Trial 0 finished with value: 11.110499810403493 and parameters: {'lambda_l1': 0.749080237694725, 'lambda_l2': 1.9014286128198323, 'num_leaves': 113, 'feature_fraction': 0.759195090518222, 'learning_rate': 0.01700037298921102, 'bagging_fraction': 0.49359671220172163, 'bagging_freq': 1, 'min_child_samples': 44, 'max_bin': 341}. Best is trial 0 with value: 11.110499810403493.\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[337]\tvalid_0's l1: 11.1105\n",
      "[I 2025-08-09 11:05:23,706] Trial 0 finished with value: 11.110499810403493 and parameters: {'lambda_l1': 0.749080237694725, 'lambda_l2': 1.9014286128198323, 'num_leaves': 113, 'feature_fraction': 0.759195090518222, 'learning_rate': 0.01700037298921102, 'bagging_fraction': 0.49359671220172163, 'bagging_freq': 1, 'min_child_samples': 44, 'max_bin': 341}. Best is trial 0 with value: 11.110499810403493.\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[240]\tvalid_0's l1: 10.9198\n",
      "[I 2025-08-09 11:05:25,351] Trial 1 finished with value: 10.91979749572606 and parameters: {'lambda_l1': 1.416145155592091, 'lambda_l2': 0.041168988591604894, 'num_leaves': 146, 'feature_fraction': 0.899465584480253, 'learning_rate': 0.020589728197687916, 'bagging_fraction': 0.5090949803242604, 'bagging_freq': 2, 'min_child_samples': 18, 'max_bin': 310}. Best is trial 1 with value: 10.91979749572606.\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[240]\tvalid_0's l1: 10.9198\n",
      "[I 2025-08-09 11:05:25,351] Trial 1 finished with value: 10.91979749572606 and parameters: {'lambda_l1': 1.416145155592091, 'lambda_l2': 0.041168988591604894, 'num_leaves': 146, 'feature_fraction': 0.899465584480253, 'learning_rate': 0.020589728197687916, 'bagging_fraction': 0.5090949803242604, 'bagging_freq': 2, 'min_child_samples': 18, 'max_bin': 310}. Best is trial 1 with value: 10.91979749572606.\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[241]\tvalid_0's l1: 11.048\n",
      "[I 2025-08-09 11:05:26,366] Trial 2 finished with value: 11.048026900447015 and parameters: {'lambda_l1': 0.8638900372842315, 'lambda_l2': 0.5824582803960838, 'num_leaves': 96, 'feature_fraction': 0.4836963163912251, 'learning_rate': 0.027010527749605478, 'bagging_fraction': 0.619817105976215, 'bagging_freq': 5, 'min_child_samples': 41, 'max_bin': 180}. Best is trial 1 with value: 10.91979749572606.\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[241]\tvalid_0's l1: 11.048\n",
      "[I 2025-08-09 11:05:26,366] Trial 2 finished with value: 11.048026900447015 and parameters: {'lambda_l1': 0.8638900372842315, 'lambda_l2': 0.5824582803960838, 'num_leaves': 96, 'feature_fraction': 0.4836963163912251, 'learning_rate': 0.027010527749605478, 'bagging_fraction': 0.619817105976215, 'bagging_freq': 5, 'min_child_samples': 41, 'max_bin': 180}. Best is trial 1 with value: 10.91979749572606.\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[369]\tvalid_0's l1: 11.2706\n",
      "[I 2025-08-09 11:05:26,774] Trial 3 finished with value: 11.270581029165852 and parameters: {'lambda_l1': 1.0284688768272232, 'lambda_l2': 1.184829137724085, 'num_leaves': 16, 'feature_fraction': 0.764526911140863, 'learning_rate': 0.0178601378893971, 'bagging_fraction': 0.43903095579116774, 'bagging_freq': 10, 'min_child_samples': 49, 'max_bin': 424}. Best is trial 1 with value: 10.91979749572606.\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[369]\tvalid_0's l1: 11.2706\n",
      "[I 2025-08-09 11:05:26,774] Trial 3 finished with value: 11.270581029165852 and parameters: {'lambda_l1': 1.0284688768272232, 'lambda_l2': 1.184829137724085, 'num_leaves': 16, 'feature_fraction': 0.764526911140863, 'learning_rate': 0.0178601378893971, 'bagging_fraction': 0.43903095579116774, 'bagging_freq': 10, 'min_child_samples': 49, 'max_bin': 424}. Best is trial 1 with value: 10.91979749572606.\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[464]\tvalid_0's l1: 10.8577\n",
      "[I 2025-08-09 11:05:28,648] Trial 4 finished with value: 10.857697485053373 and parameters: {'lambda_l1': 0.6092275383467414, 'lambda_l2': 0.19534422801276774, 'num_leaves': 106, 'feature_fraction': 0.6640914962437607, 'learning_rate': 0.015144860262751412, 'bagging_fraction': 0.6971061460667621, 'bagging_freq': 1, 'min_child_samples': 46, 'max_bin': 203}. Best is trial 4 with value: 10.857697485053373.\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[464]\tvalid_0's l1: 10.8577\n",
      "[I 2025-08-09 11:05:28,648] Trial 4 finished with value: 10.857697485053373 and parameters: {'lambda_l1': 0.6092275383467414, 'lambda_l2': 0.19534422801276774, 'num_leaves': 106, 'feature_fraction': 0.6640914962437607, 'learning_rate': 0.015144860262751412, 'bagging_fraction': 0.6971061460667621, 'bagging_freq': 1, 'min_child_samples': 46, 'max_bin': 203}. Best is trial 4 with value: 10.857697485053373.\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[305]\tvalid_0's l1: 10.8501\n",
      "[I 2025-08-09 11:05:30,049] Trial 5 finished with value: 10.850135370422077 and parameters: {'lambda_l1': 1.325044568707964, 'lambda_l2': 0.6234221521788219, 'num_leaves': 83, 'feature_fraction': 0.7280261676059678, 'learning_rate': 0.01875220945578641, 'bagging_fraction': 0.9817507766587351, 'bagging_freq': 8, 'min_child_samples': 48, 'max_bin': 458}. Best is trial 5 with value: 10.850135370422077.\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[305]\tvalid_0's l1: 10.8501\n",
      "[I 2025-08-09 11:05:30,049] Trial 5 finished with value: 10.850135370422077 and parameters: {'lambda_l1': 1.325044568707964, 'lambda_l2': 0.6234221521788219, 'num_leaves': 83, 'feature_fraction': 0.7280261676059678, 'learning_rate': 0.01875220945578641, 'bagging_fraction': 0.9817507766587351, 'bagging_freq': 8, 'min_child_samples': 48, 'max_bin': 458}. Best is trial 5 with value: 10.850135370422077.\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[711]\tvalid_0's l1: 10.9958\n",
      "[I 2025-08-09 11:05:31,023] Trial 6 finished with value: 10.995796095892699 and parameters: {'lambda_l1': 1.1957999576221703, 'lambda_l2': 1.8437484700462337, 'num_leaves': 22, 'feature_fraction': 0.5175897174514872, 'learning_rate': 0.011662890273931383, 'bagging_fraction': 0.5951981984579586, 'bagging_freq': 4, 'min_child_samples': 17, 'max_bin': 432}. Best is trial 5 with value: 10.850135370422077.\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[711]\tvalid_0's l1: 10.9958\n",
      "[I 2025-08-09 11:05:31,023] Trial 6 finished with value: 10.995796095892699 and parameters: {'lambda_l1': 1.1957999576221703, 'lambda_l2': 1.8437484700462337, 'num_leaves': 22, 'feature_fraction': 0.5175897174514872, 'learning_rate': 0.011662890273931383, 'bagging_fraction': 0.5951981984579586, 'bagging_freq': 4, 'min_child_samples': 17, 'max_bin': 432}. Best is trial 5 with value: 10.850135370422077.\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[72]\tvalid_0's l1: 11.3378\n",
      "[I 2025-08-09 11:05:31,541] Trial 7 finished with value: 11.337804120038898 and parameters: {'lambda_l1': 0.7135066533871786, 'lambda_l2': 0.5618690193747615, 'num_leaves': 86, 'feature_fraction': 0.4845545349848576, 'learning_rate': 0.1530883741573138, 'bagging_fraction': 0.44473038620786254, 'bagging_freq': 10, 'min_child_samples': 40, 'max_bin': 179}. Best is trial 5 with value: 10.850135370422077.\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[72]\tvalid_0's l1: 11.3378\n",
      "[I 2025-08-09 11:05:31,541] Trial 7 finished with value: 11.337804120038898 and parameters: {'lambda_l1': 0.7135066533871786, 'lambda_l2': 0.5618690193747615, 'num_leaves': 86, 'feature_fraction': 0.4845545349848576, 'learning_rate': 0.1530883741573138, 'bagging_fraction': 0.44473038620786254, 'bagging_freq': 10, 'min_child_samples': 40, 'max_bin': 179}. Best is trial 5 with value: 10.850135370422077.\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[41]\tvalid_0's l1: 11.281\n",
      "[I 2025-08-09 11:05:32,073] Trial 8 finished with value: 11.280990481791271 and parameters: {'lambda_l1': 0.011044234247204798, 'lambda_l2': 1.6309228569096683, 'num_leaves': 109, 'feature_fraction': 0.8374043008245924, 'learning_rate': 0.13780336485751998, 'bagging_fraction': 0.44442679104045424, 'bagging_freq': 4, 'min_child_samples': 10, 'max_bin': 446}. Best is trial 5 with value: 10.850135370422077.\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[41]\tvalid_0's l1: 11.281\n",
      "[I 2025-08-09 11:05:32,073] Trial 8 finished with value: 11.280990481791271 and parameters: {'lambda_l1': 0.011044234247204798, 'lambda_l2': 1.6309228569096683, 'num_leaves': 109, 'feature_fraction': 0.8374043008245924, 'learning_rate': 0.13780336485751998, 'bagging_fraction': 0.44442679104045424, 'bagging_freq': 4, 'min_child_samples': 10, 'max_bin': 446}. Best is trial 5 with value: 10.850135370422077.\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[254]\tvalid_0's l1: 11.0206\n",
      "[I 2025-08-09 11:05:32,463] Trial 9 finished with value: 11.020625371684744 and parameters: {'lambda_l1': 1.2465962536551158, 'lambda_l2': 0.6617960497052984, 'num_leaves': 18, 'feature_fraction': 0.5865893930293973, 'learning_rate': 0.030222834756467344, 'bagging_fraction': 0.8377637070028385, 'bagging_freq': 7, 'min_child_samples': 45, 'max_bin': 289}. Best is trial 5 with value: 10.850135370422077.\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[254]\tvalid_0's l1: 11.0206\n",
      "[I 2025-08-09 11:05:32,463] Trial 9 finished with value: 11.020625371684744 and parameters: {'lambda_l1': 1.2465962536551158, 'lambda_l2': 0.6617960497052984, 'num_leaves': 18, 'feature_fraction': 0.5865893930293973, 'learning_rate': 0.030222834756467344, 'bagging_fraction': 0.8377637070028385, 'bagging_freq': 7, 'min_child_samples': 45, 'max_bin': 289}. Best is trial 5 with value: 10.850135370422077.\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[142]\tvalid_0's l1: 11.1428\n",
      "[I 2025-08-09 11:05:33,250] Trial 10 finished with value: 11.142813009718367 and parameters: {'lambda_l1': 1.9255002064579485, 'lambda_l2': 1.1559704609452126, 'num_leaves': 55, 'feature_fraction': 0.9593742051470726, 'learning_rate': 0.060280072870289664, 'bagging_fraction': 0.9445988771695107, 'bagging_freq': 8, 'min_child_samples': 32, 'max_bin': 488}. Best is trial 5 with value: 10.850135370422077.\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[142]\tvalid_0's l1: 11.1428\n",
      "[I 2025-08-09 11:05:33,250] Trial 10 finished with value: 11.142813009718367 and parameters: {'lambda_l1': 1.9255002064579485, 'lambda_l2': 1.1559704609452126, 'num_leaves': 55, 'feature_fraction': 0.9593742051470726, 'learning_rate': 0.060280072870289664, 'bagging_fraction': 0.9445988771695107, 'bagging_freq': 8, 'min_child_samples': 32, 'max_bin': 488}. Best is trial 5 with value: 10.850135370422077.\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[189]\tvalid_0's l1: 10.7515\n",
      "[I 2025-08-09 11:05:33,863] Trial 11 finished with value: 10.751519127182027 and parameters: {'lambda_l1': 0.2511059440930814, 'lambda_l2': 0.05955379583755582, 'num_leaves': 60, 'feature_fraction': 0.6395327254203782, 'learning_rate': 0.05545225037953748, 'bagging_fraction': 0.7321356670023261, 'bagging_freq': 7, 'min_child_samples': 32, 'max_bin': 112}. Best is trial 11 with value: 10.751519127182027.\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[189]\tvalid_0's l1: 10.7515\n",
      "[I 2025-08-09 11:05:33,863] Trial 11 finished with value: 10.751519127182027 and parameters: {'lambda_l1': 0.2511059440930814, 'lambda_l2': 0.05955379583755582, 'num_leaves': 60, 'feature_fraction': 0.6395327254203782, 'learning_rate': 0.05545225037953748, 'bagging_fraction': 0.7321356670023261, 'bagging_freq': 7, 'min_child_samples': 32, 'max_bin': 112}. Best is trial 11 with value: 10.751519127182027.\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[87]\tvalid_0's l1: 10.7105\n",
      "[I 2025-08-09 11:05:34,192] Trial 12 finished with value: 10.71050130838939 and parameters: {'lambda_l1': 0.1199832683280607, 'lambda_l2': 0.2900018255549278, 'num_leaves': 58, 'feature_fraction': 0.6187007206867036, 'learning_rate': 0.06909313164440407, 'bagging_fraction': 0.8534625355196006, 'bagging_freq': 7, 'min_child_samples': 32, 'max_bin': 102}. Best is trial 12 with value: 10.71050130838939.\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[87]\tvalid_0's l1: 10.7105\n",
      "[I 2025-08-09 11:05:34,192] Trial 12 finished with value: 10.71050130838939 and parameters: {'lambda_l1': 0.1199832683280607, 'lambda_l2': 0.2900018255549278, 'num_leaves': 58, 'feature_fraction': 0.6187007206867036, 'learning_rate': 0.06909313164440407, 'bagging_fraction': 0.8534625355196006, 'bagging_freq': 7, 'min_child_samples': 32, 'max_bin': 102}. Best is trial 12 with value: 10.71050130838939.\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[71]\tvalid_0's l1: 10.7535\n",
      "[I 2025-08-09 11:05:34,489] Trial 13 finished with value: 10.75351552332164 and parameters: {'lambda_l1': 0.023392341845768494, 'lambda_l2': 0.2828770553955577, 'num_leaves': 58, 'feature_fraction': 0.6116436969183914, 'learning_rate': 0.0723757756427942, 'bagging_fraction': 0.8164991658696965, 'bagging_freq': 7, 'min_child_samples': 30, 'max_bin': 107}. Best is trial 12 with value: 10.71050130838939.\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[19]\tvalid_0's l1: 11.3125\n",
      "[I 2025-08-09 11:05:34,645] Trial 14 finished with value: 11.312467481115755 and parameters: {'lambda_l1': 0.34743838790697035, 'lambda_l2': 0.02616620965234223, 'num_leaves': 45, 'feature_fraction': 0.405119828707704, 'learning_rate': 0.29565563003428347, 'bagging_fraction': 0.8062729073246514, 'bagging_freq': 6, 'min_child_samples': 23, 'max_bin': 118}. Best is trial 12 with value: 10.71050130838939.\n",
      "Early stopping, best iteration is:\n",
      "[71]\tvalid_0's l1: 10.7535\n",
      "[I 2025-08-09 11:05:34,489] Trial 13 finished with value: 10.75351552332164 and parameters: {'lambda_l1': 0.023392341845768494, 'lambda_l2': 0.2828770553955577, 'num_leaves': 58, 'feature_fraction': 0.6116436969183914, 'learning_rate': 0.0723757756427942, 'bagging_fraction': 0.8164991658696965, 'bagging_freq': 7, 'min_child_samples': 30, 'max_bin': 107}. Best is trial 12 with value: 10.71050130838939.\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[19]\tvalid_0's l1: 11.3125\n",
      "[I 2025-08-09 11:05:34,645] Trial 14 finished with value: 11.312467481115755 and parameters: {'lambda_l1': 0.34743838790697035, 'lambda_l2': 0.02616620965234223, 'num_leaves': 45, 'feature_fraction': 0.405119828707704, 'learning_rate': 0.29565563003428347, 'bagging_fraction': 0.8062729073246514, 'bagging_freq': 6, 'min_child_samples': 23, 'max_bin': 118}. Best is trial 12 with value: 10.71050130838939.\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[184]\tvalid_0's l1: 10.8684\n",
      "[I 2025-08-09 11:05:35,342] Trial 15 finished with value: 10.868437916019381 and parameters: {'lambda_l1': 0.3315146707433886, 'lambda_l2': 0.3864382510903843, 'num_leaves': 67, 'feature_fraction': 0.6329624047403581, 'learning_rate': 0.04241036621398397, 'bagging_fraction': 0.742584879154286, 'bagging_freq': 9, 'min_child_samples': 35, 'max_bin': 226}. Best is trial 12 with value: 10.71050130838939.\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[184]\tvalid_0's l1: 10.8684\n",
      "[I 2025-08-09 11:05:35,342] Trial 15 finished with value: 10.868437916019381 and parameters: {'lambda_l1': 0.3315146707433886, 'lambda_l2': 0.3864382510903843, 'num_leaves': 67, 'feature_fraction': 0.6329624047403581, 'learning_rate': 0.04241036621398397, 'bagging_fraction': 0.742584879154286, 'bagging_freq': 9, 'min_child_samples': 35, 'max_bin': 226}. Best is trial 12 with value: 10.71050130838939.\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[147]\tvalid_0's l1: 10.8507\n",
      "[I 2025-08-09 11:05:35,746] Trial 16 finished with value: 10.850738552180665 and parameters: {'lambda_l1': 0.29351365603538637, 'lambda_l2': 0.901424486373648, 'num_leaves': 40, 'feature_fraction': 0.552877794423218, 'learning_rate': 0.09457692440469626, 'bagging_fraction': 0.9122427333292663, 'bagging_freq': 6, 'min_child_samples': 27, 'max_bin': 137}. Best is trial 12 with value: 10.71050130838939.\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[147]\tvalid_0's l1: 10.8507\n",
      "[I 2025-08-09 11:05:35,746] Trial 16 finished with value: 10.850738552180665 and parameters: {'lambda_l1': 0.29351365603538637, 'lambda_l2': 0.901424486373648, 'num_leaves': 40, 'feature_fraction': 0.552877794423218, 'learning_rate': 0.09457692440469626, 'bagging_fraction': 0.9122427333292663, 'bagging_freq': 6, 'min_child_samples': 27, 'max_bin': 137}. Best is trial 12 with value: 10.71050130838939.\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[119]\tvalid_0's l1: 11.0156\n",
      "[I 2025-08-09 11:05:36,258] Trial 17 finished with value: 11.015555505125864 and parameters: {'lambda_l1': 0.4860755758565186, 'lambda_l2': 0.8977837367900416, 'num_leaves': 70, 'feature_fraction': 0.6945988817891031, 'learning_rate': 0.04621755506644064, 'bagging_fraction': 0.7148817639713086, 'bagging_freq': 8, 'min_child_samples': 36, 'max_bin': 150}. Best is trial 12 with value: 10.71050130838939.\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[119]\tvalid_0's l1: 11.0156\n",
      "[I 2025-08-09 11:05:36,258] Trial 17 finished with value: 11.015555505125864 and parameters: {'lambda_l1': 0.4860755758565186, 'lambda_l2': 0.8977837367900416, 'num_leaves': 70, 'feature_fraction': 0.6945988817891031, 'learning_rate': 0.04621755506644064, 'bagging_fraction': 0.7148817639713086, 'bagging_freq': 8, 'min_child_samples': 36, 'max_bin': 150}. Best is trial 12 with value: 10.71050130838939.\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[57]\tvalid_0's l1: 11.0883\n",
      "[I 2025-08-09 11:05:36,509] Trial 18 finished with value: 11.088256216526515 and parameters: {'lambda_l1': 0.11570169712787767, 'lambda_l2': 0.3477253241312479, 'num_leaves': 36, 'feature_fraction': 0.8090059331954651, 'learning_rate': 0.10163450321393216, 'bagging_fraction': 0.8961203865795027, 'bagging_freq': 4, 'min_child_samples': 23, 'max_bin': 260}. Best is trial 12 with value: 10.71050130838939.\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[57]\tvalid_0's l1: 11.0883\n",
      "[I 2025-08-09 11:05:36,509] Trial 18 finished with value: 11.088256216526515 and parameters: {'lambda_l1': 0.11570169712787767, 'lambda_l2': 0.3477253241312479, 'num_leaves': 36, 'feature_fraction': 0.8090059331954651, 'learning_rate': 0.10163450321393216, 'bagging_fraction': 0.8961203865795027, 'bagging_freq': 4, 'min_child_samples': 23, 'max_bin': 260}. Best is trial 12 with value: 10.71050130838939.\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[186]\tvalid_0's l1: 10.8858\n",
      "[I 2025-08-09 11:05:37,785] Trial 19 finished with value: 10.885767399003294 and parameters: {'lambda_l1': 1.594995700892736, 'lambda_l2': 0.01975423588473521, 'num_leaves': 134, 'feature_fraction': 0.42592050972458867, 'learning_rate': 0.03567509095739717, 'bagging_fraction': 0.6445976621655365, 'bagging_freq': 5, 'min_child_samples': 25, 'max_bin': 346}. Best is trial 12 with value: 10.71050130838939.\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[186]\tvalid_0's l1: 10.8858\n",
      "[I 2025-08-09 11:05:37,785] Trial 19 finished with value: 10.885767399003294 and parameters: {'lambda_l1': 1.594995700892736, 'lambda_l2': 0.01975423588473521, 'num_leaves': 134, 'feature_fraction': 0.42592050972458867, 'learning_rate': 0.03567509095739717, 'bagging_fraction': 0.6445976621655365, 'bagging_freq': 5, 'min_child_samples': 25, 'max_bin': 346}. Best is trial 12 with value: 10.71050130838939.\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[28]\tvalid_0's l1: 11.4533\n",
      "[I 2025-08-09 11:05:38,067] Trial 20 finished with value: 11.453280748443717 and parameters: {'lambda_l1': 0.2202783920423806, 'lambda_l2': 1.5232234730543914, 'num_leaves': 70, 'feature_fraction': 0.6665025934077063, 'learning_rate': 0.23492026021785897, 'bagging_fraction': 0.7791653185021064, 'bagging_freq': 7, 'min_child_samples': 5, 'max_bin': 239}. Best is trial 12 with value: 10.71050130838939.\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[28]\tvalid_0's l1: 11.4533\n",
      "[I 2025-08-09 11:05:38,067] Trial 20 finished with value: 11.453280748443717 and parameters: {'lambda_l1': 0.2202783920423806, 'lambda_l2': 1.5232234730543914, 'num_leaves': 70, 'feature_fraction': 0.6665025934077063, 'learning_rate': 0.23492026021785897, 'bagging_fraction': 0.7791653185021064, 'bagging_freq': 7, 'min_child_samples': 5, 'max_bin': 239}. Best is trial 12 with value: 10.71050130838939.\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[79]\tvalid_0's l1: 10.7273\n",
      "[I 2025-08-09 11:05:38,394] Trial 21 finished with value: 10.727295632552385 and parameters: {'lambda_l1': 0.00031427083671726683, 'lambda_l2': 0.3234941041937786, 'num_leaves': 53, 'feature_fraction': 0.6044498055044591, 'learning_rate': 0.06845325331255803, 'bagging_fraction': 0.8636840710551087, 'bagging_freq': 7, 'min_child_samples': 31, 'max_bin': 102}. Best is trial 12 with value: 10.71050130838939.\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[79]\tvalid_0's l1: 10.7273\n",
      "[I 2025-08-09 11:05:38,394] Trial 21 finished with value: 10.727295632552385 and parameters: {'lambda_l1': 0.00031427083671726683, 'lambda_l2': 0.3234941041937786, 'num_leaves': 53, 'feature_fraction': 0.6044498055044591, 'learning_rate': 0.06845325331255803, 'bagging_fraction': 0.8636840710551087, 'bagging_freq': 7, 'min_child_samples': 31, 'max_bin': 102}. Best is trial 12 with value: 10.71050130838939.\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[117]\tvalid_0's l1: 10.7215\n",
      "[I 2025-08-09 11:05:38,816] Trial 22 finished with value: 10.721451790582325 and parameters: {'lambda_l1': 0.5334453390958273, 'lambda_l2': 0.20209107659423764, 'num_leaves': 53, 'feature_fraction': 0.5785693076245654, 'learning_rate': 0.07075105704134364, 'bagging_fraction': 0.8497509362078095, 'bagging_freq': 9, 'min_child_samples': 35, 'max_bin': 107}. Best is trial 12 with value: 10.71050130838939.\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[117]\tvalid_0's l1: 10.7215\n",
      "[I 2025-08-09 11:05:38,816] Trial 22 finished with value: 10.721451790582325 and parameters: {'lambda_l1': 0.5334453390958273, 'lambda_l2': 0.20209107659423764, 'num_leaves': 53, 'feature_fraction': 0.5785693076245654, 'learning_rate': 0.07075105704134364, 'bagging_fraction': 0.8497509362078095, 'bagging_freq': 9, 'min_child_samples': 35, 'max_bin': 107}. Best is trial 12 with value: 10.71050130838939.\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[84]\tvalid_0's l1: 10.9638\n",
      "[I 2025-08-09 11:05:39,094] Trial 23 finished with value: 10.963802814726657 and parameters: {'lambda_l1': 0.46963171188454544, 'lambda_l2': 0.4332097004135722, 'num_leaves': 34, 'feature_fraction': 0.5662274996770582, 'learning_rate': 0.08149272763461118, 'bagging_fraction': 0.8707417699902844, 'bagging_freq': 9, 'min_child_samples': 36, 'max_bin': 155}. Best is trial 12 with value: 10.71050130838939.\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[84]\tvalid_0's l1: 10.9638\n",
      "[I 2025-08-09 11:05:39,094] Trial 23 finished with value: 10.963802814726657 and parameters: {'lambda_l1': 0.46963171188454544, 'lambda_l2': 0.4332097004135722, 'num_leaves': 34, 'feature_fraction': 0.5662274996770582, 'learning_rate': 0.08149272763461118, 'bagging_fraction': 0.8707417699902844, 'bagging_freq': 9, 'min_child_samples': 36, 'max_bin': 155}. Best is trial 12 with value: 10.71050130838939.\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[62]\tvalid_0's l1: 10.9587\n",
      "[I 2025-08-09 11:05:39,384] Trial 24 finished with value: 10.958716655134715 and parameters: {'lambda_l1': 0.5007550333685669, 'lambda_l2': 0.7752638014947741, 'num_leaves': 47, 'feature_fraction': 0.5251924653256786, 'learning_rate': 0.12962242877211058, 'bagging_fraction': 0.9777417848888165, 'bagging_freq': 9, 'min_child_samples': 39, 'max_bin': 105}. Best is trial 12 with value: 10.71050130838939.\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[62]\tvalid_0's l1: 10.9587\n",
      "[I 2025-08-09 11:05:39,384] Trial 24 finished with value: 10.958716655134715 and parameters: {'lambda_l1': 0.5007550333685669, 'lambda_l2': 0.7752638014947741, 'num_leaves': 47, 'feature_fraction': 0.5251924653256786, 'learning_rate': 0.12962242877211058, 'bagging_fraction': 0.9777417848888165, 'bagging_freq': 9, 'min_child_samples': 39, 'max_bin': 105}. Best is trial 12 with value: 10.71050130838939.\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[91]\tvalid_0's l1: 11.1454\n",
      "[I 2025-08-09 11:05:39,646] Trial 25 finished with value: 11.145363468265685 and parameters: {'lambda_l1': 0.14148172668419717, 'lambda_l2': 0.2226081867221815, 'num_leaves': 29, 'feature_fraction': 0.5998408578961011, 'learning_rate': 0.06525590723195313, 'bagging_fraction': 0.8634106652710176, 'bagging_freq': 8, 'min_child_samples': 28, 'max_bin': 175}. Best is trial 12 with value: 10.71050130838939.\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[91]\tvalid_0's l1: 11.1454\n",
      "[I 2025-08-09 11:05:39,646] Trial 25 finished with value: 11.145363468265685 and parameters: {'lambda_l1': 0.14148172668419717, 'lambda_l2': 0.2226081867221815, 'num_leaves': 29, 'feature_fraction': 0.5998408578961011, 'learning_rate': 0.06525590723195313, 'bagging_fraction': 0.8634106652710176, 'bagging_freq': 8, 'min_child_samples': 28, 'max_bin': 175}. Best is trial 12 with value: 10.71050130838939.\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[34]\tvalid_0's l1: 11.1769\n",
      "[I 2025-08-09 11:05:39,880] Trial 26 finished with value: 11.176865307959282 and parameters: {'lambda_l1': 0.013298631576814088, 'lambda_l2': 0.4218452277145693, 'num_leaves': 52, 'feature_fraction': 0.453306103530419, 'learning_rate': 0.18917139297404936, 'bagging_fraction': 0.9296438710556614, 'bagging_freq': 6, 'min_child_samples': 20, 'max_bin': 152}. Best is trial 12 with value: 10.71050130838939.\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[34]\tvalid_0's l1: 11.1769\n",
      "[I 2025-08-09 11:05:39,880] Trial 26 finished with value: 11.176865307959282 and parameters: {'lambda_l1': 0.013298631576814088, 'lambda_l2': 0.4218452277145693, 'num_leaves': 52, 'feature_fraction': 0.453306103530419, 'learning_rate': 0.18917139297404936, 'bagging_fraction': 0.9296438710556614, 'bagging_freq': 6, 'min_child_samples': 20, 'max_bin': 152}. Best is trial 12 with value: 10.71050130838939.\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[63]\tvalid_0's l1: 10.9305\n",
      "[I 2025-08-09 11:05:40,278] Trial 27 finished with value: 10.930525557020214 and parameters: {'lambda_l1': 0.3955631819530874, 'lambda_l2': 0.17252239635449207, 'num_leaves': 73, 'feature_fraction': 0.7033456082463543, 'learning_rate': 0.10828923193135206, 'bagging_fraction': 0.7643435429374401, 'bagging_freq': 9, 'min_child_samples': 33, 'max_bin': 205}. Best is trial 12 with value: 10.71050130838939.\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[63]\tvalid_0's l1: 10.9305\n",
      "[I 2025-08-09 11:05:40,278] Trial 27 finished with value: 10.930525557020214 and parameters: {'lambda_l1': 0.3955631819530874, 'lambda_l2': 0.17252239635449207, 'num_leaves': 73, 'feature_fraction': 0.7033456082463543, 'learning_rate': 0.10828923193135206, 'bagging_fraction': 0.7643435429374401, 'bagging_freq': 9, 'min_child_samples': 33, 'max_bin': 205}. Best is trial 12 with value: 10.71050130838939.\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[469]\tvalid_0's l1: 10.7653\n",
      "[I 2025-08-09 11:05:40,664] Trial 28 finished with value: 10.765283181178416 and parameters: {'lambda_l1': 0.6760677960781725, 'lambda_l2': 0.4973641181707017, 'num_leaves': 10, 'feature_fraction': 0.5360984258382611, 'learning_rate': 0.04663485334046273, 'bagging_fraction': 0.8506355546544803, 'bagging_freq': 10, 'min_child_samples': 28, 'max_bin': 135}. Best is trial 12 with value: 10.71050130838939.\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[469]\tvalid_0's l1: 10.7653\n",
      "[I 2025-08-09 11:05:40,664] Trial 28 finished with value: 10.765283181178416 and parameters: {'lambda_l1': 0.6760677960781725, 'lambda_l2': 0.4973641181707017, 'num_leaves': 10, 'feature_fraction': 0.5360984258382611, 'learning_rate': 0.04663485334046273, 'bagging_fraction': 0.8506355546544803, 'bagging_freq': 10, 'min_child_samples': 28, 'max_bin': 135}. Best is trial 12 with value: 10.71050130838939.\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[99]\tvalid_0's l1: 11.1743\n",
      "[I 2025-08-09 11:05:41,313] Trial 29 finished with value: 11.174321637395613 and parameters: {'lambda_l1': 0.8426134881744979, 'lambda_l2': 0.7441959260394615, 'num_leaves': 90, 'feature_fraction': 0.7467051118130028, 'learning_rate': 0.07920297602298573, 'bagging_fraction': 0.6699011875812145, 'bagging_freq': 8, 'min_child_samples': 43, 'max_bin': 359}. Best is trial 12 with value: 10.71050130838939.\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[99]\tvalid_0's l1: 11.1743\n",
      "[I 2025-08-09 11:05:41,313] Trial 29 finished with value: 11.174321637395613 and parameters: {'lambda_l1': 0.8426134881744979, 'lambda_l2': 0.7441959260394615, 'num_leaves': 90, 'feature_fraction': 0.7467051118130028, 'learning_rate': 0.07920297602298573, 'bagging_fraction': 0.6699011875812145, 'bagging_freq': 8, 'min_child_samples': 43, 'max_bin': 359}. Best is trial 12 with value: 10.71050130838939.\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[243]\tvalid_0's l1: 10.6649\n",
      "[I 2025-08-09 11:05:42,248] Trial 30 finished with value: 10.66494409827414 and parameters: {'lambda_l1': 0.16807654079447742, 'lambda_l2': 1.2664299357452182, 'num_leaves': 77, 'feature_fraction': 0.7893773787371509, 'learning_rate': 0.0332473953956804, 'bagging_fraction': 0.8921584874563345, 'bagging_freq': 7, 'min_child_samples': 38, 'max_bin': 103}. Best is trial 30 with value: 10.66494409827414.\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[243]\tvalid_0's l1: 10.6649\n",
      "[I 2025-08-09 11:05:42,248] Trial 30 finished with value: 10.66494409827414 and parameters: {'lambda_l1': 0.16807654079447742, 'lambda_l2': 1.2664299357452182, 'num_leaves': 77, 'feature_fraction': 0.7893773787371509, 'learning_rate': 0.0332473953956804, 'bagging_fraction': 0.8921584874563345, 'bagging_freq': 7, 'min_child_samples': 38, 'max_bin': 103}. Best is trial 30 with value: 10.66494409827414.\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[236]\tvalid_0's l1: 10.4825\n",
      "[I 2025-08-09 11:05:43,216] Trial 31 finished with value: 10.482549487468033 and parameters: {'lambda_l1': 0.14363173258604017, 'lambda_l2': 1.2583165690261955, 'num_leaves': 77, 'feature_fraction': 0.8132527310963572, 'learning_rate': 0.033492688307476565, 'bagging_fraction': 0.8961869915583215, 'bagging_freq': 7, 'min_child_samples': 39, 'max_bin': 100}. Best is trial 31 with value: 10.482549487468033.\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[236]\tvalid_0's l1: 10.4825\n",
      "[I 2025-08-09 11:05:43,216] Trial 31 finished with value: 10.482549487468033 and parameters: {'lambda_l1': 0.14363173258604017, 'lambda_l2': 1.2583165690261955, 'num_leaves': 77, 'feature_fraction': 0.8132527310963572, 'learning_rate': 0.033492688307476565, 'bagging_fraction': 0.8961869915583215, 'bagging_freq': 7, 'min_child_samples': 39, 'max_bin': 100}. Best is trial 31 with value: 10.482549487468033.\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[285]\tvalid_0's l1: 10.9746\n",
      "[I 2025-08-09 11:05:44,326] Trial 32 finished with value: 10.9746106507656 and parameters: {'lambda_l1': 0.19727564210488502, 'lambda_l2': 1.2999455472027623, 'num_leaves': 79, 'feature_fraction': 0.8872090749212163, 'learning_rate': 0.024966882908214645, 'bagging_fraction': 0.9982473431986242, 'bagging_freq': 6, 'min_child_samples': 37, 'max_bin': 139}. Best is trial 31 with value: 10.482549487468033.\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[285]\tvalid_0's l1: 10.9746\n",
      "[I 2025-08-09 11:05:44,326] Trial 32 finished with value: 10.9746106507656 and parameters: {'lambda_l1': 0.19727564210488502, 'lambda_l2': 1.2999455472027623, 'num_leaves': 79, 'feature_fraction': 0.8872090749212163, 'learning_rate': 0.024966882908214645, 'bagging_fraction': 0.9982473431986242, 'bagging_freq': 6, 'min_child_samples': 37, 'max_bin': 139}. Best is trial 31 with value: 10.482549487468033.\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[238]\tvalid_0's l1: 10.881\n",
      "[I 2025-08-09 11:05:45,979] Trial 33 finished with value: 10.880951053154412 and parameters: {'lambda_l1': 0.5920893879357874, 'lambda_l2': 1.4249005286637262, 'num_leaves': 124, 'feature_fraction': 0.7901094823990581, 'learning_rate': 0.034793440984927634, 'bagging_fraction': 0.9024483771317474, 'bagging_freq': 5, 'min_child_samples': 42, 'max_bin': 378}. Best is trial 31 with value: 10.482549487468033.\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[238]\tvalid_0's l1: 10.881\n",
      "[I 2025-08-09 11:05:45,979] Trial 33 finished with value: 10.880951053154412 and parameters: {'lambda_l1': 0.5920893879357874, 'lambda_l2': 1.4249005286637262, 'num_leaves': 124, 'feature_fraction': 0.7901094823990581, 'learning_rate': 0.034793440984927634, 'bagging_fraction': 0.9024483771317474, 'bagging_freq': 5, 'min_child_samples': 42, 'max_bin': 378}. Best is trial 31 with value: 10.482549487468033.\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[237]\tvalid_0's l1: 11.1102\n",
      "[I 2025-08-09 11:05:47,046] Trial 34 finished with value: 11.110152457144983 and parameters: {'lambda_l1': 1.0050676413461606, 'lambda_l2': 1.0940005453559676, 'num_leaves': 92, 'feature_fraction': 0.8700996919179451, 'learning_rate': 0.02335799263218434, 'bagging_fraction': 0.9477382472777189, 'bagging_freq': 7, 'min_child_samples': 39, 'max_bin': 170}. Best is trial 31 with value: 10.482549487468033.\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[237]\tvalid_0's l1: 11.1102\n",
      "[I 2025-08-09 11:05:47,046] Trial 34 finished with value: 11.110152457144983 and parameters: {'lambda_l1': 1.0050676413461606, 'lambda_l2': 1.0940005453559676, 'num_leaves': 92, 'feature_fraction': 0.8700996919179451, 'learning_rate': 0.02335799263218434, 'bagging_fraction': 0.9477382472777189, 'bagging_freq': 7, 'min_child_samples': 39, 'max_bin': 170}. Best is trial 31 with value: 10.482549487468033.\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[168]\tvalid_0's l1: 10.691\n",
      "[I 2025-08-09 11:05:48,009] Trial 35 finished with value: 10.69097784482253 and parameters: {'lambda_l1': 0.16417472690820503, 'lambda_l2': 1.2890318213460836, 'num_leaves': 100, 'feature_fraction': 0.9656063914879107, 'learning_rate': 0.03922280641257788, 'bagging_fraction': 0.7948185854297374, 'bagging_freq': 3, 'min_child_samples': 34, 'max_bin': 202}. Best is trial 31 with value: 10.482549487468033.\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[168]\tvalid_0's l1: 10.691\n",
      "[I 2025-08-09 11:05:48,009] Trial 35 finished with value: 10.69097784482253 and parameters: {'lambda_l1': 0.16417472690820503, 'lambda_l2': 1.2890318213460836, 'num_leaves': 100, 'feature_fraction': 0.9656063914879107, 'learning_rate': 0.03922280641257788, 'bagging_fraction': 0.7948185854297374, 'bagging_freq': 3, 'min_child_samples': 34, 'max_bin': 202}. Best is trial 31 with value: 10.482549487468033.\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[195]\tvalid_0's l1: 11.0936\n",
      "[I 2025-08-09 11:05:49,226] Trial 36 finished with value: 11.09355707772322 and parameters: {'lambda_l1': 0.15645484015402278, 'lambda_l2': 1.3378419833276518, 'num_leaves': 121, 'feature_fraction': 0.9829943807273317, 'learning_rate': 0.031121810540748824, 'bagging_fraction': 0.8030070165561827, 'bagging_freq': 3, 'min_child_samples': 47, 'max_bin': 191}. Best is trial 31 with value: 10.482549487468033.\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[195]\tvalid_0's l1: 11.0936\n",
      "[I 2025-08-09 11:05:49,226] Trial 36 finished with value: 11.09355707772322 and parameters: {'lambda_l1': 0.15645484015402278, 'lambda_l2': 1.3378419833276518, 'num_leaves': 121, 'feature_fraction': 0.9829943807273317, 'learning_rate': 0.031121810540748824, 'bagging_fraction': 0.8030070165561827, 'bagging_freq': 3, 'min_child_samples': 47, 'max_bin': 191}. Best is trial 31 with value: 10.482549487468033.\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[474]\tvalid_0's l1: 10.9619\n",
      "[I 2025-08-09 11:05:51,183] Trial 37 finished with value: 10.961859782088556 and parameters: {'lambda_l1': 0.8388588193902949, 'lambda_l2': 1.6814742153278153, 'num_leaves': 98, 'feature_fraction': 0.9296937750366618, 'learning_rate': 0.015156776056270749, 'bagging_fraction': 0.5678898196913976, 'bagging_freq': 1, 'min_child_samples': 50, 'max_bin': 231}. Best is trial 31 with value: 10.482549487468033.\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[474]\tvalid_0's l1: 10.9619\n",
      "[I 2025-08-09 11:05:51,183] Trial 37 finished with value: 10.961859782088556 and parameters: {'lambda_l1': 0.8388588193902949, 'lambda_l2': 1.6814742153278153, 'num_leaves': 98, 'feature_fraction': 0.9296937750366618, 'learning_rate': 0.015156776056270749, 'bagging_fraction': 0.5678898196913976, 'bagging_freq': 1, 'min_child_samples': 50, 'max_bin': 231}. Best is trial 31 with value: 10.482549487468033.\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[149]\tvalid_0's l1: 10.8303\n",
      "[I 2025-08-09 11:05:52,103] Trial 38 finished with value: 10.830333696838121 and parameters: {'lambda_l1': 0.4135582180720575, 'lambda_l2': 1.0423041909947919, 'num_leaves': 99, 'feature_fraction': 0.853207023771392, 'learning_rate': 0.03978501406559434, 'bagging_fraction': 0.780092888115533, 'bagging_freq': 2, 'min_child_samples': 38, 'max_bin': 272}. Best is trial 31 with value: 10.482549487468033.\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[149]\tvalid_0's l1: 10.8303\n",
      "[I 2025-08-09 11:05:52,103] Trial 38 finished with value: 10.830333696838121 and parameters: {'lambda_l1': 0.4135582180720575, 'lambda_l2': 1.0423041909947919, 'num_leaves': 99, 'feature_fraction': 0.853207023771392, 'learning_rate': 0.03978501406559434, 'bagging_fraction': 0.780092888115533, 'bagging_freq': 2, 'min_child_samples': 38, 'max_bin': 272}. Best is trial 31 with value: 10.482549487468033.\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[260]\tvalid_0's l1: 10.9417\n",
      "[I 2025-08-09 11:05:53,532] Trial 39 finished with value: 10.941713344490497 and parameters: {'lambda_l1': 0.14953989302724002, 'lambda_l2': 1.23653201119548, 'num_leaves': 102, 'feature_fraction': 0.9230859700903901, 'learning_rate': 0.021737183770285162, 'bagging_fraction': 0.8902823632617471, 'bagging_freq': 5, 'min_child_samples': 41, 'max_bin': 322}. Best is trial 31 with value: 10.482549487468033.\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[260]\tvalid_0's l1: 10.9417\n",
      "[I 2025-08-09 11:05:53,532] Trial 39 finished with value: 10.941713344490497 and parameters: {'lambda_l1': 0.14953989302724002, 'lambda_l2': 1.23653201119548, 'num_leaves': 102, 'feature_fraction': 0.9230859700903901, 'learning_rate': 0.021737183770285162, 'bagging_fraction': 0.8902823632617471, 'bagging_freq': 5, 'min_child_samples': 41, 'max_bin': 322}. Best is trial 31 with value: 10.482549487468033.\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[273]\tvalid_0's l1: 10.8233\n",
      "[I 2025-08-09 11:05:54,659] Trial 40 finished with value: 10.823336332695714 and parameters: {'lambda_l1': 0.30921881413256086, 'lambda_l2': 1.976632932553553, 'num_leaves': 79, 'feature_fraction': 0.786137190295181, 'learning_rate': 0.02698331529232657, 'bagging_fraction': 0.8253555759896163, 'bagging_freq': 3, 'min_child_samples': 43, 'max_bin': 197}. Best is trial 31 with value: 10.482549487468033.\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[273]\tvalid_0's l1: 10.8233\n",
      "[I 2025-08-09 11:05:54,659] Trial 40 finished with value: 10.823336332695714 and parameters: {'lambda_l1': 0.30921881413256086, 'lambda_l2': 1.976632932553553, 'num_leaves': 79, 'feature_fraction': 0.786137190295181, 'learning_rate': 0.02698331529232657, 'bagging_fraction': 0.8253555759896163, 'bagging_freq': 3, 'min_child_samples': 43, 'max_bin': 197}. Best is trial 31 with value: 10.482549487468033.\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[167]\tvalid_0's l1: 10.7899\n",
      "[I 2025-08-09 11:05:55,275] Trial 41 finished with value: 10.789863812799306 and parameters: {'lambda_l1': 0.5424140413724772, 'lambda_l2': 1.421382809724007, 'num_leaves': 65, 'feature_fraction': 0.8276990147058599, 'learning_rate': 0.0492609212192105, 'bagging_fraction': 0.9598221915414151, 'bagging_freq': 8, 'min_child_samples': 34, 'max_bin': 130}. Best is trial 31 with value: 10.482549487468033.\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[167]\tvalid_0's l1: 10.7899\n",
      "[I 2025-08-09 11:05:55,275] Trial 41 finished with value: 10.789863812799306 and parameters: {'lambda_l1': 0.5424140413724772, 'lambda_l2': 1.421382809724007, 'num_leaves': 65, 'feature_fraction': 0.8276990147058599, 'learning_rate': 0.0492609212192105, 'bagging_fraction': 0.9598221915414151, 'bagging_freq': 8, 'min_child_samples': 34, 'max_bin': 130}. Best is trial 31 with value: 10.482549487468033.\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[108]\tvalid_0's l1: 11.0183\n",
      "[I 2025-08-09 11:05:55,852] Trial 42 finished with value: 11.01831442704469 and parameters: {'lambda_l1': 0.09188982768913816, 'lambda_l2': 1.5770537331866938, 'num_leaves': 85, 'feature_fraction': 0.7435213626348423, 'learning_rate': 0.05334988198425112, 'bagging_fraction': 0.9215109516684951, 'bagging_freq': 6, 'min_child_samples': 30, 'max_bin': 166}. Best is trial 31 with value: 10.482549487468033.\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[108]\tvalid_0's l1: 11.0183\n",
      "[I 2025-08-09 11:05:55,852] Trial 42 finished with value: 11.01831442704469 and parameters: {'lambda_l1': 0.09188982768913816, 'lambda_l2': 1.5770537331866938, 'num_leaves': 85, 'feature_fraction': 0.7435213626348423, 'learning_rate': 0.05334988198425112, 'bagging_fraction': 0.9215109516684951, 'bagging_freq': 6, 'min_child_samples': 30, 'max_bin': 166}. Best is trial 31 with value: 10.482549487468033.\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[182]\tvalid_0's l1: 10.8046\n",
      "[I 2025-08-09 11:05:56,556] Trial 43 finished with value: 10.804641959879856 and parameters: {'lambda_l1': 0.23625267551927737, 'lambda_l2': 1.7558907978575395, 'num_leaves': 74, 'feature_fraction': 0.6657534887518416, 'learning_rate': 0.03828646458397878, 'bagging_fraction': 0.8357433150343524, 'bagging_freq': 10, 'min_child_samples': 34, 'max_bin': 121}. Best is trial 31 with value: 10.482549487468033.\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[182]\tvalid_0's l1: 10.8046\n",
      "[I 2025-08-09 11:05:56,556] Trial 43 finished with value: 10.804641959879856 and parameters: {'lambda_l1': 0.23625267551927737, 'lambda_l2': 1.7558907978575395, 'num_leaves': 74, 'feature_fraction': 0.6657534887518416, 'learning_rate': 0.03828646458397878, 'bagging_fraction': 0.8357433150343524, 'bagging_freq': 10, 'min_child_samples': 34, 'max_bin': 121}. Best is trial 31 with value: 10.482549487468033.\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[260]\tvalid_0's l1: 10.4933\n",
      "[I 2025-08-09 11:05:57,404] Trial 44 finished with value: 10.49325445309575 and parameters: {'lambda_l1': 1.0969684153711727, 'lambda_l2': 1.1963424002174028, 'num_leaves': 65, 'feature_fraction': 0.7117160631273314, 'learning_rate': 0.03174363086954893, 'bagging_fraction': 0.8795741465288001, 'bagging_freq': 3, 'min_child_samples': 45, 'max_bin': 100}. Best is trial 31 with value: 10.482549487468033.\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[260]\tvalid_0's l1: 10.4933\n",
      "[I 2025-08-09 11:05:57,404] Trial 44 finished with value: 10.49325445309575 and parameters: {'lambda_l1': 1.0969684153711727, 'lambda_l2': 1.1963424002174028, 'num_leaves': 65, 'feature_fraction': 0.7117160631273314, 'learning_rate': 0.03174363086954893, 'bagging_fraction': 0.8795741465288001, 'bagging_freq': 3, 'min_child_samples': 45, 'max_bin': 100}. Best is trial 31 with value: 10.482549487468033.\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[235]\tvalid_0's l1: 10.8568\n",
      "[I 2025-08-09 11:05:58,752] Trial 45 finished with value: 10.85679581344107 and parameters: {'lambda_l1': 1.0918392446259202, 'lambda_l2': 1.1934256429421188, 'num_leaves': 115, 'feature_fraction': 0.6881303694529266, 'learning_rate': 0.030253003725649097, 'bagging_fraction': 0.8812111589691725, 'bagging_freq': 3, 'min_child_samples': 45, 'max_bin': 122}. Best is trial 31 with value: 10.482549487468033.\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[235]\tvalid_0's l1: 10.8568\n",
      "[I 2025-08-09 11:05:58,752] Trial 45 finished with value: 10.85679581344107 and parameters: {'lambda_l1': 1.0918392446259202, 'lambda_l2': 1.1934256429421188, 'num_leaves': 115, 'feature_fraction': 0.6881303694529266, 'learning_rate': 0.030253003725649097, 'bagging_fraction': 0.8812111589691725, 'bagging_freq': 3, 'min_child_samples': 45, 'max_bin': 122}. Best is trial 31 with value: 10.482549487468033.\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[856]\tvalid_0's l1: 10.5289\n",
      "[I 2025-08-09 11:06:00,915] Trial 46 finished with value: 10.528899390145236 and parameters: {'lambda_l1': 1.0977759735440717, 'lambda_l2': 0.9128523956658485, 'num_leaves': 60, 'feature_fraction': 0.76554640635376, 'learning_rate': 0.011294548070060919, 'bagging_fraction': 0.7889908568110097, 'bagging_freq': 1, 'min_child_samples': 47, 'max_bin': 100}. Best is trial 31 with value: 10.482549487468033.\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[856]\tvalid_0's l1: 10.5289\n",
      "[I 2025-08-09 11:06:00,915] Trial 46 finished with value: 10.528899390145236 and parameters: {'lambda_l1': 1.0977759735440717, 'lambda_l2': 0.9128523956658485, 'num_leaves': 60, 'feature_fraction': 0.76554640635376, 'learning_rate': 0.011294548070060919, 'bagging_fraction': 0.7889908568110097, 'bagging_freq': 1, 'min_child_samples': 47, 'max_bin': 100}. Best is trial 31 with value: 10.482549487468033.\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[415]\tvalid_0's l1: 11.0188\n",
      "[I 2025-08-09 11:06:02,255] Trial 47 finished with value: 11.018831981198664 and parameters: {'lambda_l1': 1.1374312906999657, 'lambda_l2': 0.9300324238430788, 'num_leaves': 63, 'feature_fraction': 0.7644210225123247, 'learning_rate': 0.01315678122035428, 'bagging_fraction': 0.7582121346425141, 'bagging_freq': 2, 'min_child_samples': 48, 'max_bin': 213}. Best is trial 31 with value: 10.482549487468033.\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[415]\tvalid_0's l1: 11.0188\n",
      "[I 2025-08-09 11:06:02,255] Trial 47 finished with value: 11.018831981198664 and parameters: {'lambda_l1': 1.1374312906999657, 'lambda_l2': 0.9300324238430788, 'num_leaves': 63, 'feature_fraction': 0.7644210225123247, 'learning_rate': 0.01315678122035428, 'bagging_fraction': 0.7582121346425141, 'bagging_freq': 2, 'min_child_samples': 48, 'max_bin': 213}. Best is trial 31 with value: 10.482549487468033.\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[569]\tvalid_0's l1: 10.941\n",
      "[I 2025-08-09 11:06:05,160] Trial 48 finished with value: 10.940973213564586 and parameters: {'lambda_l1': 1.4730499251162954, 'lambda_l2': 1.1170161056444827, 'num_leaves': 149, 'feature_fraction': 0.7228182403873563, 'learning_rate': 0.010299785393896296, 'bagging_fraction': 0.7969152375102575, 'bagging_freq': 1, 'min_child_samples': 46, 'max_bin': 151}. Best is trial 31 with value: 10.482549487468033.\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[569]\tvalid_0's l1: 10.941\n",
      "[I 2025-08-09 11:06:05,160] Trial 48 finished with value: 10.940973213564586 and parameters: {'lambda_l1': 1.4730499251162954, 'lambda_l2': 1.1170161056444827, 'num_leaves': 149, 'feature_fraction': 0.7228182403873563, 'learning_rate': 0.010299785393896296, 'bagging_fraction': 0.7969152375102575, 'bagging_freq': 1, 'min_child_samples': 46, 'max_bin': 151}. Best is trial 31 with value: 10.482549487468033.\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[297]\tvalid_0's l1: 11.0869\n",
      "[I 2025-08-09 11:06:06,550] Trial 49 finished with value: 11.086908624891974 and parameters: {'lambda_l1': 1.3119237733221312, 'lambda_l2': 1.00702568847409, 'num_leaves': 90, 'feature_fraction': 0.7933280677297339, 'learning_rate': 0.02019436520001453, 'bagging_fraction': 0.7124914807531391, 'bagging_freq': 4, 'min_child_samples': 41, 'max_bin': 184}. Best is trial 31 with value: 10.482549487468033.\n",
      "\n",
      "‚úÖ Optimizaci√≥n completada!\n",
      "üèÜ Mejor MAE encontrado: 10.4825\n",
      "\n",
      "üîß HIPERPAR√ÅMETROS OPTIMIZADOS OBTENIDOS:\n",
      "============================================================\n",
      "   lambda_l1:        0.1436\n",
      "   lambda_l2:        1.2583\n",
      "   num_leaves:       77\n",
      "   feature_fraction: 0.8133\n",
      "   learning_rate:    0.0335\n",
      "   bagging_fraction: 0.8962\n",
      "   bagging_freq:     7\n",
      "   min_child_samples: 39\n",
      "   max_bin:          100\n",
      "============================================================\n",
      "\n",
      "üìä Resumen de la optimizaci√≥n:\n",
      "  Trials completados: 50\n",
      "  Mejor trial: 31\n",
      "  Tiempo total: 44.3 segundos\n",
      "Early stopping, best iteration is:\n",
      "[297]\tvalid_0's l1: 11.0869\n",
      "[I 2025-08-09 11:06:06,550] Trial 49 finished with value: 11.086908624891974 and parameters: {'lambda_l1': 1.3119237733221312, 'lambda_l2': 1.00702568847409, 'num_leaves': 90, 'feature_fraction': 0.7933280677297339, 'learning_rate': 0.02019436520001453, 'bagging_fraction': 0.7124914807531391, 'bagging_freq': 4, 'min_child_samples': 41, 'max_bin': 184}. Best is trial 31 with value: 10.482549487468033.\n",
      "\n",
      "‚úÖ Optimizaci√≥n completada!\n",
      "üèÜ Mejor MAE encontrado: 10.4825\n",
      "\n",
      "üîß HIPERPAR√ÅMETROS OPTIMIZADOS OBTENIDOS:\n",
      "============================================================\n",
      "   lambda_l1:        0.1436\n",
      "   lambda_l2:        1.2583\n",
      "   num_leaves:       77\n",
      "   feature_fraction: 0.8133\n",
      "   learning_rate:    0.0335\n",
      "   bagging_fraction: 0.8962\n",
      "   bagging_freq:     7\n",
      "   min_child_samples: 39\n",
      "   max_bin:          100\n",
      "============================================================\n",
      "\n",
      "üìä Resumen de la optimizaci√≥n:\n",
      "  Trials completados: 50\n",
      "  Mejor trial: 31\n",
      "  Tiempo total: 44.3 segundos\n"
     ]
    }
   ],
   "source": [
    "# üîß Optimizaci√≥n de hiperpar√°metros con Optuna\n",
    "print(\"OPTIMIZACI√ìN DE HIPERPAR√ÅMETROS CON OPTUNA\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "def objective(trial):\n",
    "    \"\"\"Funci√≥n objetivo para optimizaci√≥n con Optuna\"\"\"\n",
    "    \n",
    "    # Sugerir SOLO los hiperpar√°metros especificados por el usuario\n",
    "    params = {\n",
    "        'objective': 'regression',\n",
    "        'metric': 'mae',\n",
    "        'boosting_type': 'gbdt',\n",
    "        'lambda_l1': trial.suggest_float('lambda_l1', 0.0, 2.0),\n",
    "        'lambda_l2': trial.suggest_float('lambda_l2', 0.0, 2.0),\n",
    "        'num_leaves': trial.suggest_int('num_leaves', 10, 150),\n",
    "        'feature_fraction': trial.suggest_float('feature_fraction', 0.4, 1.0),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3, log=True),\n",
    "        'bagging_fraction': trial.suggest_float('bagging_fraction', 0.4, 1.0),\n",
    "        'bagging_freq': trial.suggest_int('bagging_freq', 1, 10),\n",
    "        'min_child_samples': trial.suggest_int('min_child_samples', 5, 50),\n",
    "        'max_bin': trial.suggest_int('max_bin', 100, 500),\n",
    "        'verbose': -1,\n",
    "        'random_state': 42\n",
    "    }\n",
    "    \n",
    "    # Crear datasets de LightGBM\n",
    "    train_dataset = lgb.Dataset(X_train, label=y_train)\n",
    "    val_dataset = lgb.Dataset(X_val, label=y_val, reference=train_dataset)\n",
    "    \n",
    "    # Entrenar modelo con validaci√≥n cruzada interna\n",
    "    model = lgb.train(\n",
    "        params,\n",
    "        train_dataset,\n",
    "        valid_sets=[val_dataset],\n",
    "        num_boost_round=1000,\n",
    "        callbacks=[\n",
    "            lgb.early_stopping(stopping_rounds=50),\n",
    "            lgb.log_evaluation(0)  # Silenciar logs\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    # Predecir en conjunto de validaci√≥n\n",
    "    y_pred = model.predict(X_val, num_iteration=model.best_iteration)\n",
    "    \n",
    "    # Calcular MAE como m√©trica a minimizar\n",
    "    mae = mean_absolute_error(y_val, y_pred)\n",
    "    \n",
    "    return mae\n",
    "\n",
    "# Crear estudio de optimizaci√≥n\n",
    "print(\"üîç Iniciando optimizaci√≥n de hiperpar√°metros...\")\n",
    "study = optuna.create_study(\n",
    "    direction='minimize',\n",
    "    sampler=optuna.samplers.TPESampler(seed=42),\n",
    "    pruner=optuna.pruners.MedianPruner(n_warmup_steps=10)\n",
    ")\n",
    "\n",
    "# Ejecutar optimizaci√≥n\n",
    "n_trials = 50  # N√∫mero de pruebas (ajustar seg√∫n tiempo disponible)\n",
    "print(f\"üöÄ Ejecutando {n_trials} trials de optimizaci√≥n...\")\n",
    "\n",
    "study.optimize(objective, n_trials=n_trials, show_progress_bar=True)\n",
    "\n",
    "# Mostrar mejores par√°metros\n",
    "print(f\"\\n‚úÖ Optimizaci√≥n completada!\")\n",
    "print(f\"üèÜ Mejor MAE encontrado: {study.best_value:.4f}\")\n",
    "print(f\"\\nüîß HIPERPAR√ÅMETROS OPTIMIZADOS OBTENIDOS:\")\n",
    "best_params = study.best_params\n",
    "print(\"=\"*60)\n",
    "print(f\"   lambda_l1:        {best_params['lambda_l1']:.4f}\")\n",
    "print(f\"   lambda_l2:        {best_params['lambda_l2']:.4f}\")\n",
    "print(f\"   num_leaves:       {best_params['num_leaves']}\")\n",
    "print(f\"   feature_fraction: {best_params['feature_fraction']:.4f}\")\n",
    "print(f\"   learning_rate:    {best_params['learning_rate']:.4f}\")\n",
    "print(f\"   bagging_fraction: {best_params['bagging_fraction']:.4f}\")\n",
    "print(f\"   bagging_freq:     {best_params['bagging_freq']}\")\n",
    "print(f\"   min_child_samples: {best_params['min_child_samples']}\")\n",
    "print(f\"   max_bin:          {best_params['max_bin']}\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Agregar par√°metros fijos\n",
    "best_params.update({\n",
    "    'objective': 'regression',\n",
    "    'metric': 'mae',\n",
    "    'boosting_type': 'gbdt',\n",
    "    'verbose': 0,\n",
    "    'random_state': 42\n",
    "})\n",
    "\n",
    "print(f\"\\nüìä Resumen de la optimizaci√≥n:\")\n",
    "print(f\"  Trials completados: {len(study.trials)}\")\n",
    "print(f\"  Mejor trial: {study.best_trial.number}\")\n",
    "print(f\"  Tiempo total: {sum(t.duration.total_seconds() for t in study.trials if t.duration):.1f} segundos\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e067db2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ENTRENAMIENTO DEL MODELO LIGHTGBM CON OPTUNA - POR PRODUCTO\n",
      "======================================================================\n",
      "üîß PAR√ÅMETROS OPTIMIZADOS QUE SE USAR√ÅN PARA EL MODELO FINAL:\n",
      "======================================================================\n",
      "   lambda_l1:        0.1436\n",
      "   lambda_l2:        1.2583\n",
      "   num_leaves:       77\n",
      "   feature_fraction: 0.8133\n",
      "   learning_rate:    0.0335\n",
      "   bagging_fraction: 0.8962\n",
      "   bagging_freq:     7\n",
      "   min_child_samples: 39\n",
      "   max_bin:          100\n",
      "======================================================================\n",
      "\n",
      "üéØ Iniciando entrenamiento con par√°metros optimizados...\n",
      "üìä Features utilizadas: 29\n",
      "üè≠ Productos en entrenamiento: 718\n",
      "Training until validation scores don't improve for 150 rounds\n",
      "[100]\ttrain's l1: 12.003\teval's l1: 11.3344\n",
      "[100]\ttrain's l1: 12.003\teval's l1: 11.3344\n",
      "[200]\ttrain's l1: 10.1055\teval's l1: 10.5298\n",
      "[200]\ttrain's l1: 10.1055\teval's l1: 10.5298\n",
      "[300]\ttrain's l1: 9.18668\teval's l1: 10.5458\n",
      "[300]\ttrain's l1: 9.18668\teval's l1: 10.5458\n",
      "Early stopping, best iteration is:\n",
      "[236]\ttrain's l1: 9.74586\teval's l1: 10.4825\n",
      "‚úÖ Modelo optimizado entrenado exitosamente!\n",
      "üìä N√∫mero de √°rboles finales: 236\n",
      "\n",
      "üìà M√âTRICAS EN VALIDACI√ìN (MODELO OPTIMIZADO - POR PRODUCTO):\n",
      "  MAE:  10.4825\n",
      "  RMSE: 32.4590\n",
      "  MAPE: 240.33%\n",
      "\n",
      "üìä ESTAD√çSTICAS POR PRODUCTO (MODELO OPTIMIZADO):\n",
      "Productos evaluados: 780\n",
      "Promedio de per√≠odos por producto: 4.9\n",
      "Early stopping, best iteration is:\n",
      "[236]\ttrain's l1: 9.74586\teval's l1: 10.4825\n",
      "‚úÖ Modelo optimizado entrenado exitosamente!\n",
      "üìä N√∫mero de √°rboles finales: 236\n",
      "\n",
      "üìà M√âTRICAS EN VALIDACI√ìN (MODELO OPTIMIZADO - POR PRODUCTO):\n",
      "  MAE:  10.4825\n",
      "  RMSE: 32.4590\n",
      "  MAPE: 240.33%\n",
      "\n",
      "üìä ESTAD√çSTICAS POR PRODUCTO (MODELO OPTIMIZADO):\n",
      "Productos evaluados: 780\n",
      "Promedio de per√≠odos por producto: 4.9\n"
     ]
    }
   ],
   "source": [
    "# üöÄ Entrenar modelo LightGBM con par√°metros optimizados - GRANULARIDAD POR PRODUCTO\n",
    "print(\"ENTRENAMIENTO DEL MODELO LIGHTGBM CON OPTUNA - POR PRODUCTO\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Usar los mejores par√°metros encontrados por Optuna\n",
    "lgb_params = best_params.copy()\n",
    "\n",
    "print(\"üîß PAR√ÅMETROS OPTIMIZADOS QUE SE USAR√ÅN PARA EL MODELO FINAL:\")\n",
    "print(\"=\"*70)\n",
    "print(f\"   lambda_l1:        {lgb_params['lambda_l1']:.4f}\")\n",
    "print(f\"   lambda_l2:        {lgb_params['lambda_l2']:.4f}\")\n",
    "print(f\"   num_leaves:       {lgb_params['num_leaves']}\")\n",
    "print(f\"   feature_fraction: {lgb_params['feature_fraction']:.4f}\")\n",
    "print(f\"   learning_rate:    {lgb_params['learning_rate']:.4f}\")\n",
    "print(f\"   bagging_fraction: {lgb_params['bagging_fraction']:.4f}\")\n",
    "print(f\"   bagging_freq:     {lgb_params['bagging_freq']}\")\n",
    "print(f\"   min_child_samples: {lgb_params['min_child_samples']}\")\n",
    "print(f\"   max_bin:          {lgb_params['max_bin']}\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Crear datasets de LightGBM\n",
    "train_dataset = lgb.Dataset(X_train, label=y_train)\n",
    "val_dataset = lgb.Dataset(X_val, label=y_val, reference=train_dataset)\n",
    "\n",
    "print(f\"\\nüéØ Iniciando entrenamiento con par√°metros optimizados...\")\n",
    "print(f\"üìä Features utilizadas: {len(feature_columns)}\")\n",
    "print(f\"üè≠ Productos en entrenamiento: {productos_train}\")\n",
    "\n",
    "# Entrenar el modelo con m√°s iteraciones para el modelo final\n",
    "model_optimized = lgb.train(\n",
    "    lgb_params,\n",
    "    train_dataset,\n",
    "    valid_sets=[train_dataset, val_dataset],\n",
    "    valid_names=['train', 'eval'],\n",
    "    num_boost_round=2000,       # M√°s iteraciones para el modelo final\n",
    "    callbacks=[\n",
    "        lgb.early_stopping(stopping_rounds=150),  # M√°s paciencia para el modelo final\n",
    "        lgb.log_evaluation(period=100)\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(f\"‚úÖ Modelo optimizado entrenado exitosamente!\")\n",
    "print(f\"üìä N√∫mero de √°rboles finales: {model_optimized.num_trees()}\")\n",
    "\n",
    "# Predicciones en validaci√≥n con modelo optimizado\n",
    "y_pred_val_opt = model_optimized.predict(X_val, num_iteration=model_optimized.best_iteration)\n",
    "\n",
    "# M√©tricas de evaluaci√≥n del modelo optimizado\n",
    "mae_opt = mean_absolute_error(y_val, y_pred_val_opt)\n",
    "rmse_opt = np.sqrt(mean_squared_error(y_val, y_pred_val_opt))\n",
    "mape_opt = np.mean(np.abs((y_val - y_pred_val_opt) / y_val)) * 100\n",
    "\n",
    "print(f\"\\nüìà M√âTRICAS EN VALIDACI√ìN (MODELO OPTIMIZADO - POR PRODUCTO):\")\n",
    "print(f\"  MAE:  {mae_opt:.4f}\")\n",
    "print(f\"  RMSE: {rmse_opt:.4f}\")\n",
    "print(f\"  MAPE: {mape_opt:.2f}%\")\n",
    "\n",
    "# Comparar con modelo base (si existe)\n",
    "if 'mae' in locals():\n",
    "    print(f\"\\nüìä COMPARACI√ìN CON MODELO BASE:\")\n",
    "    print(f\"  Mejora en MAE:  {((mae - mae_opt) / mae * 100):+.2f}%\")\n",
    "    print(f\"  Mejora en RMSE: {((rmse - rmse_opt) / rmse * 100):+.2f}%\")\n",
    "    print(f\"  Mejora en MAPE: {(mape - mape_opt):+.2f} puntos porcentuales\")\n",
    "\n",
    "# Estad√≠sticas adicionales por producto\n",
    "print(f\"\\nüìä ESTAD√çSTICAS POR PRODUCTO (MODELO OPTIMIZADO):\")\n",
    "val_data_with_pred_opt = train_data.loc[~train_mask].copy()\n",
    "val_data_with_pred_opt['pred_optimized'] = y_pred_val_opt\n",
    "product_metrics_opt = val_data_with_pred_opt.groupby('product_id').agg({\n",
    "    'target': ['mean', 'std', 'count'],\n",
    "    'pred_optimized': ['mean', 'std']\n",
    "}).round(3)\n",
    "\n",
    "print(f\"Productos evaluados: {len(product_metrics_opt)}\")\n",
    "print(f\"Promedio de per√≠odos por producto: {product_metrics_opt[('target', 'count')].mean():.1f}\")\n",
    "\n",
    "# Actualizar variables para usar en celdas siguientes\n",
    "model = model_optimized\n",
    "y_pred_val = y_pred_val_opt\n",
    "mae = mae_opt\n",
    "rmse = rmse_opt\n",
    "mape = mape_opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "33bd8359",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AN√ÅLISIS DE IMPORTANCIA DE FEATURES\n",
      "==================================================\n",
      "üîù Top 10 features m√°s importantes:\n",
      "                feature    importance\n",
      "20    tn_rolling_mean_6  1.933250e+09\n",
      "25     total_request_tn  7.404889e+08\n",
      "19    tn_rolling_mean_3  6.689767e+08\n",
      "16                  mes  5.970255e+07\n",
      "3              tn_lag_6  4.803076e+07\n",
      "7   num_customers_lag_3  2.607700e+07\n",
      "6   num_customers_lag_2  2.311939e+07\n",
      "24    total_request_qty  2.075636e+07\n",
      "23        num_customers  2.003750e+07\n",
      "21     tn_rolling_std_3  1.920101e+07\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üéØ AN√ÅLISIS DE PREDICCIONES:\n",
      "Predicciones m√≠nimas: 0.08\n",
      "Predicciones m√°ximas: 1411.56\n",
      "Predicciones promedio: 39.30\n",
      "Valores reales promedio: 38.72\n",
      "Predicciones negativas: 0 (0.0%)\n",
      "Predicciones m√≠nimas: 0.08\n",
      "Predicciones m√°ximas: 1411.56\n",
      "Predicciones promedio: 39.30\n",
      "Valores reales promedio: 38.72\n",
      "Predicciones negativas: 0 (0.0%)\n"
     ]
    }
   ],
   "source": [
    "# üìä An√°lisis de importancia de features\n",
    "print(\"AN√ÅLISIS DE IMPORTANCIA DE FEATURES\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Obtener importancia de features\n",
    "feature_importance = model.feature_importance(importance_type='gain')\n",
    "feature_names = feature_columns\n",
    "\n",
    "# Crear DataFrame con importancias\n",
    "importance_df = pd.DataFrame({\n",
    "    'feature': feature_names,\n",
    "    'importance': feature_importance\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "print(\"üîù Top 10 features m√°s importantes:\")\n",
    "print(importance_df.head(10))\n",
    "\n",
    "# Visualizar importancia\n",
    "plt.figure(figsize=(10, 8))\n",
    "top_features = importance_df.head(15)\n",
    "plt.barh(range(len(top_features)), top_features['importance'])\n",
    "plt.yticks(range(len(top_features)), top_features['feature'])\n",
    "plt.xlabel('Importancia')\n",
    "plt.title('Top 15 Features - Importancia LightGBM')\n",
    "plt.gca().invert_yaxis()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# An√°lisis de predicciones\n",
    "print(f\"\\nüéØ AN√ÅLISIS DE PREDICCIONES:\")\n",
    "print(f\"Predicciones m√≠nimas: {y_pred_val.min():.2f}\")\n",
    "print(f\"Predicciones m√°ximas: {y_pred_val.max():.2f}\")\n",
    "print(f\"Predicciones promedio: {y_pred_val.mean():.2f}\")\n",
    "print(f\"Valores reales promedio: {y_val.mean():.2f}\")\n",
    "\n",
    "# Verificar predicciones negativas\n",
    "negative_preds = (y_pred_val < 0).sum()\n",
    "print(f\"Predicciones negativas: {negative_preds} ({negative_preds/len(y_pred_val)*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "127060bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GENERACI√ìN DE PREDICCIONES FINALES\n",
      "==================================================\n",
      "üìä Productos para predicci√≥n: 780\n",
      "üìÖ Per√≠odo base para predicci√≥n: periodo\n",
      "201912    780\n",
      "Name: count, dtype: int64\n",
      "üîç Shape de datos de predicci√≥n: (780, 29)\n",
      "üîç Valores nulos en predicci√≥n: 0\n",
      "\n",
      "üîß CONFIRMACI√ìN: Predicciones generadas con hiperpar√°metros optimizados:\n",
      "=================================================================\n",
      "   lambda_l1:        0.1436\n",
      "   lambda_l2:        1.2583\n",
      "   num_leaves:       77\n",
      "   feature_fraction: 0.8133\n",
      "   learning_rate:    0.0335\n",
      "   bagging_fraction: 0.8962\n",
      "   bagging_freq:     7\n",
      "   min_child_samples: 39\n",
      "   max_bin:          100\n",
      "=================================================================\n",
      "‚úÖ Predicciones generadas para 780 productos\n",
      "\n",
      "üìä Estad√≠sticas de predicciones:\n",
      "  Promedio: 35.22\n",
      "  Mediana:  7.98\n",
      "  M√≠nimo:   0.32\n",
      "  M√°ximo:   1010.16\n",
      "  Std:      86.05\n",
      "\n",
      "Primeras 10 predicciones:\n",
      "   product_id           tn\n",
      "0       20001   888.677174\n",
      "1       20002  1010.155906\n",
      "2       20003   789.907956\n",
      "3       20004   741.301926\n",
      "4       20005   697.096955\n",
      "5       20006   386.132096\n",
      "6       20007   387.613584\n",
      "7       20008   272.291464\n",
      "8       20009   399.209420\n",
      "9       20010   339.556663\n"
     ]
    }
   ],
   "source": [
    "# üîÆ Generar predicciones finales para febrero 2020\n",
    "print(\"GENERACI√ìN DE PREDICCIONES FINALES\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Preparar datos para predicci√≥n (√∫ltimos datos disponibles de cada producto)\n",
    "# Necesitamos los datos m√°s recientes para predecir 2 per√≠odos adelante\n",
    "\n",
    "# Obtener √∫ltimo per√≠odo disponible para cada producto\n",
    "ultimo_periodo = data_combined.groupby('product_id')['fecha'].max().reset_index()\n",
    "ultimo_periodo.columns = ['product_id', 'ultima_fecha']\n",
    "\n",
    "# Unir con datos completos para obtener features m√°s recientes\n",
    "datos_prediccion = pd.merge(data_combined, ultimo_periodo, on='product_id')\n",
    "datos_prediccion = datos_prediccion[datos_prediccion['fecha'] == datos_prediccion['ultima_fecha']].copy()\n",
    "\n",
    "print(f\"üìä Productos para predicci√≥n: {len(datos_prediccion)}\")\n",
    "print(f\"üìÖ Per√≠odo base para predicci√≥n: {datos_prediccion['periodo'].value_counts().head()}\")\n",
    "\n",
    "# Preparar features para predicci√≥n\n",
    "X_pred = datos_prediccion[feature_columns].copy()\n",
    "X_pred = X_pred.fillna(0)\n",
    "\n",
    "print(f\"üîç Shape de datos de predicci√≥n: {X_pred.shape}\")\n",
    "print(f\"üîç Valores nulos en predicci√≥n: {X_pred.isnull().sum().sum()}\")\n",
    "\n",
    "# Generar predicciones\n",
    "predicciones = model.predict(X_pred, num_iteration=model.best_iteration)\n",
    "\n",
    "print(f\"\\nüîß CONFIRMACI√ìN: Predicciones generadas con hiperpar√°metros optimizados:\")\n",
    "print(\"=\"*65)\n",
    "print(f\"   lambda_l1:        {lgb_params['lambda_l1']:.4f}\")\n",
    "print(f\"   lambda_l2:        {lgb_params['lambda_l2']:.4f}\")\n",
    "print(f\"   num_leaves:       {lgb_params['num_leaves']}\")\n",
    "print(f\"   feature_fraction: {lgb_params['feature_fraction']:.4f}\")\n",
    "print(f\"   learning_rate:    {lgb_params['learning_rate']:.4f}\")\n",
    "print(f\"   bagging_fraction: {lgb_params['bagging_fraction']:.4f}\")\n",
    "print(f\"   bagging_freq:     {lgb_params['bagging_freq']}\")\n",
    "print(f\"   min_child_samples: {lgb_params['min_child_samples']}\")\n",
    "print(f\"   max_bin:          {lgb_params['max_bin']}\")\n",
    "print(\"=\"*65)\n",
    "\n",
    "# Crear DataFrame de resultados\n",
    "resultado_lgbm = pd.DataFrame({\n",
    "    'product_id': datos_prediccion['product_id'].values,\n",
    "    'tn': predicciones\n",
    "})\n",
    "\n",
    "# Asegurar que no hay predicciones negativas (reemplazar con 0)\n",
    "resultado_lgbm['tn'] = np.maximum(resultado_lgbm['tn'], 0)\n",
    "\n",
    "print(f\"‚úÖ Predicciones generadas para {len(resultado_lgbm)} productos\")\n",
    "print(f\"\\nüìä Estad√≠sticas de predicciones:\")\n",
    "print(f\"  Promedio: {resultado_lgbm['tn'].mean():.2f}\")\n",
    "print(f\"  Mediana:  {resultado_lgbm['tn'].median():.2f}\")\n",
    "print(f\"  M√≠nimo:   {resultado_lgbm['tn'].min():.2f}\")\n",
    "print(f\"  M√°ximo:   {resultado_lgbm['tn'].max():.2f}\")\n",
    "print(f\"  Std:      {resultado_lgbm['tn'].std():.2f}\")\n",
    "\n",
    "print(f\"\\nPrimeras 10 predicciones:\")\n",
    "print(resultado_lgbm.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a348fa53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GUARDADO DE PREDICCIONES Y RESUMEN - POR PRODUCTO\n",
      "============================================================\n",
      "üìä Productos esperados: 780\n",
      "üìà Productos predichos: 780\n",
      "‚úÖ Predicciones guardadas en: data/pred_lgbm_v2__revisa_hiperparametrosproducto.csv\n",
      "\n",
      "üéØ RESUMEN FINAL DEL MODELO LGBM - GRANULARIDAD POR PRODUCTO:\n",
      "üìä Total productos predichos: 780\n",
      "üìà M√©tricas de validaci√≥n:\n",
      "   MAE:  10.4825\n",
      "   RMSE: 32.4590\n",
      "   MAPE: 240.33%\n",
      "üîß Features utilizadas: 29\n",
      "üå≥ N√∫mero de √°rboles: 236\n",
      "üìÖ Predicci√≥n objetivo: 2 per√≠odos a futuro (Feb 2020)\n",
      "üè≠ Granularidad: POR PRODUCTO (agregando clientes)\n",
      "\n",
      "üìä ESTAD√çSTICAS DE PREDICCIONES POR PRODUCTO:\n",
      "   Promedio por producto: 35.22\n",
      "   Mediana por producto:  7.98\n",
      "   Std por producto:      86.05\n",
      "   Min por producto:      0.32\n",
      "   Max por producto:      1010.16\n",
      "\n",
      "üìã Top 5 features m√°s importantes para granularidad por producto:\n",
      "   tn_rolling_mean_6: 1933250382\n",
      "   total_request_tn: 740488931\n",
      "   tn_rolling_mean_3: 668976734\n",
      "   mes: 59702548\n",
      "   tn_lag_6: 48030756\n",
      "\n",
      "üîß RESUMEN DE HIPERPAR√ÅMETROS OPTIMIZADOS:\n",
      "============================================================\n",
      "‚úÖ Los siguientes 9 hiperpar√°metros fueron optimizados con Optuna:\n",
      "   1. lambda_l1:        0.1436\n",
      "   2. lambda_l2:        1.2583\n",
      "   3. num_leaves:       77\n",
      "   4. feature_fraction: 0.8133\n",
      "   5. learning_rate:    0.0335\n",
      "   6. bagging_fraction: 0.8962\n",
      "   7. bagging_freq:     7\n",
      "   8. min_child_samples: 39\n",
      "   9. max_bin:          100\n",
      "============================================================\n",
      "\n",
      "‚úÖ Modelo LightGBM completado exitosamente con granularidad POR PRODUCTO!\n",
      "Archivo: data/pred_lgbm_v2__revisa_hiperparametrosproducto.csv\n",
      "\n",
      "üéØ HIPERPAR√ÅMETROS FINALES UTILIZADOS EN LAS PREDICCIONES:\n",
      "=================================================================\n",
      "   lambda_l1:        0.1436\n",
      "   lambda_l2:        1.2583\n",
      "   num_leaves:       77\n",
      "   feature_fraction: 0.8133\n",
      "   learning_rate:    0.0335\n",
      "   bagging_fraction: 0.8962\n",
      "   bagging_freq:     7\n",
      "   min_child_samples: 39\n",
      "   max_bin:          100\n",
      "=================================================================\n",
      "‚úÖ Predicciones generadas usando estos valores optimizados por Optuna!\n",
      "\n",
      "üîç Verificaci√≥n archivo guardado:\n",
      "   Filas: 780\n",
      "   Columnas: ['product_id', 'tn']\n",
      "   Primeras 3 filas:\n",
      "   product_id           tn\n",
      "0       20001   888.677174\n",
      "1       20002  1010.155906\n",
      "2       20003   789.907956\n",
      "\n",
      "üìà Resumen de predicciones por producto:\n",
      "   Total de toneladas predichas: 27474.44\n",
      "   Productos con predicci√≥n > 0: 780\n",
      "   Productos con predicci√≥n = 0: 0\n"
     ]
    }
   ],
   "source": [
    "# üíæ Guardar predicciones y resumen final - GRANULARIDAD POR PRODUCTO\n",
    "print(\"GUARDADO DE PREDICCIONES Y RESUMEN - POR PRODUCTO\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Verificar que tenemos todos los productos objetivo\n",
    "productos_esperados = set(productos_objetivo)\n",
    "productos_predichos = set(resultado_lgbm['product_id'])\n",
    "\n",
    "print(f\"üìä Productos esperados: {len(productos_esperados)}\")\n",
    "print(f\"üìà Productos predichos: {len(productos_predichos)}\")\n",
    "\n",
    "# Verificar productos faltantes\n",
    "productos_faltantes = productos_esperados - productos_predichos\n",
    "if productos_faltantes:\n",
    "    print(f\"‚ö†Ô∏è Productos faltantes: {len(productos_faltantes)}\")\n",
    "    print(f\"Primeros 5 faltantes: {list(productos_faltantes)[:5]}\")\n",
    "    \n",
    "    # Crear predicciones por defecto para productos faltantes\n",
    "    predicciones_default = pd.DataFrame({\n",
    "        'product_id': list(productos_faltantes),\n",
    "        'tn': [resultado_lgbm['tn'].median()] * len(productos_faltantes)\n",
    "    })\n",
    "    \n",
    "    resultado_lgbm = pd.concat([resultado_lgbm, predicciones_default], ignore_index=True)\n",
    "    print(f\"‚úÖ Agregadas predicciones por defecto para productos faltantes\")\n",
    "\n",
    "# Ordenar por product_id\n",
    "resultado_lgbm = resultado_lgbm.sort_values('product_id').reset_index(drop=True)\n",
    "\n",
    "# Guardar archivo\n",
    "import os\n",
    "os.makedirs('data', exist_ok=True)\n",
    "archivo_salida = 'data/pred_lgbm_v2__revisa_hiperparametrosproducto.csv'\n",
    "resultado_lgbm.to_csv(archivo_salida, index=False)\n",
    "\n",
    "print(f\"‚úÖ Predicciones guardadas en: {archivo_salida}\")\n",
    "\n",
    "# Resumen final del modelo por producto\n",
    "print(f\"\\nüéØ RESUMEN FINAL DEL MODELO LGBM - GRANULARIDAD POR PRODUCTO:\")\n",
    "print(f\"üìä Total productos predichos: {len(resultado_lgbm)}\")\n",
    "print(f\"üìà M√©tricas de validaci√≥n:\")\n",
    "print(f\"   MAE:  {mae:.4f}\")\n",
    "print(f\"   RMSE: {rmse:.4f}\")\n",
    "print(f\"   MAPE: {mape:.2f}%\")\n",
    "print(f\"üîß Features utilizadas: {len(feature_columns)}\")\n",
    "print(f\"üå≥ N√∫mero de √°rboles: {model.num_trees()}\")\n",
    "print(f\"üìÖ Predicci√≥n objetivo: 2 per√≠odos a futuro (Feb 2020)\")\n",
    "print(f\"üè≠ Granularidad: POR PRODUCTO (agregando clientes)\")\n",
    "\n",
    "# Estad√≠sticas de predicciones por producto\n",
    "print(f\"\\nüìä ESTAD√çSTICAS DE PREDICCIONES POR PRODUCTO:\")\n",
    "print(f\"   Promedio por producto: {resultado_lgbm['tn'].mean():.2f}\")\n",
    "print(f\"   Mediana por producto:  {resultado_lgbm['tn'].median():.2f}\")\n",
    "print(f\"   Std por producto:      {resultado_lgbm['tn'].std():.2f}\")\n",
    "print(f\"   Min por producto:      {resultado_lgbm['tn'].min():.2f}\")\n",
    "print(f\"   Max por producto:      {resultado_lgbm['tn'].max():.2f}\")\n",
    "\n",
    "print(f\"\\nüìã Top 5 features m√°s importantes para granularidad por producto:\")\n",
    "for i, row in importance_df.head(5).iterrows():\n",
    "    print(f\"   {row['feature']}: {row['importance']:.0f}\")\n",
    "\n",
    "print(f\"\\nüîß RESUMEN DE HIPERPAR√ÅMETROS OPTIMIZADOS:\")\n",
    "print(\"=\"*60)\n",
    "print(f\"‚úÖ Los siguientes 9 hiperpar√°metros fueron optimizados con Optuna:\")\n",
    "print(f\"   1. lambda_l1:        {lgb_params['lambda_l1']:.4f}\")\n",
    "print(f\"   2. lambda_l2:        {lgb_params['lambda_l2']:.4f}\")\n",
    "print(f\"   3. num_leaves:       {lgb_params['num_leaves']}\")\n",
    "print(f\"   4. feature_fraction: {lgb_params['feature_fraction']:.4f}\")\n",
    "print(f\"   5. learning_rate:    {lgb_params['learning_rate']:.4f}\")\n",
    "print(f\"   6. bagging_fraction: {lgb_params['bagging_fraction']:.4f}\")\n",
    "print(f\"   7. bagging_freq:     {lgb_params['bagging_freq']}\")\n",
    "print(f\"   8. min_child_samples: {lgb_params['min_child_samples']}\")\n",
    "print(f\"   9. max_bin:          {lgb_params['max_bin']}\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(f\"\\n‚úÖ Modelo LightGBM completado exitosamente con granularidad POR PRODUCTO!\")\n",
    "print(f\"Archivo: {archivo_salida}\")\n",
    "\n",
    "# Mostrar resumen final de hiperpar√°metros optimizados\n",
    "print(f\"\\nüéØ HIPERPAR√ÅMETROS FINALES UTILIZADOS EN LAS PREDICCIONES:\")\n",
    "print(\"=\"*65)\n",
    "print(f\"   lambda_l1:        {lgb_params['lambda_l1']:.4f}\")\n",
    "print(f\"   lambda_l2:        {lgb_params['lambda_l2']:.4f}\")\n",
    "print(f\"   num_leaves:       {lgb_params['num_leaves']}\")\n",
    "print(f\"   feature_fraction: {lgb_params['feature_fraction']:.4f}\")\n",
    "print(f\"   learning_rate:    {lgb_params['learning_rate']:.4f}\")\n",
    "print(f\"   bagging_fraction: {lgb_params['bagging_fraction']:.4f}\")\n",
    "print(f\"   bagging_freq:     {lgb_params['bagging_freq']}\")\n",
    "print(f\"   min_child_samples: {lgb_params['min_child_samples']}\")\n",
    "print(f\"   max_bin:          {lgb_params['max_bin']}\")\n",
    "print(\"=\"*65)\n",
    "print(f\"‚úÖ Predicciones generadas usando estos valores optimizados por Optuna!\")\n",
    "\n",
    "# Verificar archivo guardado\n",
    "if os.path.exists(archivo_salida):\n",
    "    verificacion = pd.read_csv(archivo_salida)\n",
    "    print(f\"\\nüîç Verificaci√≥n archivo guardado:\")\n",
    "    print(f\"   Filas: {len(verificacion)}\")\n",
    "    print(f\"   Columnas: {list(verificacion.columns)}\")\n",
    "    print(f\"   Primeras 3 filas:\")\n",
    "    print(verificacion.head(3))\n",
    "    \n",
    "    print(f\"\\nüìà Resumen de predicciones por producto:\")\n",
    "    print(f\"   Total de toneladas predichas: {verificacion['tn'].sum():.2f}\")\n",
    "    print(f\"   Productos con predicci√≥n > 0: {(verificacion['tn'] > 0).sum()}\")\n",
    "    print(f\"   Productos con predicci√≥n = 0: {(verificacion['tn'] == 0).sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f60978d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìà Resumen final de optimizaci√≥n con Optuna\n",
      "RESUMEN FINAL DE OPTIMIZACI√ìN CON OPTUNA\n",
      "============================================================\n",
      "üîç Detalles de la optimizaci√≥n:\n",
      "   M√©todo de optimizaci√≥n: TPE (Tree-structured Parzen Estimator)\n",
      "   Hiperpar√°metros optimizados: 9 par√°metros espec√≠ficos\n",
      "   N√∫mero total de trials: 50\n",
      "   Trials exitosos: 50\n",
      "   Trials podados: 0\n",
      "\n",
      "üèÜ Mejor configuraci√≥n encontrada:\n",
      "   MAE en validaci√≥n: 10.4825\n",
      "   Trial n√∫mero: 31\n",
      "\n",
      "üéØ VALORES FINALES DE LOS 9 HIPERPAR√ÅMETROS OPTIMIZADOS:\n",
      "=================================================================\n",
      "   1. lambda_l1:        0.1436\n",
      "   2. lambda_l2:        1.2583\n",
      "   3. num_leaves:       77\n",
      "   4. feature_fraction: 0.8133\n",
      "   5. learning_rate:    0.0335\n",
      "   6. bagging_fraction: 0.8962\n",
      "   7. bagging_freq:     7\n",
      "   8. min_child_samples: 39\n",
      "   9. max_bin:          100\n",
      "=================================================================\n",
      "\n",
      "üîß Impacto de la optimizaci√≥n:\n",
      "   MAE optimizado vs base: +0.0000 (+0.00%)\n",
      "\n",
      "üìà Top 3 trials m√°s exitosos:\n",
      "   1. Trial 31: MAE = 10.4825\n",
      "   2. Trial 44: MAE = 10.4933\n",
      "   3. Trial 46: MAE = 10.5289\n",
      "\n",
      "üìã Par√°metros m√°s impactantes (por varianza):\n",
      "   1. max_bin: varianza = 787.8889\n",
      "   2. num_leaves: varianza = 401.0556\n",
      "   3. min_child_samples: varianza = 31.4097\n",
      "\n",
      "‚úÖ Optimizaci√≥n Optuna completada exitosamente!\n",
      "üìÅ Predicciones finales guardadas en: data/pred_lgbm_v2__revisa_hiperparametrosproducto.csv\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\nüìà Resumen final de optimizaci√≥n con Optuna\")\n",
    "print(\"RESUMEN FINAL DE OPTIMIZACI√ìN CON OPTUNA\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Mostrar informaci√≥n del estudio de optimizaci√≥n\n",
    "print(f\"üîç Detalles de la optimizaci√≥n:\")\n",
    "print(f\"   M√©todo de optimizaci√≥n: TPE (Tree-structured Parzen Estimator)\")\n",
    "print(f\"   Hiperpar√°metros optimizados: 9 par√°metros espec√≠ficos\")\n",
    "print(f\"   N√∫mero total de trials: {len(study.trials)}\")\n",
    "print(f\"   Trials exitosos: {len([t for t in study.trials if t.state == optuna.trial.TrialState.COMPLETE])}\")\n",
    "print(f\"   Trials podados: {len([t for t in study.trials if t.state == optuna.trial.TrialState.PRUNED])}\")\n",
    "\n",
    "print(f\"\\nüèÜ Mejor configuraci√≥n encontrada:\")\n",
    "print(f\"   MAE en validaci√≥n: {study.best_value:.4f}\")\n",
    "print(f\"   Trial n√∫mero: {study.best_trial.number}\")\n",
    "\n",
    "print(f\"\\nüéØ VALORES FINALES DE LOS 9 HIPERPAR√ÅMETROS OPTIMIZADOS:\")\n",
    "print(\"=\"*65)\n",
    "final_params = study.best_params\n",
    "print(f\"   1. lambda_l1:        {final_params['lambda_l1']:.4f}\")\n",
    "print(f\"   2. lambda_l2:        {final_params['lambda_l2']:.4f}\")\n",
    "print(f\"   3. num_leaves:       {final_params['num_leaves']}\")\n",
    "print(f\"   4. feature_fraction: {final_params['feature_fraction']:.4f}\")\n",
    "print(f\"   5. learning_rate:    {final_params['learning_rate']:.4f}\")\n",
    "print(f\"   6. bagging_fraction: {final_params['bagging_fraction']:.4f}\")\n",
    "print(f\"   7. bagging_freq:     {final_params['bagging_freq']}\")\n",
    "print(f\"   8. min_child_samples: {final_params['min_child_samples']}\")\n",
    "print(f\"   9. max_bin:          {final_params['max_bin']}\")\n",
    "print(\"=\"*65)\n",
    "\n",
    "print(f\"\\nüîß Impacto de la optimizaci√≥n:\")\n",
    "if 'mae' in locals() and 'study' in locals():\n",
    "    mejora_absoluta = study.best_value - mae  # Deber√≠a ser negativa si mejor√≥\n",
    "    mejora_relativa = (mejora_absoluta / study.best_value) * 100\n",
    "    print(f\"   MAE optimizado vs base: {mejora_absoluta:+.4f} ({mejora_relativa:+.2f}%)\")\n",
    "\n",
    "print(f\"\\nüìà Top 3 trials m√°s exitosos:\")\n",
    "sorted_trials = sorted(study.trials, key=lambda t: t.value if t.value is not None else float('inf'))\n",
    "for i, trial in enumerate(sorted_trials[:3]):\n",
    "    if trial.value is not None:\n",
    "        print(f\"   {i+1}. Trial {trial.number}: MAE = {trial.value:.4f}\")\n",
    "\n",
    "print(f\"\\nüìã Par√°metros m√°s impactantes (por varianza):\")\n",
    "# Calcular varianza de par√°metros en los mejores trials\n",
    "if len(study.trials) > 5:\n",
    "    top_trials = sorted_trials[:max(5, len(sorted_trials)//4)]\n",
    "    param_values = {}\n",
    "    \n",
    "    for trial in top_trials:\n",
    "        if trial.value is not None:\n",
    "            for param, value in trial.params.items():\n",
    "                if param not in param_values:\n",
    "                    param_values[param] = []\n",
    "                param_values[param].append(value)\n",
    "    \n",
    "    param_variance = {}\n",
    "    for param, values in param_values.items():\n",
    "        if len(values) > 1:\n",
    "            if all(isinstance(v, (int, float)) for v in values):\n",
    "                param_variance[param] = np.var(values)\n",
    "    \n",
    "    # Mostrar top 3 par√°metros con mayor varianza\n",
    "    sorted_params = sorted(param_variance.items(), key=lambda x: x[1], reverse=True)\n",
    "    for i, (param, variance) in enumerate(sorted_params[:3]):\n",
    "        print(f\"   {i+1}. {param}: varianza = {variance:.4f}\")\n",
    "\n",
    "print(f\"\\n‚úÖ Optimizaci√≥n Optuna completada exitosamente!\")\n",
    "print(f\"üìÅ Predicciones finales guardadas en: data/pred_lgbm_v2__revisa_hiperparametrosproducto.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ldi2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
