{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5907ba2e",
   "metadata": {},
   "source": [
    "cr la optimizacion de los parametros recomendados en virtual 2025"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d70a5edb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… LibrerÃ­as importadas correctamente\n"
     ]
    }
   ],
   "source": [
    "# ğŸ“¦ Importar librerÃ­as necesarias\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "print(\"âœ… LibrerÃ­as importadas correctamente\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4317525b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cargando datasets...\n",
      "âœ… Sales data cargado: (2945818, 7)\n",
      "âœ… Stocks data cargado: (13691, 3)\n",
      "âœ… Product info cargado: (1251, 7)\n",
      "âœ… Productos a predecir cargados: (780, 1)\n",
      "\n",
      "ğŸ¯ Todos los datasets cargados exitosamente\n",
      "âœ… Sales data cargado: (2945818, 7)\n",
      "âœ… Stocks data cargado: (13691, 3)\n",
      "âœ… Product info cargado: (1251, 7)\n",
      "âœ… Productos a predecir cargados: (780, 1)\n",
      "\n",
      "ğŸ¯ Todos los datasets cargados exitosamente\n"
     ]
    }
   ],
   "source": [
    "# ğŸ“„ Cargar todos los datasets\n",
    "print(\"Cargando datasets...\")\n",
    "\n",
    "# Load the sales data (tab-delimited)\n",
    "sales = pd.read_csv(\"datasets/sell-in.txt\", sep=\"\\t\", dtype={\"periodo\": str})\n",
    "print(f\"âœ… Sales data cargado: {sales.shape}\")\n",
    "\n",
    "# Load the stocks data (tab-delimited) \n",
    "stocks = pd.read_csv(\"datasets/tb_stocks.txt\", sep=\"\\t\", dtype={\"periodo\": str})\n",
    "print(f\"âœ… Stocks data cargado: {stocks.shape}\")\n",
    "\n",
    "# Load the product information data (tab-delimited)\n",
    "product_info = pd.read_csv(\"datasets/tb_productos.txt\", sep=\"\\t\")\n",
    "print(f\"âœ… Product info cargado: {product_info.shape}\")\n",
    "\n",
    "# Carga productos a predecir\n",
    "product_predict = pd.read_csv(\"datasets/product_id_apredecir201912.txt\", sep=\"\\t\", header=0)\n",
    "print(f\"âœ… Productos a predecir cargados: {product_predict.shape}\")\n",
    "\n",
    "print(\"\\nğŸ¯ Todos los datasets cargados exitosamente\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1f236a4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EXPLORACIÃ“N DE DATOS\n",
      "==================================================\n",
      "\n",
      "ğŸ“Š SALES DATA:\n",
      "Columnas: ['periodo', 'customer_id', 'product_id', 'plan_precios_cuidados', 'cust_request_qty', 'cust_request_tn', 'tn']\n",
      "PerÃ­odos Ãºnicos: 36\n",
      "Productos Ãºnicos: 1233\n",
      "Primeras filas:\n",
      "  periodo  customer_id  product_id  plan_precios_cuidados  cust_request_qty  \\\n",
      "0  201701        10234       20524                      0                 2   \n",
      "1  201701        10032       20524                      0                 1   \n",
      "2  201701        10217       20524                      0                 1   \n",
      "3  201701        10125       20524                      0                 1   \n",
      "4  201701        10012       20524                      0                11   \n",
      "\n",
      "   cust_request_tn       tn  \n",
      "0          0.05300  0.05300  \n",
      "1          0.13628  0.13628  \n",
      "2          0.03028  0.03028  \n",
      "3          0.02271  0.02271  \n",
      "4          1.54452  1.54452  \n",
      "\n",
      "ğŸ“¦ STOCKS DATA:\n",
      "Columnas: ['periodo', 'product_id', 'stock_final']\n",
      "PerÃ­odos Ãºnicos: 15\n",
      "Productos Ãºnicos: 1095\n",
      "Primeras filas:\n",
      "  periodo  product_id  stock_final\n",
      "0  201810       20524      1.61267\n",
      "1  201810       20311      2.93657\n",
      "2  201810       20654      6.83269\n",
      "3  201810       21005      1.01338\n",
      "4  201810       20974      0.34595\n",
      "\n",
      "ğŸ·ï¸ PRODUCT INFO:\n",
      "Columnas: ['cat1', 'cat2', 'cat3', 'brand', 'sku_size', 'product_id', 'descripcion']\n",
      "Productos Ãºnicos: 1251\n",
      "Primeras filas:\n",
      "    cat1      cat2         cat3   brand  sku_size  product_id  \\\n",
      "0  FOODS  ADEREZOS  Aji Picante  NATURA       240       20609   \n",
      "1  FOODS  ADEREZOS     Barbacoa  NATURA       250       20266   \n",
      "2  FOODS  ADEREZOS     Barbacoa  NATURA       400       20325   \n",
      "3  FOODS  ADEREZOS     Barbacoa  NATURA       500       20503   \n",
      "4  FOODS  ADEREZOS  Chimichurri  NATURA       350       20797   \n",
      "\n",
      "         descripcion  \n",
      "0  Salsa Aji Picante  \n",
      "1     Salsa Barbacoa  \n",
      "2     Salsa Barbacoa  \n",
      "3     Salsa Barbacoa  \n",
      "4        Chimichurri  \n",
      "\n",
      "ğŸ¯ PRODUCTOS A PREDECIR:\n",
      "Columnas: ['product_id']\n",
      "Total productos a predecir: 780\n",
      "Primeras filas:\n",
      "   product_id\n",
      "0       20001\n",
      "1       20002\n",
      "2       20003\n",
      "3       20004\n",
      "4       20005\n"
     ]
    }
   ],
   "source": [
    "# ğŸ” Explorar estructura de los datos\n",
    "print(\"EXPLORACIÃ“N DE DATOS\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "print(\"\\nğŸ“Š SALES DATA:\")\n",
    "print(f\"Columnas: {list(sales.columns)}\")\n",
    "print(f\"PerÃ­odos Ãºnicos: {sales['periodo'].nunique()}\")\n",
    "print(f\"Productos Ãºnicos: {sales['product_id'].nunique()}\")\n",
    "print(\"Primeras filas:\")\n",
    "print(sales.head())\n",
    "\n",
    "print(\"\\nğŸ“¦ STOCKS DATA:\")\n",
    "print(f\"Columnas: {list(stocks.columns)}\")\n",
    "print(f\"PerÃ­odos Ãºnicos: {stocks['periodo'].nunique()}\")\n",
    "print(f\"Productos Ãºnicos: {stocks['product_id'].nunique()}\")\n",
    "print(\"Primeras filas:\")\n",
    "print(stocks.head())\n",
    "\n",
    "print(\"\\nğŸ·ï¸ PRODUCT INFO:\")\n",
    "print(f\"Columnas: {list(product_info.columns)}\")\n",
    "print(f\"Productos Ãºnicos: {product_info['product_id'].nunique()}\")\n",
    "print(\"Primeras filas:\")\n",
    "print(product_info.head())\n",
    "\n",
    "print(\"\\nğŸ¯ PRODUCTOS A PREDECIR:\")\n",
    "print(f\"Columnas: {list(product_predict.columns)}\")\n",
    "print(f\"Total productos a predecir: {len(product_predict)}\")\n",
    "print(\"Primeras filas:\")\n",
    "print(product_predict.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d647da4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VERIFICACIÃ“N DE CONSISTENCIA\n",
      "==================================================\n",
      "ğŸ“Š Productos en sales: 1233\n",
      "ğŸ“¦ Productos en stocks: 1095\n",
      "ğŸ·ï¸ Productos en product_info: 1251\n",
      "ğŸ¯ Productos a predecir: 780\n",
      "\n",
      "ğŸ” INTERSECCIONES:\n",
      "Sales âˆ© Stocks: 1095\n",
      "Sales âˆ© Product_info: 1188\n",
      "Sales âˆ© Productos_predict: 780\n",
      "Stocks âˆ© Productos_predict: 779\n",
      "Product_info âˆ© Productos_predict: 780\n",
      "\n",
      "ğŸ“… RANGOS DE FECHAS:\n",
      "Sales - perÃ­odos: 201701 a 201912\n",
      "Stocks - perÃ­odos: 201810 a 201912\n",
      "Sales - perÃ­odos: 201701 a 201912\n",
      "Stocks - perÃ­odos: 201810 a 201912\n"
     ]
    }
   ],
   "source": [
    "# ğŸ”— Verificar consistencia entre datasets\n",
    "print(\"VERIFICACIÃ“N DE CONSISTENCIA\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Productos Ãºnicos en cada dataset\n",
    "productos_sales = set(sales['product_id'].unique())\n",
    "productos_stocks = set(stocks['product_id'].unique())\n",
    "productos_info = set(product_info['product_id'].unique())\n",
    "\n",
    "# Si product_predict tiene columna product_id\n",
    "if 'product_id' in product_predict.columns:\n",
    "    productos_predict = set(product_predict['product_id'].unique())\n",
    "else:\n",
    "    # Si la primera columna contiene los product_ids\n",
    "    primera_columna = product_predict.columns[0]\n",
    "    productos_predict = set(product_predict[primera_columna].unique())\n",
    "    print(f\"âš ï¸ Usando columna '{primera_columna}' como product_id\")\n",
    "\n",
    "print(f\"ğŸ“Š Productos en sales: {len(productos_sales)}\")\n",
    "print(f\"ğŸ“¦ Productos en stocks: {len(productos_stocks)}\")\n",
    "print(f\"ğŸ·ï¸ Productos en product_info: {len(productos_info)}\")\n",
    "print(f\"ğŸ¯ Productos a predecir: {len(productos_predict)}\")\n",
    "\n",
    "# Verificar intersecciones\n",
    "print(f\"\\nğŸ” INTERSECCIONES:\")\n",
    "print(f\"Sales âˆ© Stocks: {len(productos_sales & productos_stocks)}\")\n",
    "print(f\"Sales âˆ© Product_info: {len(productos_sales & productos_info)}\")\n",
    "print(f\"Sales âˆ© Productos_predict: {len(productos_sales & productos_predict)}\")\n",
    "print(f\"Stocks âˆ© Productos_predict: {len(productos_stocks & productos_predict)}\")\n",
    "print(f\"Product_info âˆ© Productos_predict: {len(productos_info & productos_predict)}\")\n",
    "\n",
    "# Verificar rangos de fechas\n",
    "print(f\"\\nğŸ“… RANGOS DE FECHAS:\")\n",
    "print(f\"Sales - perÃ­odos: {sales['periodo'].min()} a {sales['periodo'].max()}\")\n",
    "print(f\"Stocks - perÃ­odos: {stocks['periodo'].min()} a {stocks['periodo'].max()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4e08be3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… LightGBM, Optuna y librerÃ­as ML importadas correctamente\n"
     ]
    }
   ],
   "source": [
    "# ğŸ“¦ Instalar e importar LightGBM, Optuna y librerÃ­as adicionales\n",
    "# %pip install lightgbm optuna\n",
    "\n",
    "import lightgbm as lgb\n",
    "import optuna\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"âœ… LightGBM, Optuna y librerÃ­as ML importadas correctamente\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "715202b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PREPARACIÃ“N DE DATOS PARA LGBM - GRANULARIDAD POR PRODUCTO\n",
      "============================================================\n",
      "ğŸ¯ Productos objetivo: 780\n",
      "ğŸ“Š Sales filtradas: (2293481, 8)\n",
      "ğŸ“¦ Stocks filtradas: (10727, 4)\n",
      "ğŸ“Š Sales filtradas: (2293481, 8)\n",
      "ğŸ“¦ Stocks filtradas: (10727, 4)\n",
      "ğŸ“ˆ Sales agregadas por producto: (22349, 7)\n",
      "Primeras filas de sales agregadas:\n",
      "   product_id      fecha periodo          tn  num_customers  \\\n",
      "0       20001 2017-01-01  201701   934.77222            186   \n",
      "1       20001 2017-02-01  201702   798.01620            185   \n",
      "2       20001 2017-03-01  201703  1303.35771            188   \n",
      "3       20001 2017-04-01  201704  1069.96130            104   \n",
      "4       20001 2017-05-01  201705  1502.20132            238   \n",
      "\n",
      "   total_request_qty  total_request_tn  \n",
      "0                479         937.72717  \n",
      "1                432         833.72187  \n",
      "2                509        1330.74697  \n",
      "3                279        1132.94430  \n",
      "4                701        1550.68936  \n",
      "\n",
      "ğŸ“Š EstadÃ­sticas por producto:\n",
      "  Promedio tn por producto-perÃ­odo: 50.23\n",
      "  Promedio clientes por producto-perÃ­odo: 102.62\n",
      "  Productos Ãºnicos: 780\n",
      "  PerÃ­odos Ãºnicos: 36\n",
      "ğŸ“ˆ Sales agregadas por producto: (22349, 7)\n",
      "Primeras filas de sales agregadas:\n",
      "   product_id      fecha periodo          tn  num_customers  \\\n",
      "0       20001 2017-01-01  201701   934.77222            186   \n",
      "1       20001 2017-02-01  201702   798.01620            185   \n",
      "2       20001 2017-03-01  201703  1303.35771            188   \n",
      "3       20001 2017-04-01  201704  1069.96130            104   \n",
      "4       20001 2017-05-01  201705  1502.20132            238   \n",
      "\n",
      "   total_request_qty  total_request_tn  \n",
      "0                479         937.72717  \n",
      "1                432         833.72187  \n",
      "2                509        1330.74697  \n",
      "3                279        1132.94430  \n",
      "4                701        1550.68936  \n",
      "\n",
      "ğŸ“Š EstadÃ­sticas por producto:\n",
      "  Promedio tn por producto-perÃ­odo: 50.23\n",
      "  Promedio clientes por producto-perÃ­odo: 102.62\n",
      "  Productos Ãºnicos: 780\n",
      "  PerÃ­odos Ãºnicos: 36\n"
     ]
    }
   ],
   "source": [
    "# ğŸ§¹ PreparaciÃ³n de datos para el modelo LightGBM\n",
    "print(\"PREPARACIÃ“N DE DATOS PARA LGBM - GRANULARIDAD POR PRODUCTO\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Convertir perÃ­odo a datetime para facilitar manipulaciÃ³n\n",
    "sales['fecha'] = pd.to_datetime(sales['periodo'], format='%Y%m')\n",
    "stocks['fecha'] = pd.to_datetime(stocks['periodo'], format='%Y%m')\n",
    "\n",
    "# Filtrar solo productos que necesitamos predecir\n",
    "if 'product_id' in product_predict.columns:\n",
    "    productos_objetivo = product_predict['product_id'].tolist()\n",
    "else:\n",
    "    productos_objetivo = product_predict[product_predict.columns[0]].tolist()\n",
    "\n",
    "print(f\"ğŸ¯ Productos objetivo: {len(productos_objetivo)}\")\n",
    "\n",
    "# Filtrar sales y stocks para productos objetivo\n",
    "sales_filtered = sales[sales['product_id'].isin(productos_objetivo)].copy()\n",
    "stocks_filtered = stocks[stocks['product_id'].isin(productos_objetivo)].copy()\n",
    "\n",
    "print(f\"ğŸ“Š Sales filtradas: {sales_filtered.shape}\")\n",
    "print(f\"ğŸ“¦ Stocks filtradas: {stocks_filtered.shape}\")\n",
    "\n",
    "# AGREGACIÃ“N POR PRODUCTO: Sumar por producto y perÃ­odo (agregando todos los clientes)\n",
    "sales_agg = sales_filtered.groupby(['product_id', 'fecha', 'periodo']).agg({\n",
    "    'tn': 'sum',                    # Total toneladas por producto\n",
    "    'customer_id': 'nunique',       # NÃºmero de clientes Ãºnicos\n",
    "    'cust_request_qty': 'sum',      # Total cantidad solicitada\n",
    "    'cust_request_tn': 'sum'        # Total toneladas solicitadas\n",
    "}).reset_index()\n",
    "\n",
    "# Renombrar columnas para claridad\n",
    "sales_agg.rename(columns={\n",
    "    'customer_id': 'num_customers',\n",
    "    'cust_request_qty': 'total_request_qty', \n",
    "    'cust_request_tn': 'total_request_tn'\n",
    "}, inplace=True)\n",
    "\n",
    "print(f\"ğŸ“ˆ Sales agregadas por producto: {sales_agg.shape}\")\n",
    "print(\"Primeras filas de sales agregadas:\")\n",
    "print(sales_agg.head())\n",
    "\n",
    "print(f\"\\nğŸ“Š EstadÃ­sticas por producto:\")\n",
    "print(f\"  Promedio tn por producto-perÃ­odo: {sales_agg['tn'].mean():.2f}\")\n",
    "print(f\"  Promedio clientes por producto-perÃ­odo: {sales_agg['num_customers'].mean():.2f}\")\n",
    "print(f\"  Productos Ãºnicos: {sales_agg['product_id'].nunique()}\")\n",
    "print(f\"  PerÃ­odos Ãºnicos: {sales_agg['periodo'].nunique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "511ecf79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CREACIÃ“N DE FEATURES POR PRODUCTO\n",
      "==================================================\n",
      "ğŸ“Š Sales con lags por producto: (22349, 18)\n",
      "ğŸ“¦ Datos combinados con stock por producto: (22349, 26)\n",
      "Columnas disponibles: 26\n",
      "\n",
      "Primeras columnas:\n",
      "['product_id', 'fecha', 'periodo', 'tn', 'num_customers', 'total_request_qty', 'total_request_tn', 'tn_lag_1', 'tn_lag_2', 'tn_lag_3', 'tn_lag_6', 'tn_lag_12', 'num_customers_lag_1', 'num_customers_lag_2', 'num_customers_lag_3']\n",
      "Ãšltimas columnas:\n",
      "['total_request_tn_lag_2', 'total_request_tn_lag_3', 'stock_tn_mean', 'stock_tn_sum', 'stock_tn_std', 'stock_tn_mean_lag_1', 'stock_tn_mean_lag_2', 'stock_tn_mean_lag_3', 'stock_tn_sum_lag_1', 'stock_tn_sum_lag_2']\n"
     ]
    }
   ],
   "source": [
    "# ğŸ”§ Crear features de lag y combinar con stocks - GRANULARIDAD POR PRODUCTO\n",
    "print(\"CREACIÃ“N DE FEATURES POR PRODUCTO\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Crear features de lag para cada producto\n",
    "def create_lag_features(df, product_col, value_col, date_col, lags=[1, 2, 3, 6, 12]):\n",
    "    \"\"\"Crear features de lag para series temporales por producto\"\"\"\n",
    "    df_features = df.copy()\n",
    "    df_features = df_features.sort_values([product_col, date_col])\n",
    "    \n",
    "    for lag in lags:\n",
    "        df_features[f'{value_col}_lag_{lag}'] = df_features.groupby(product_col)[value_col].shift(lag)\n",
    "    \n",
    "    return df_features\n",
    "\n",
    "# Crear lags para ventas (tn) por producto\n",
    "sales_with_lags = create_lag_features(\n",
    "    sales_agg, \n",
    "    'product_id', \n",
    "    'tn', \n",
    "    'fecha', \n",
    "    lags=[1, 2, 3, 6, 12]\n",
    ")\n",
    "\n",
    "# Crear lags para nÃºmero de clientes por producto\n",
    "sales_with_lags = create_lag_features(\n",
    "    sales_with_lags, \n",
    "    'product_id', \n",
    "    'num_customers', \n",
    "    'fecha', \n",
    "    lags=[1, 2, 3]\n",
    ")\n",
    "\n",
    "# Crear lags para solicitudes de clientes\n",
    "sales_with_lags = create_lag_features(\n",
    "    sales_with_lags, \n",
    "    'product_id', \n",
    "    'total_request_tn', \n",
    "    'fecha', \n",
    "    lags=[1, 2, 3]\n",
    ")\n",
    "\n",
    "print(f\"ğŸ“Š Sales con lags por producto: {sales_with_lags.shape}\")\n",
    "\n",
    "# Agregar datos de stock por producto\n",
    "stocks_agg = stocks_filtered.groupby(['product_id', 'fecha', 'periodo']).agg({\n",
    "    'stock_final': ['mean', 'sum', 'std']  # Stock promedio, total y desviaciÃ³n estÃ¡ndar por producto\n",
    "}).reset_index()\n",
    "\n",
    "# Aplanar columnas multinivel\n",
    "stocks_agg.columns = ['product_id', 'fecha', 'periodo', 'stock_tn_mean', 'stock_tn_sum', 'stock_tn_std']\n",
    "stocks_agg['stock_tn_std'] = stocks_agg['stock_tn_std'].fillna(0)  # Rellenar NaN en std\n",
    "\n",
    "# Combinar sales y stocks por producto\n",
    "data_combined = pd.merge(\n",
    "    sales_with_lags, \n",
    "    stocks_agg[['product_id', 'fecha', 'stock_tn_mean', 'stock_tn_sum', 'stock_tn_std']], \n",
    "    on=['product_id', 'fecha'], \n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# Crear lags para stock por producto\n",
    "data_combined = create_lag_features(\n",
    "    data_combined, \n",
    "    'product_id', \n",
    "    'stock_tn_mean', \n",
    "    'fecha', \n",
    "    lags=[1, 2, 3]\n",
    ")\n",
    "\n",
    "data_combined = create_lag_features(\n",
    "    data_combined, \n",
    "    'product_id', \n",
    "    'stock_tn_sum', \n",
    "    'fecha', \n",
    "    lags=[1, 2]\n",
    ")\n",
    "\n",
    "print(f\"ğŸ“¦ Datos combinados con stock por producto: {data_combined.shape}\")\n",
    "print(f\"Columnas disponibles: {len(data_combined.columns)}\")\n",
    "print(\"\\nPrimeras columnas:\")\n",
    "print(data_combined.columns.tolist()[:15])\n",
    "print(\"Ãšltimas columnas:\")\n",
    "print(data_combined.columns.tolist()[-10:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a7e73cfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CREACIÃ“N DE TARGET Y FEATURES ADICIONALES\n",
      "==================================================\n",
      "âœ… InformaciÃ³n de productos agregada\n",
      "ğŸ“Š Dataset final: (22349, 40)\n",
      "ğŸ“ˆ Registros con target vÃ¡lido: 20789\n",
      "\n",
      "ğŸ“Š EstadÃ­sticas del target:\n",
      "count    20789.000000\n",
      "mean        50.931444\n",
      "std        127.140873\n",
      "min          0.000890\n",
      "25%          3.009870\n",
      "50%         11.928920\n",
      "75%         36.636220\n",
      "max       2295.198320\n",
      "Name: target, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# ğŸ¯ Crear target y features adicionales\n",
    "print(\"CREACIÃ“N DE TARGET Y FEATURES ADICIONALES\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Crear target: tn de 2 perÃ­odos a futuro\n",
    "data_combined = data_combined.sort_values(['product_id', 'fecha'])\n",
    "data_combined['target'] = data_combined.groupby('product_id')['tn'].shift(-2)\n",
    "\n",
    "# Crear features temporales\n",
    "data_combined['mes'] = data_combined['fecha'].dt.month\n",
    "data_combined['trimestre'] = data_combined['fecha'].dt.quarter\n",
    "data_combined['aÃ±o'] = data_combined['fecha'].dt.year\n",
    "\n",
    "# Crear features estadÃ­sticas mÃ³viles\n",
    "def create_rolling_features(df, product_col, value_col, date_col, windows=[3, 6, 12]):\n",
    "    \"\"\"Crear features de ventanas mÃ³viles\"\"\"\n",
    "    df = df.sort_values([product_col, date_col])\n",
    "    \n",
    "    for window in windows:\n",
    "        df[f'{value_col}_rolling_mean_{window}'] = df.groupby(product_col)[value_col].rolling(window, min_periods=1).mean().reset_index(level=0, drop=True)\n",
    "        df[f'{value_col}_rolling_std_{window}'] = df.groupby(product_col)[value_col].rolling(window, min_periods=1).std().reset_index(level=0, drop=True)\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Crear rolling features para ventas\n",
    "data_combined = create_rolling_features(data_combined, 'product_id', 'tn', 'fecha', windows=[3, 6])\n",
    "\n",
    "# Agregar informaciÃ³n de productos si estÃ¡ disponible\n",
    "if len(product_info) > 0:\n",
    "    data_combined = pd.merge(\n",
    "        data_combined, \n",
    "        product_info, \n",
    "        on='product_id', \n",
    "        how='left'\n",
    "    )\n",
    "    print(f\"âœ… InformaciÃ³n de productos agregada\")\n",
    "\n",
    "print(f\"ğŸ“Š Dataset final: {data_combined.shape}\")\n",
    "print(f\"ğŸ“ˆ Registros con target vÃ¡lido: {data_combined['target'].notna().sum()}\")\n",
    "\n",
    "# Mostrar algunas estadÃ­sticas del target\n",
    "target_stats = data_combined['target'].describe()\n",
    "print(f\"\\nğŸ“Š EstadÃ­sticas del target:\")\n",
    "print(target_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5c228b6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PREPARACIÃ“N DE DATOS DE ENTRENAMIENTO POR PRODUCTO\n",
      "============================================================\n",
      "ğŸ“Š Registros vÃ¡lidos para entrenamiento: 20789\n",
      "âœ… Features disponibles: 29\n",
      "âš ï¸ Features faltantes: 0\n",
      "ğŸ“Š Shape de X: (20789, 29)\n",
      "ğŸ“ˆ Shape de y: (20789,)\n",
      "ğŸ” Valores nulos en X: 0\n",
      "ğŸ” Valores nulos en y: 0\n",
      "\n",
      "ğŸ“Š DIVISIÃ“N TEMPORAL:\n",
      "Entrenamiento: 16970 registros (hasta 2019-05)\n",
      "ValidaciÃ³n: 3819 registros (desde 2019-05)\n",
      "\n",
      "ğŸ¯ PRODUCTOS EN ENTRENAMIENTO:\n",
      "Productos Ãºnicos en entrenamiento: 718\n",
      "Productos Ãºnicos en validaciÃ³n: 780\n",
      "\n",
      "Features seleccionadas para granularidad por producto:\n",
      "   1. tn_lag_1\n",
      "   2. tn_lag_2\n",
      "   3. tn_lag_3\n",
      "   4. tn_lag_6\n",
      "   5. tn_lag_12\n",
      "   6. num_customers_lag_1\n",
      "   7. num_customers_lag_2\n",
      "   8. num_customers_lag_3\n",
      "   9. total_request_tn_lag_1\n",
      "  10. total_request_tn_lag_2\n",
      "  11. total_request_tn_lag_3\n",
      "  12. stock_tn_mean_lag_1\n",
      "  13. stock_tn_mean_lag_2\n",
      "  14. stock_tn_mean_lag_3\n",
      "  15. stock_tn_sum_lag_1\n",
      "  16. stock_tn_sum_lag_2\n",
      "  17. mes\n",
      "  18. trimestre\n",
      "  19. aÃ±o\n",
      "  20. tn_rolling_mean_3\n",
      "  21. tn_rolling_mean_6\n",
      "  22. tn_rolling_std_3\n",
      "  23. tn_rolling_std_6\n",
      "  24. num_customers\n",
      "  25. total_request_qty\n",
      "  26. total_request_tn\n",
      "  27. stock_tn_mean\n",
      "  28. stock_tn_sum\n",
      "  29. stock_tn_std\n"
     ]
    }
   ],
   "source": [
    "# ğŸ“‹ Preparar datos para entrenamiento - GRANULARIDAD POR PRODUCTO\n",
    "print(\"PREPARACIÃ“N DE DATOS DE ENTRENAMIENTO POR PRODUCTO\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Filtrar registros con target vÃ¡lido\n",
    "train_data = data_combined[data_combined['target'].notna()].copy()\n",
    "print(f\"ğŸ“Š Registros vÃ¡lidos para entrenamiento: {len(train_data)}\")\n",
    "\n",
    "# Seleccionar features para el modelo con granularidad por producto\n",
    "feature_columns = [\n",
    "    # Lags de ventas (tn) por producto\n",
    "    'tn_lag_1', 'tn_lag_2', 'tn_lag_3', 'tn_lag_6', 'tn_lag_12',\n",
    "    \n",
    "    # Lags de clientes por producto\n",
    "    'num_customers_lag_1', 'num_customers_lag_2', 'num_customers_lag_3',\n",
    "    \n",
    "    # Lags de solicitudes por producto\n",
    "    'total_request_tn_lag_1', 'total_request_tn_lag_2', 'total_request_tn_lag_3',\n",
    "    \n",
    "    # Lags de stock por producto\n",
    "    'stock_tn_mean_lag_1', 'stock_tn_mean_lag_2', 'stock_tn_mean_lag_3',\n",
    "    'stock_tn_sum_lag_1', 'stock_tn_sum_lag_2',\n",
    "    \n",
    "    # Features temporales\n",
    "    'mes', 'trimestre', 'aÃ±o',\n",
    "    \n",
    "    # Rolling features por producto\n",
    "    'tn_rolling_mean_3', 'tn_rolling_mean_6',\n",
    "    'tn_rolling_std_3', 'tn_rolling_std_6',\n",
    "    \n",
    "    # Features actuales por producto\n",
    "    'num_customers', 'total_request_qty', 'total_request_tn',\n",
    "    'stock_tn_mean', 'stock_tn_sum', 'stock_tn_std'\n",
    "]\n",
    "\n",
    "# Verificar quÃ© features existen\n",
    "available_features = [col for col in feature_columns if col in train_data.columns]\n",
    "missing_features = [col for col in feature_columns if col not in train_data.columns]\n",
    "\n",
    "print(f\"âœ… Features disponibles: {len(available_features)}\")\n",
    "print(f\"âš ï¸ Features faltantes: {len(missing_features)}\")\n",
    "if missing_features:\n",
    "    print(f\"Features faltantes: {missing_features}\")\n",
    "\n",
    "# Usar solo features disponibles\n",
    "feature_columns = available_features\n",
    "\n",
    "# Preparar X e y\n",
    "X = train_data[feature_columns].copy()\n",
    "y = train_data['target'].copy()\n",
    "\n",
    "# Rellenar valores nulos con 0 (para lags iniciales y stocks faltantes)\n",
    "X = X.fillna(0)\n",
    "\n",
    "print(f\"ğŸ“Š Shape de X: {X.shape}\")\n",
    "print(f\"ğŸ“ˆ Shape de y: {y.shape}\")\n",
    "print(f\"ğŸ” Valores nulos en X: {X.isnull().sum().sum()}\")\n",
    "print(f\"ğŸ” Valores nulos en y: {y.isnull().sum()}\")\n",
    "\n",
    "# DivisiÃ³n temporal para validaciÃ³n (Ãºltimos perÃ­odos como validaciÃ³n)\n",
    "train_data_sorted = train_data.sort_values('fecha')\n",
    "split_date = train_data_sorted['fecha'].quantile(0.8)  # 80% entrenamiento, 20% validaciÃ³n\n",
    "\n",
    "train_mask = train_data_sorted['fecha'] <= split_date\n",
    "X_train = X.loc[train_mask]\n",
    "X_val = X.loc[~train_mask] \n",
    "y_train = y.loc[train_mask]\n",
    "y_val = y.loc[~train_mask]\n",
    "\n",
    "print(f\"\\nğŸ“Š DIVISIÃ“N TEMPORAL:\")\n",
    "print(f\"Entrenamiento: {len(X_train)} registros (hasta {split_date.strftime('%Y-%m')})\")\n",
    "print(f\"ValidaciÃ³n: {len(X_val)} registros (desde {split_date.strftime('%Y-%m')})\")\n",
    "\n",
    "print(f\"\\nğŸ¯ PRODUCTOS EN ENTRENAMIENTO:\")\n",
    "productos_train = train_data.loc[train_mask, 'product_id'].nunique()\n",
    "productos_val = train_data.loc[~train_mask, 'product_id'].nunique()\n",
    "print(f\"Productos Ãºnicos en entrenamiento: {productos_train}\")\n",
    "print(f\"Productos Ãºnicos en validaciÃ³n: {productos_val}\")\n",
    "\n",
    "print(f\"\\nFeatures seleccionadas para granularidad por producto:\")\n",
    "for i, feat in enumerate(feature_columns):\n",
    "    print(f\"  {i+1:2d}. {feat}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c842ebac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-09 11:05:22,112] A new study created in memory with name: no-name-af20972a-786e-435c-878e-eb46e28ddcad\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OPTIMIZACIÃ“N DE HIPERPARÃMETROS CON OPTUNA\n",
      "============================================================\n",
      "ğŸ” Iniciando optimizaciÃ³n de hiperparÃ¡metros...\n",
      "ğŸš€ Ejecutando 50 trials de optimizaciÃ³n...\n",
      "ğŸš€ Ejecutando 50 trials de optimizaciÃ³n...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e15858af3f54be5981834ee4a9b10a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[337]\tvalid_0's l1: 11.1105\n",
      "[I 2025-08-09 11:05:23,706] Trial 0 finished with value: 11.110499810403493 and parameters: {'lambda_l1': 0.749080237694725, 'lambda_l2': 1.9014286128198323, 'num_leaves': 113, 'feature_fraction': 0.759195090518222, 'learning_rate': 0.01700037298921102, 'bagging_fraction': 0.49359671220172163, 'bagging_freq': 1, 'min_child_samples': 44, 'max_bin': 341}. Best is trial 0 with value: 11.110499810403493.\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[337]\tvalid_0's l1: 11.1105\n",
      "[I 2025-08-09 11:05:23,706] Trial 0 finished with value: 11.110499810403493 and parameters: {'lambda_l1': 0.749080237694725, 'lambda_l2': 1.9014286128198323, 'num_leaves': 113, 'feature_fraction': 0.759195090518222, 'learning_rate': 0.01700037298921102, 'bagging_fraction': 0.49359671220172163, 'bagging_freq': 1, 'min_child_samples': 44, 'max_bin': 341}. Best is trial 0 with value: 11.110499810403493.\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[240]\tvalid_0's l1: 10.9198\n",
      "[I 2025-08-09 11:05:25,351] Trial 1 finished with value: 10.91979749572606 and parameters: {'lambda_l1': 1.416145155592091, 'lambda_l2': 0.041168988591604894, 'num_leaves': 146, 'feature_fraction': 0.899465584480253, 'learning_rate': 0.020589728197687916, 'bagging_fraction': 0.5090949803242604, 'bagging_freq': 2, 'min_child_samples': 18, 'max_bin': 310}. Best is trial 1 with value: 10.91979749572606.\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[240]\tvalid_0's l1: 10.9198\n",
      "[I 2025-08-09 11:05:25,351] Trial 1 finished with value: 10.91979749572606 and parameters: {'lambda_l1': 1.416145155592091, 'lambda_l2': 0.041168988591604894, 'num_leaves': 146, 'feature_fraction': 0.899465584480253, 'learning_rate': 0.020589728197687916, 'bagging_fraction': 0.5090949803242604, 'bagging_freq': 2, 'min_child_samples': 18, 'max_bin': 310}. Best is trial 1 with value: 10.91979749572606.\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[241]\tvalid_0's l1: 11.048\n",
      "[I 2025-08-09 11:05:26,366] Trial 2 finished with value: 11.048026900447015 and parameters: {'lambda_l1': 0.8638900372842315, 'lambda_l2': 0.5824582803960838, 'num_leaves': 96, 'feature_fraction': 0.4836963163912251, 'learning_rate': 0.027010527749605478, 'bagging_fraction': 0.619817105976215, 'bagging_freq': 5, 'min_child_samples': 41, 'max_bin': 180}. Best is trial 1 with value: 10.91979749572606.\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[241]\tvalid_0's l1: 11.048\n",
      "[I 2025-08-09 11:05:26,366] Trial 2 finished with value: 11.048026900447015 and parameters: {'lambda_l1': 0.8638900372842315, 'lambda_l2': 0.5824582803960838, 'num_leaves': 96, 'feature_fraction': 0.4836963163912251, 'learning_rate': 0.027010527749605478, 'bagging_fraction': 0.619817105976215, 'bagging_freq': 5, 'min_child_samples': 41, 'max_bin': 180}. Best is trial 1 with value: 10.91979749572606.\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[369]\tvalid_0's l1: 11.2706\n",
      "[I 2025-08-09 11:05:26,774] Trial 3 finished with value: 11.270581029165852 and parameters: {'lambda_l1': 1.0284688768272232, 'lambda_l2': 1.184829137724085, 'num_leaves': 16, 'feature_fraction': 0.764526911140863, 'learning_rate': 0.0178601378893971, 'bagging_fraction': 0.43903095579116774, 'bagging_freq': 10, 'min_child_samples': 49, 'max_bin': 424}. Best is trial 1 with value: 10.91979749572606.\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[369]\tvalid_0's l1: 11.2706\n",
      "[I 2025-08-09 11:05:26,774] Trial 3 finished with value: 11.270581029165852 and parameters: {'lambda_l1': 1.0284688768272232, 'lambda_l2': 1.184829137724085, 'num_leaves': 16, 'feature_fraction': 0.764526911140863, 'learning_rate': 0.0178601378893971, 'bagging_fraction': 0.43903095579116774, 'bagging_freq': 10, 'min_child_samples': 49, 'max_bin': 424}. Best is trial 1 with value: 10.91979749572606.\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[464]\tvalid_0's l1: 10.8577\n",
      "[I 2025-08-09 11:05:28,648] Trial 4 finished with value: 10.857697485053373 and parameters: {'lambda_l1': 0.6092275383467414, 'lambda_l2': 0.19534422801276774, 'num_leaves': 106, 'feature_fraction': 0.6640914962437607, 'learning_rate': 0.015144860262751412, 'bagging_fraction': 0.6971061460667621, 'bagging_freq': 1, 'min_child_samples': 46, 'max_bin': 203}. Best is trial 4 with value: 10.857697485053373.\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[464]\tvalid_0's l1: 10.8577\n",
      "[I 2025-08-09 11:05:28,648] Trial 4 finished with value: 10.857697485053373 and parameters: {'lambda_l1': 0.6092275383467414, 'lambda_l2': 0.19534422801276774, 'num_leaves': 106, 'feature_fraction': 0.6640914962437607, 'learning_rate': 0.015144860262751412, 'bagging_fraction': 0.6971061460667621, 'bagging_freq': 1, 'min_child_samples': 46, 'max_bin': 203}. Best is trial 4 with value: 10.857697485053373.\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[305]\tvalid_0's l1: 10.8501\n",
      "[I 2025-08-09 11:05:30,049] Trial 5 finished with value: 10.850135370422077 and parameters: {'lambda_l1': 1.325044568707964, 'lambda_l2': 0.6234221521788219, 'num_leaves': 83, 'feature_fraction': 0.7280261676059678, 'learning_rate': 0.01875220945578641, 'bagging_fraction': 0.9817507766587351, 'bagging_freq': 8, 'min_child_samples': 48, 'max_bin': 458}. Best is trial 5 with value: 10.850135370422077.\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[305]\tvalid_0's l1: 10.8501\n",
      "[I 2025-08-09 11:05:30,049] Trial 5 finished with value: 10.850135370422077 and parameters: {'lambda_l1': 1.325044568707964, 'lambda_l2': 0.6234221521788219, 'num_leaves': 83, 'feature_fraction': 0.7280261676059678, 'learning_rate': 0.01875220945578641, 'bagging_fraction': 0.9817507766587351, 'bagging_freq': 8, 'min_child_samples': 48, 'max_bin': 458}. Best is trial 5 with value: 10.850135370422077.\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[711]\tvalid_0's l1: 10.9958\n",
      "[I 2025-08-09 11:05:31,023] Trial 6 finished with value: 10.995796095892699 and parameters: {'lambda_l1': 1.1957999576221703, 'lambda_l2': 1.8437484700462337, 'num_leaves': 22, 'feature_fraction': 0.5175897174514872, 'learning_rate': 0.011662890273931383, 'bagging_fraction': 0.5951981984579586, 'bagging_freq': 4, 'min_child_samples': 17, 'max_bin': 432}. Best is trial 5 with value: 10.850135370422077.\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[711]\tvalid_0's l1: 10.9958\n",
      "[I 2025-08-09 11:05:31,023] Trial 6 finished with value: 10.995796095892699 and parameters: {'lambda_l1': 1.1957999576221703, 'lambda_l2': 1.8437484700462337, 'num_leaves': 22, 'feature_fraction': 0.5175897174514872, 'learning_rate': 0.011662890273931383, 'bagging_fraction': 0.5951981984579586, 'bagging_freq': 4, 'min_child_samples': 17, 'max_bin': 432}. Best is trial 5 with value: 10.850135370422077.\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[72]\tvalid_0's l1: 11.3378\n",
      "[I 2025-08-09 11:05:31,541] Trial 7 finished with value: 11.337804120038898 and parameters: {'lambda_l1': 0.7135066533871786, 'lambda_l2': 0.5618690193747615, 'num_leaves': 86, 'feature_fraction': 0.4845545349848576, 'learning_rate': 0.1530883741573138, 'bagging_fraction': 0.44473038620786254, 'bagging_freq': 10, 'min_child_samples': 40, 'max_bin': 179}. Best is trial 5 with value: 10.850135370422077.\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[72]\tvalid_0's l1: 11.3378\n",
      "[I 2025-08-09 11:05:31,541] Trial 7 finished with value: 11.337804120038898 and parameters: {'lambda_l1': 0.7135066533871786, 'lambda_l2': 0.5618690193747615, 'num_leaves': 86, 'feature_fraction': 0.4845545349848576, 'learning_rate': 0.1530883741573138, 'bagging_fraction': 0.44473038620786254, 'bagging_freq': 10, 'min_child_samples': 40, 'max_bin': 179}. Best is trial 5 with value: 10.850135370422077.\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[41]\tvalid_0's l1: 11.281\n",
      "[I 2025-08-09 11:05:32,073] Trial 8 finished with value: 11.280990481791271 and parameters: {'lambda_l1': 0.011044234247204798, 'lambda_l2': 1.6309228569096683, 'num_leaves': 109, 'feature_fraction': 0.8374043008245924, 'learning_rate': 0.13780336485751998, 'bagging_fraction': 0.44442679104045424, 'bagging_freq': 4, 'min_child_samples': 10, 'max_bin': 446}. Best is trial 5 with value: 10.850135370422077.\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[41]\tvalid_0's l1: 11.281\n",
      "[I 2025-08-09 11:05:32,073] Trial 8 finished with value: 11.280990481791271 and parameters: {'lambda_l1': 0.011044234247204798, 'lambda_l2': 1.6309228569096683, 'num_leaves': 109, 'feature_fraction': 0.8374043008245924, 'learning_rate': 0.13780336485751998, 'bagging_fraction': 0.44442679104045424, 'bagging_freq': 4, 'min_child_samples': 10, 'max_bin': 446}. Best is trial 5 with value: 10.850135370422077.\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[254]\tvalid_0's l1: 11.0206\n",
      "[I 2025-08-09 11:05:32,463] Trial 9 finished with value: 11.020625371684744 and parameters: {'lambda_l1': 1.2465962536551158, 'lambda_l2': 0.6617960497052984, 'num_leaves': 18, 'feature_fraction': 0.5865893930293973, 'learning_rate': 0.030222834756467344, 'bagging_fraction': 0.8377637070028385, 'bagging_freq': 7, 'min_child_samples': 45, 'max_bin': 289}. Best is trial 5 with value: 10.850135370422077.\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[254]\tvalid_0's l1: 11.0206\n",
      "[I 2025-08-09 11:05:32,463] Trial 9 finished with value: 11.020625371684744 and parameters: {'lambda_l1': 1.2465962536551158, 'lambda_l2': 0.6617960497052984, 'num_leaves': 18, 'feature_fraction': 0.5865893930293973, 'learning_rate': 0.030222834756467344, 'bagging_fraction': 0.8377637070028385, 'bagging_freq': 7, 'min_child_samples': 45, 'max_bin': 289}. Best is trial 5 with value: 10.850135370422077.\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[142]\tvalid_0's l1: 11.1428\n",
      "[I 2025-08-09 11:05:33,250] Trial 10 finished with value: 11.142813009718367 and parameters: {'lambda_l1': 1.9255002064579485, 'lambda_l2': 1.1559704609452126, 'num_leaves': 55, 'feature_fraction': 0.9593742051470726, 'learning_rate': 0.060280072870289664, 'bagging_fraction': 0.9445988771695107, 'bagging_freq': 8, 'min_child_samples': 32, 'max_bin': 488}. Best is trial 5 with value: 10.850135370422077.\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[142]\tvalid_0's l1: 11.1428\n",
      "[I 2025-08-09 11:05:33,250] Trial 10 finished with value: 11.142813009718367 and parameters: {'lambda_l1': 1.9255002064579485, 'lambda_l2': 1.1559704609452126, 'num_leaves': 55, 'feature_fraction': 0.9593742051470726, 'learning_rate': 0.060280072870289664, 'bagging_fraction': 0.9445988771695107, 'bagging_freq': 8, 'min_child_samples': 32, 'max_bin': 488}. Best is trial 5 with value: 10.850135370422077.\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[189]\tvalid_0's l1: 10.7515\n",
      "[I 2025-08-09 11:05:33,863] Trial 11 finished with value: 10.751519127182027 and parameters: {'lambda_l1': 0.2511059440930814, 'lambda_l2': 0.05955379583755582, 'num_leaves': 60, 'feature_fraction': 0.6395327254203782, 'learning_rate': 0.05545225037953748, 'bagging_fraction': 0.7321356670023261, 'bagging_freq': 7, 'min_child_samples': 32, 'max_bin': 112}. Best is trial 11 with value: 10.751519127182027.\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[189]\tvalid_0's l1: 10.7515\n",
      "[I 2025-08-09 11:05:33,863] Trial 11 finished with value: 10.751519127182027 and parameters: {'lambda_l1': 0.2511059440930814, 'lambda_l2': 0.05955379583755582, 'num_leaves': 60, 'feature_fraction': 0.6395327254203782, 'learning_rate': 0.05545225037953748, 'bagging_fraction': 0.7321356670023261, 'bagging_freq': 7, 'min_child_samples': 32, 'max_bin': 112}. Best is trial 11 with value: 10.751519127182027.\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[87]\tvalid_0's l1: 10.7105\n",
      "[I 2025-08-09 11:05:34,192] Trial 12 finished with value: 10.71050130838939 and parameters: {'lambda_l1': 0.1199832683280607, 'lambda_l2': 0.2900018255549278, 'num_leaves': 58, 'feature_fraction': 0.6187007206867036, 'learning_rate': 0.06909313164440407, 'bagging_fraction': 0.8534625355196006, 'bagging_freq': 7, 'min_child_samples': 32, 'max_bin': 102}. Best is trial 12 with value: 10.71050130838939.\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[87]\tvalid_0's l1: 10.7105\n",
      "[I 2025-08-09 11:05:34,192] Trial 12 finished with value: 10.71050130838939 and parameters: {'lambda_l1': 0.1199832683280607, 'lambda_l2': 0.2900018255549278, 'num_leaves': 58, 'feature_fraction': 0.6187007206867036, 'learning_rate': 0.06909313164440407, 'bagging_fraction': 0.8534625355196006, 'bagging_freq': 7, 'min_child_samples': 32, 'max_bin': 102}. Best is trial 12 with value: 10.71050130838939.\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[71]\tvalid_0's l1: 10.7535\n",
      "[I 2025-08-09 11:05:34,489] Trial 13 finished with value: 10.75351552332164 and parameters: {'lambda_l1': 0.023392341845768494, 'lambda_l2': 0.2828770553955577, 'num_leaves': 58, 'feature_fraction': 0.6116436969183914, 'learning_rate': 0.0723757756427942, 'bagging_fraction': 0.8164991658696965, 'bagging_freq': 7, 'min_child_samples': 30, 'max_bin': 107}. Best is trial 12 with value: 10.71050130838939.\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[19]\tvalid_0's l1: 11.3125\n",
      "[I 2025-08-09 11:05:34,645] Trial 14 finished with value: 11.312467481115755 and parameters: {'lambda_l1': 0.34743838790697035, 'lambda_l2': 0.02616620965234223, 'num_leaves': 45, 'feature_fraction': 0.405119828707704, 'learning_rate': 0.29565563003428347, 'bagging_fraction': 0.8062729073246514, 'bagging_freq': 6, 'min_child_samples': 23, 'max_bin': 118}. Best is trial 12 with value: 10.71050130838939.\n",
      "Early stopping, best iteration is:\n",
      "[71]\tvalid_0's l1: 10.7535\n",
      "[I 2025-08-09 11:05:34,489] Trial 13 finished with value: 10.75351552332164 and parameters: {'lambda_l1': 0.023392341845768494, 'lambda_l2': 0.2828770553955577, 'num_leaves': 58, 'feature_fraction': 0.6116436969183914, 'learning_rate': 0.0723757756427942, 'bagging_fraction': 0.8164991658696965, 'bagging_freq': 7, 'min_child_samples': 30, 'max_bin': 107}. Best is trial 12 with value: 10.71050130838939.\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[19]\tvalid_0's l1: 11.3125\n",
      "[I 2025-08-09 11:05:34,645] Trial 14 finished with value: 11.312467481115755 and parameters: {'lambda_l1': 0.34743838790697035, 'lambda_l2': 0.02616620965234223, 'num_leaves': 45, 'feature_fraction': 0.405119828707704, 'learning_rate': 0.29565563003428347, 'bagging_fraction': 0.8062729073246514, 'bagging_freq': 6, 'min_child_samples': 23, 'max_bin': 118}. Best is trial 12 with value: 10.71050130838939.\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[184]\tvalid_0's l1: 10.8684\n",
      "[I 2025-08-09 11:05:35,342] Trial 15 finished with value: 10.868437916019381 and parameters: {'lambda_l1': 0.3315146707433886, 'lambda_l2': 0.3864382510903843, 'num_leaves': 67, 'feature_fraction': 0.6329624047403581, 'learning_rate': 0.04241036621398397, 'bagging_fraction': 0.742584879154286, 'bagging_freq': 9, 'min_child_samples': 35, 'max_bin': 226}. Best is trial 12 with value: 10.71050130838939.\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[184]\tvalid_0's l1: 10.8684\n",
      "[I 2025-08-09 11:05:35,342] Trial 15 finished with value: 10.868437916019381 and parameters: {'lambda_l1': 0.3315146707433886, 'lambda_l2': 0.3864382510903843, 'num_leaves': 67, 'feature_fraction': 0.6329624047403581, 'learning_rate': 0.04241036621398397, 'bagging_fraction': 0.742584879154286, 'bagging_freq': 9, 'min_child_samples': 35, 'max_bin': 226}. Best is trial 12 with value: 10.71050130838939.\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[147]\tvalid_0's l1: 10.8507\n",
      "[I 2025-08-09 11:05:35,746] Trial 16 finished with value: 10.850738552180665 and parameters: {'lambda_l1': 0.29351365603538637, 'lambda_l2': 0.901424486373648, 'num_leaves': 40, 'feature_fraction': 0.552877794423218, 'learning_rate': 0.09457692440469626, 'bagging_fraction': 0.9122427333292663, 'bagging_freq': 6, 'min_child_samples': 27, 'max_bin': 137}. Best is trial 12 with value: 10.71050130838939.\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[147]\tvalid_0's l1: 10.8507\n",
      "[I 2025-08-09 11:05:35,746] Trial 16 finished with value: 10.850738552180665 and parameters: {'lambda_l1': 0.29351365603538637, 'lambda_l2': 0.901424486373648, 'num_leaves': 40, 'feature_fraction': 0.552877794423218, 'learning_rate': 0.09457692440469626, 'bagging_fraction': 0.9122427333292663, 'bagging_freq': 6, 'min_child_samples': 27, 'max_bin': 137}. Best is trial 12 with value: 10.71050130838939.\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[119]\tvalid_0's l1: 11.0156\n",
      "[I 2025-08-09 11:05:36,258] Trial 17 finished with value: 11.015555505125864 and parameters: {'lambda_l1': 0.4860755758565186, 'lambda_l2': 0.8977837367900416, 'num_leaves': 70, 'feature_fraction': 0.6945988817891031, 'learning_rate': 0.04621755506644064, 'bagging_fraction': 0.7148817639713086, 'bagging_freq': 8, 'min_child_samples': 36, 'max_bin': 150}. Best is trial 12 with value: 10.71050130838939.\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[119]\tvalid_0's l1: 11.0156\n",
      "[I 2025-08-09 11:05:36,258] Trial 17 finished with value: 11.015555505125864 and parameters: {'lambda_l1': 0.4860755758565186, 'lambda_l2': 0.8977837367900416, 'num_leaves': 70, 'feature_fraction': 0.6945988817891031, 'learning_rate': 0.04621755506644064, 'bagging_fraction': 0.7148817639713086, 'bagging_freq': 8, 'min_child_samples': 36, 'max_bin': 150}. Best is trial 12 with value: 10.71050130838939.\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[57]\tvalid_0's l1: 11.0883\n",
      "[I 2025-08-09 11:05:36,509] Trial 18 finished with value: 11.088256216526515 and parameters: {'lambda_l1': 0.11570169712787767, 'lambda_l2': 0.3477253241312479, 'num_leaves': 36, 'feature_fraction': 0.8090059331954651, 'learning_rate': 0.10163450321393216, 'bagging_fraction': 0.8961203865795027, 'bagging_freq': 4, 'min_child_samples': 23, 'max_bin': 260}. Best is trial 12 with value: 10.71050130838939.\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[57]\tvalid_0's l1: 11.0883\n",
      "[I 2025-08-09 11:05:36,509] Trial 18 finished with value: 11.088256216526515 and parameters: {'lambda_l1': 0.11570169712787767, 'lambda_l2': 0.3477253241312479, 'num_leaves': 36, 'feature_fraction': 0.8090059331954651, 'learning_rate': 0.10163450321393216, 'bagging_fraction': 0.8961203865795027, 'bagging_freq': 4, 'min_child_samples': 23, 'max_bin': 260}. Best is trial 12 with value: 10.71050130838939.\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[186]\tvalid_0's l1: 10.8858\n",
      "[I 2025-08-09 11:05:37,785] Trial 19 finished with value: 10.885767399003294 and parameters: {'lambda_l1': 1.594995700892736, 'lambda_l2': 0.01975423588473521, 'num_leaves': 134, 'feature_fraction': 0.42592050972458867, 'learning_rate': 0.03567509095739717, 'bagging_fraction': 0.6445976621655365, 'bagging_freq': 5, 'min_child_samples': 25, 'max_bin': 346}. Best is trial 12 with value: 10.71050130838939.\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[186]\tvalid_0's l1: 10.8858\n",
      "[I 2025-08-09 11:05:37,785] Trial 19 finished with value: 10.885767399003294 and parameters: {'lambda_l1': 1.594995700892736, 'lambda_l2': 0.01975423588473521, 'num_leaves': 134, 'feature_fraction': 0.42592050972458867, 'learning_rate': 0.03567509095739717, 'bagging_fraction': 0.6445976621655365, 'bagging_freq': 5, 'min_child_samples': 25, 'max_bin': 346}. Best is trial 12 with value: 10.71050130838939.\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[28]\tvalid_0's l1: 11.4533\n",
      "[I 2025-08-09 11:05:38,067] Trial 20 finished with value: 11.453280748443717 and parameters: {'lambda_l1': 0.2202783920423806, 'lambda_l2': 1.5232234730543914, 'num_leaves': 70, 'feature_fraction': 0.6665025934077063, 'learning_rate': 0.23492026021785897, 'bagging_fraction': 0.7791653185021064, 'bagging_freq': 7, 'min_child_samples': 5, 'max_bin': 239}. Best is trial 12 with value: 10.71050130838939.\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[28]\tvalid_0's l1: 11.4533\n",
      "[I 2025-08-09 11:05:38,067] Trial 20 finished with value: 11.453280748443717 and parameters: {'lambda_l1': 0.2202783920423806, 'lambda_l2': 1.5232234730543914, 'num_leaves': 70, 'feature_fraction': 0.6665025934077063, 'learning_rate': 0.23492026021785897, 'bagging_fraction': 0.7791653185021064, 'bagging_freq': 7, 'min_child_samples': 5, 'max_bin': 239}. Best is trial 12 with value: 10.71050130838939.\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[79]\tvalid_0's l1: 10.7273\n",
      "[I 2025-08-09 11:05:38,394] Trial 21 finished with value: 10.727295632552385 and parameters: {'lambda_l1': 0.00031427083671726683, 'lambda_l2': 0.3234941041937786, 'num_leaves': 53, 'feature_fraction': 0.6044498055044591, 'learning_rate': 0.06845325331255803, 'bagging_fraction': 0.8636840710551087, 'bagging_freq': 7, 'min_child_samples': 31, 'max_bin': 102}. Best is trial 12 with value: 10.71050130838939.\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[79]\tvalid_0's l1: 10.7273\n",
      "[I 2025-08-09 11:05:38,394] Trial 21 finished with value: 10.727295632552385 and parameters: {'lambda_l1': 0.00031427083671726683, 'lambda_l2': 0.3234941041937786, 'num_leaves': 53, 'feature_fraction': 0.6044498055044591, 'learning_rate': 0.06845325331255803, 'bagging_fraction': 0.8636840710551087, 'bagging_freq': 7, 'min_child_samples': 31, 'max_bin': 102}. Best is trial 12 with value: 10.71050130838939.\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[117]\tvalid_0's l1: 10.7215\n",
      "[I 2025-08-09 11:05:38,816] Trial 22 finished with value: 10.721451790582325 and parameters: {'lambda_l1': 0.5334453390958273, 'lambda_l2': 0.20209107659423764, 'num_leaves': 53, 'feature_fraction': 0.5785693076245654, 'learning_rate': 0.07075105704134364, 'bagging_fraction': 0.8497509362078095, 'bagging_freq': 9, 'min_child_samples': 35, 'max_bin': 107}. Best is trial 12 with value: 10.71050130838939.\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[117]\tvalid_0's l1: 10.7215\n",
      "[I 2025-08-09 11:05:38,816] Trial 22 finished with value: 10.721451790582325 and parameters: {'lambda_l1': 0.5334453390958273, 'lambda_l2': 0.20209107659423764, 'num_leaves': 53, 'feature_fraction': 0.5785693076245654, 'learning_rate': 0.07075105704134364, 'bagging_fraction': 0.8497509362078095, 'bagging_freq': 9, 'min_child_samples': 35, 'max_bin': 107}. Best is trial 12 with value: 10.71050130838939.\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[84]\tvalid_0's l1: 10.9638\n",
      "[I 2025-08-09 11:05:39,094] Trial 23 finished with value: 10.963802814726657 and parameters: {'lambda_l1': 0.46963171188454544, 'lambda_l2': 0.4332097004135722, 'num_leaves': 34, 'feature_fraction': 0.5662274996770582, 'learning_rate': 0.08149272763461118, 'bagging_fraction': 0.8707417699902844, 'bagging_freq': 9, 'min_child_samples': 36, 'max_bin': 155}. Best is trial 12 with value: 10.71050130838939.\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[84]\tvalid_0's l1: 10.9638\n",
      "[I 2025-08-09 11:05:39,094] Trial 23 finished with value: 10.963802814726657 and parameters: {'lambda_l1': 0.46963171188454544, 'lambda_l2': 0.4332097004135722, 'num_leaves': 34, 'feature_fraction': 0.5662274996770582, 'learning_rate': 0.08149272763461118, 'bagging_fraction': 0.8707417699902844, 'bagging_freq': 9, 'min_child_samples': 36, 'max_bin': 155}. Best is trial 12 with value: 10.71050130838939.\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[62]\tvalid_0's l1: 10.9587\n",
      "[I 2025-08-09 11:05:39,384] Trial 24 finished with value: 10.958716655134715 and parameters: {'lambda_l1': 0.5007550333685669, 'lambda_l2': 0.7752638014947741, 'num_leaves': 47, 'feature_fraction': 0.5251924653256786, 'learning_rate': 0.12962242877211058, 'bagging_fraction': 0.9777417848888165, 'bagging_freq': 9, 'min_child_samples': 39, 'max_bin': 105}. Best is trial 12 with value: 10.71050130838939.\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[62]\tvalid_0's l1: 10.9587\n",
      "[I 2025-08-09 11:05:39,384] Trial 24 finished with value: 10.958716655134715 and parameters: {'lambda_l1': 0.5007550333685669, 'lambda_l2': 0.7752638014947741, 'num_leaves': 47, 'feature_fraction': 0.5251924653256786, 'learning_rate': 0.12962242877211058, 'bagging_fraction': 0.9777417848888165, 'bagging_freq': 9, 'min_child_samples': 39, 'max_bin': 105}. Best is trial 12 with value: 10.71050130838939.\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[91]\tvalid_0's l1: 11.1454\n",
      "[I 2025-08-09 11:05:39,646] Trial 25 finished with value: 11.145363468265685 and parameters: {'lambda_l1': 0.14148172668419717, 'lambda_l2': 0.2226081867221815, 'num_leaves': 29, 'feature_fraction': 0.5998408578961011, 'learning_rate': 0.06525590723195313, 'bagging_fraction': 0.8634106652710176, 'bagging_freq': 8, 'min_child_samples': 28, 'max_bin': 175}. Best is trial 12 with value: 10.71050130838939.\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[91]\tvalid_0's l1: 11.1454\n",
      "[I 2025-08-09 11:05:39,646] Trial 25 finished with value: 11.145363468265685 and parameters: {'lambda_l1': 0.14148172668419717, 'lambda_l2': 0.2226081867221815, 'num_leaves': 29, 'feature_fraction': 0.5998408578961011, 'learning_rate': 0.06525590723195313, 'bagging_fraction': 0.8634106652710176, 'bagging_freq': 8, 'min_child_samples': 28, 'max_bin': 175}. Best is trial 12 with value: 10.71050130838939.\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[34]\tvalid_0's l1: 11.1769\n",
      "[I 2025-08-09 11:05:39,880] Trial 26 finished with value: 11.176865307959282 and parameters: {'lambda_l1': 0.013298631576814088, 'lambda_l2': 0.4218452277145693, 'num_leaves': 52, 'feature_fraction': 0.453306103530419, 'learning_rate': 0.18917139297404936, 'bagging_fraction': 0.9296438710556614, 'bagging_freq': 6, 'min_child_samples': 20, 'max_bin': 152}. Best is trial 12 with value: 10.71050130838939.\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[34]\tvalid_0's l1: 11.1769\n",
      "[I 2025-08-09 11:05:39,880] Trial 26 finished with value: 11.176865307959282 and parameters: {'lambda_l1': 0.013298631576814088, 'lambda_l2': 0.4218452277145693, 'num_leaves': 52, 'feature_fraction': 0.453306103530419, 'learning_rate': 0.18917139297404936, 'bagging_fraction': 0.9296438710556614, 'bagging_freq': 6, 'min_child_samples': 20, 'max_bin': 152}. Best is trial 12 with value: 10.71050130838939.\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[63]\tvalid_0's l1: 10.9305\n",
      "[I 2025-08-09 11:05:40,278] Trial 27 finished with value: 10.930525557020214 and parameters: {'lambda_l1': 0.3955631819530874, 'lambda_l2': 0.17252239635449207, 'num_leaves': 73, 'feature_fraction': 0.7033456082463543, 'learning_rate': 0.10828923193135206, 'bagging_fraction': 0.7643435429374401, 'bagging_freq': 9, 'min_child_samples': 33, 'max_bin': 205}. Best is trial 12 with value: 10.71050130838939.\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[63]\tvalid_0's l1: 10.9305\n",
      "[I 2025-08-09 11:05:40,278] Trial 27 finished with value: 10.930525557020214 and parameters: {'lambda_l1': 0.3955631819530874, 'lambda_l2': 0.17252239635449207, 'num_leaves': 73, 'feature_fraction': 0.7033456082463543, 'learning_rate': 0.10828923193135206, 'bagging_fraction': 0.7643435429374401, 'bagging_freq': 9, 'min_child_samples': 33, 'max_bin': 205}. Best is trial 12 with value: 10.71050130838939.\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[469]\tvalid_0's l1: 10.7653\n",
      "[I 2025-08-09 11:05:40,664] Trial 28 finished with value: 10.765283181178416 and parameters: {'lambda_l1': 0.6760677960781725, 'lambda_l2': 0.4973641181707017, 'num_leaves': 10, 'feature_fraction': 0.5360984258382611, 'learning_rate': 0.04663485334046273, 'bagging_fraction': 0.8506355546544803, 'bagging_freq': 10, 'min_child_samples': 28, 'max_bin': 135}. Best is trial 12 with value: 10.71050130838939.\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[469]\tvalid_0's l1: 10.7653\n",
      "[I 2025-08-09 11:05:40,664] Trial 28 finished with value: 10.765283181178416 and parameters: {'lambda_l1': 0.6760677960781725, 'lambda_l2': 0.4973641181707017, 'num_leaves': 10, 'feature_fraction': 0.5360984258382611, 'learning_rate': 0.04663485334046273, 'bagging_fraction': 0.8506355546544803, 'bagging_freq': 10, 'min_child_samples': 28, 'max_bin': 135}. Best is trial 12 with value: 10.71050130838939.\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[99]\tvalid_0's l1: 11.1743\n",
      "[I 2025-08-09 11:05:41,313] Trial 29 finished with value: 11.174321637395613 and parameters: {'lambda_l1': 0.8426134881744979, 'lambda_l2': 0.7441959260394615, 'num_leaves': 90, 'feature_fraction': 0.7467051118130028, 'learning_rate': 0.07920297602298573, 'bagging_fraction': 0.6699011875812145, 'bagging_freq': 8, 'min_child_samples': 43, 'max_bin': 359}. Best is trial 12 with value: 10.71050130838939.\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[99]\tvalid_0's l1: 11.1743\n",
      "[I 2025-08-09 11:05:41,313] Trial 29 finished with value: 11.174321637395613 and parameters: {'lambda_l1': 0.8426134881744979, 'lambda_l2': 0.7441959260394615, 'num_leaves': 90, 'feature_fraction': 0.7467051118130028, 'learning_rate': 0.07920297602298573, 'bagging_fraction': 0.6699011875812145, 'bagging_freq': 8, 'min_child_samples': 43, 'max_bin': 359}. Best is trial 12 with value: 10.71050130838939.\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[243]\tvalid_0's l1: 10.6649\n",
      "[I 2025-08-09 11:05:42,248] Trial 30 finished with value: 10.66494409827414 and parameters: {'lambda_l1': 0.16807654079447742, 'lambda_l2': 1.2664299357452182, 'num_leaves': 77, 'feature_fraction': 0.7893773787371509, 'learning_rate': 0.0332473953956804, 'bagging_fraction': 0.8921584874563345, 'bagging_freq': 7, 'min_child_samples': 38, 'max_bin': 103}. Best is trial 30 with value: 10.66494409827414.\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[243]\tvalid_0's l1: 10.6649\n",
      "[I 2025-08-09 11:05:42,248] Trial 30 finished with value: 10.66494409827414 and parameters: {'lambda_l1': 0.16807654079447742, 'lambda_l2': 1.2664299357452182, 'num_leaves': 77, 'feature_fraction': 0.7893773787371509, 'learning_rate': 0.0332473953956804, 'bagging_fraction': 0.8921584874563345, 'bagging_freq': 7, 'min_child_samples': 38, 'max_bin': 103}. Best is trial 30 with value: 10.66494409827414.\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[236]\tvalid_0's l1: 10.4825\n",
      "[I 2025-08-09 11:05:43,216] Trial 31 finished with value: 10.482549487468033 and parameters: {'lambda_l1': 0.14363173258604017, 'lambda_l2': 1.2583165690261955, 'num_leaves': 77, 'feature_fraction': 0.8132527310963572, 'learning_rate': 0.033492688307476565, 'bagging_fraction': 0.8961869915583215, 'bagging_freq': 7, 'min_child_samples': 39, 'max_bin': 100}. Best is trial 31 with value: 10.482549487468033.\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[236]\tvalid_0's l1: 10.4825\n",
      "[I 2025-08-09 11:05:43,216] Trial 31 finished with value: 10.482549487468033 and parameters: {'lambda_l1': 0.14363173258604017, 'lambda_l2': 1.2583165690261955, 'num_leaves': 77, 'feature_fraction': 0.8132527310963572, 'learning_rate': 0.033492688307476565, 'bagging_fraction': 0.8961869915583215, 'bagging_freq': 7, 'min_child_samples': 39, 'max_bin': 100}. Best is trial 31 with value: 10.482549487468033.\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[285]\tvalid_0's l1: 10.9746\n",
      "[I 2025-08-09 11:05:44,326] Trial 32 finished with value: 10.9746106507656 and parameters: {'lambda_l1': 0.19727564210488502, 'lambda_l2': 1.2999455472027623, 'num_leaves': 79, 'feature_fraction': 0.8872090749212163, 'learning_rate': 0.024966882908214645, 'bagging_fraction': 0.9982473431986242, 'bagging_freq': 6, 'min_child_samples': 37, 'max_bin': 139}. Best is trial 31 with value: 10.482549487468033.\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[285]\tvalid_0's l1: 10.9746\n",
      "[I 2025-08-09 11:05:44,326] Trial 32 finished with value: 10.9746106507656 and parameters: {'lambda_l1': 0.19727564210488502, 'lambda_l2': 1.2999455472027623, 'num_leaves': 79, 'feature_fraction': 0.8872090749212163, 'learning_rate': 0.024966882908214645, 'bagging_fraction': 0.9982473431986242, 'bagging_freq': 6, 'min_child_samples': 37, 'max_bin': 139}. Best is trial 31 with value: 10.482549487468033.\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[238]\tvalid_0's l1: 10.881\n",
      "[I 2025-08-09 11:05:45,979] Trial 33 finished with value: 10.880951053154412 and parameters: {'lambda_l1': 0.5920893879357874, 'lambda_l2': 1.4249005286637262, 'num_leaves': 124, 'feature_fraction': 0.7901094823990581, 'learning_rate': 0.034793440984927634, 'bagging_fraction': 0.9024483771317474, 'bagging_freq': 5, 'min_child_samples': 42, 'max_bin': 378}. Best is trial 31 with value: 10.482549487468033.\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[238]\tvalid_0's l1: 10.881\n",
      "[I 2025-08-09 11:05:45,979] Trial 33 finished with value: 10.880951053154412 and parameters: {'lambda_l1': 0.5920893879357874, 'lambda_l2': 1.4249005286637262, 'num_leaves': 124, 'feature_fraction': 0.7901094823990581, 'learning_rate': 0.034793440984927634, 'bagging_fraction': 0.9024483771317474, 'bagging_freq': 5, 'min_child_samples': 42, 'max_bin': 378}. Best is trial 31 with value: 10.482549487468033.\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[237]\tvalid_0's l1: 11.1102\n",
      "[I 2025-08-09 11:05:47,046] Trial 34 finished with value: 11.110152457144983 and parameters: {'lambda_l1': 1.0050676413461606, 'lambda_l2': 1.0940005453559676, 'num_leaves': 92, 'feature_fraction': 0.8700996919179451, 'learning_rate': 0.02335799263218434, 'bagging_fraction': 0.9477382472777189, 'bagging_freq': 7, 'min_child_samples': 39, 'max_bin': 170}. Best is trial 31 with value: 10.482549487468033.\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[237]\tvalid_0's l1: 11.1102\n",
      "[I 2025-08-09 11:05:47,046] Trial 34 finished with value: 11.110152457144983 and parameters: {'lambda_l1': 1.0050676413461606, 'lambda_l2': 1.0940005453559676, 'num_leaves': 92, 'feature_fraction': 0.8700996919179451, 'learning_rate': 0.02335799263218434, 'bagging_fraction': 0.9477382472777189, 'bagging_freq': 7, 'min_child_samples': 39, 'max_bin': 170}. Best is trial 31 with value: 10.482549487468033.\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[168]\tvalid_0's l1: 10.691\n",
      "[I 2025-08-09 11:05:48,009] Trial 35 finished with value: 10.69097784482253 and parameters: {'lambda_l1': 0.16417472690820503, 'lambda_l2': 1.2890318213460836, 'num_leaves': 100, 'feature_fraction': 0.9656063914879107, 'learning_rate': 0.03922280641257788, 'bagging_fraction': 0.7948185854297374, 'bagging_freq': 3, 'min_child_samples': 34, 'max_bin': 202}. Best is trial 31 with value: 10.482549487468033.\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[168]\tvalid_0's l1: 10.691\n",
      "[I 2025-08-09 11:05:48,009] Trial 35 finished with value: 10.69097784482253 and parameters: {'lambda_l1': 0.16417472690820503, 'lambda_l2': 1.2890318213460836, 'num_leaves': 100, 'feature_fraction': 0.9656063914879107, 'learning_rate': 0.03922280641257788, 'bagging_fraction': 0.7948185854297374, 'bagging_freq': 3, 'min_child_samples': 34, 'max_bin': 202}. Best is trial 31 with value: 10.482549487468033.\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[195]\tvalid_0's l1: 11.0936\n",
      "[I 2025-08-09 11:05:49,226] Trial 36 finished with value: 11.09355707772322 and parameters: {'lambda_l1': 0.15645484015402278, 'lambda_l2': 1.3378419833276518, 'num_leaves': 121, 'feature_fraction': 0.9829943807273317, 'learning_rate': 0.031121810540748824, 'bagging_fraction': 0.8030070165561827, 'bagging_freq': 3, 'min_child_samples': 47, 'max_bin': 191}. Best is trial 31 with value: 10.482549487468033.\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[195]\tvalid_0's l1: 11.0936\n",
      "[I 2025-08-09 11:05:49,226] Trial 36 finished with value: 11.09355707772322 and parameters: {'lambda_l1': 0.15645484015402278, 'lambda_l2': 1.3378419833276518, 'num_leaves': 121, 'feature_fraction': 0.9829943807273317, 'learning_rate': 0.031121810540748824, 'bagging_fraction': 0.8030070165561827, 'bagging_freq': 3, 'min_child_samples': 47, 'max_bin': 191}. Best is trial 31 with value: 10.482549487468033.\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[474]\tvalid_0's l1: 10.9619\n",
      "[I 2025-08-09 11:05:51,183] Trial 37 finished with value: 10.961859782088556 and parameters: {'lambda_l1': 0.8388588193902949, 'lambda_l2': 1.6814742153278153, 'num_leaves': 98, 'feature_fraction': 0.9296937750366618, 'learning_rate': 0.015156776056270749, 'bagging_fraction': 0.5678898196913976, 'bagging_freq': 1, 'min_child_samples': 50, 'max_bin': 231}. Best is trial 31 with value: 10.482549487468033.\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[474]\tvalid_0's l1: 10.9619\n",
      "[I 2025-08-09 11:05:51,183] Trial 37 finished with value: 10.961859782088556 and parameters: {'lambda_l1': 0.8388588193902949, 'lambda_l2': 1.6814742153278153, 'num_leaves': 98, 'feature_fraction': 0.9296937750366618, 'learning_rate': 0.015156776056270749, 'bagging_fraction': 0.5678898196913976, 'bagging_freq': 1, 'min_child_samples': 50, 'max_bin': 231}. Best is trial 31 with value: 10.482549487468033.\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[149]\tvalid_0's l1: 10.8303\n",
      "[I 2025-08-09 11:05:52,103] Trial 38 finished with value: 10.830333696838121 and parameters: {'lambda_l1': 0.4135582180720575, 'lambda_l2': 1.0423041909947919, 'num_leaves': 99, 'feature_fraction': 0.853207023771392, 'learning_rate': 0.03978501406559434, 'bagging_fraction': 0.780092888115533, 'bagging_freq': 2, 'min_child_samples': 38, 'max_bin': 272}. Best is trial 31 with value: 10.482549487468033.\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[149]\tvalid_0's l1: 10.8303\n",
      "[I 2025-08-09 11:05:52,103] Trial 38 finished with value: 10.830333696838121 and parameters: {'lambda_l1': 0.4135582180720575, 'lambda_l2': 1.0423041909947919, 'num_leaves': 99, 'feature_fraction': 0.853207023771392, 'learning_rate': 0.03978501406559434, 'bagging_fraction': 0.780092888115533, 'bagging_freq': 2, 'min_child_samples': 38, 'max_bin': 272}. Best is trial 31 with value: 10.482549487468033.\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[260]\tvalid_0's l1: 10.9417\n",
      "[I 2025-08-09 11:05:53,532] Trial 39 finished with value: 10.941713344490497 and parameters: {'lambda_l1': 0.14953989302724002, 'lambda_l2': 1.23653201119548, 'num_leaves': 102, 'feature_fraction': 0.9230859700903901, 'learning_rate': 0.021737183770285162, 'bagging_fraction': 0.8902823632617471, 'bagging_freq': 5, 'min_child_samples': 41, 'max_bin': 322}. Best is trial 31 with value: 10.482549487468033.\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[260]\tvalid_0's l1: 10.9417\n",
      "[I 2025-08-09 11:05:53,532] Trial 39 finished with value: 10.941713344490497 and parameters: {'lambda_l1': 0.14953989302724002, 'lambda_l2': 1.23653201119548, 'num_leaves': 102, 'feature_fraction': 0.9230859700903901, 'learning_rate': 0.021737183770285162, 'bagging_fraction': 0.8902823632617471, 'bagging_freq': 5, 'min_child_samples': 41, 'max_bin': 322}. Best is trial 31 with value: 10.482549487468033.\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[273]\tvalid_0's l1: 10.8233\n",
      "[I 2025-08-09 11:05:54,659] Trial 40 finished with value: 10.823336332695714 and parameters: {'lambda_l1': 0.30921881413256086, 'lambda_l2': 1.976632932553553, 'num_leaves': 79, 'feature_fraction': 0.786137190295181, 'learning_rate': 0.02698331529232657, 'bagging_fraction': 0.8253555759896163, 'bagging_freq': 3, 'min_child_samples': 43, 'max_bin': 197}. Best is trial 31 with value: 10.482549487468033.\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[273]\tvalid_0's l1: 10.8233\n",
      "[I 2025-08-09 11:05:54,659] Trial 40 finished with value: 10.823336332695714 and parameters: {'lambda_l1': 0.30921881413256086, 'lambda_l2': 1.976632932553553, 'num_leaves': 79, 'feature_fraction': 0.786137190295181, 'learning_rate': 0.02698331529232657, 'bagging_fraction': 0.8253555759896163, 'bagging_freq': 3, 'min_child_samples': 43, 'max_bin': 197}. Best is trial 31 with value: 10.482549487468033.\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[167]\tvalid_0's l1: 10.7899\n",
      "[I 2025-08-09 11:05:55,275] Trial 41 finished with value: 10.789863812799306 and parameters: {'lambda_l1': 0.5424140413724772, 'lambda_l2': 1.421382809724007, 'num_leaves': 65, 'feature_fraction': 0.8276990147058599, 'learning_rate': 0.0492609212192105, 'bagging_fraction': 0.9598221915414151, 'bagging_freq': 8, 'min_child_samples': 34, 'max_bin': 130}. Best is trial 31 with value: 10.482549487468033.\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[167]\tvalid_0's l1: 10.7899\n",
      "[I 2025-08-09 11:05:55,275] Trial 41 finished with value: 10.789863812799306 and parameters: {'lambda_l1': 0.5424140413724772, 'lambda_l2': 1.421382809724007, 'num_leaves': 65, 'feature_fraction': 0.8276990147058599, 'learning_rate': 0.0492609212192105, 'bagging_fraction': 0.9598221915414151, 'bagging_freq': 8, 'min_child_samples': 34, 'max_bin': 130}. Best is trial 31 with value: 10.482549487468033.\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[108]\tvalid_0's l1: 11.0183\n",
      "[I 2025-08-09 11:05:55,852] Trial 42 finished with value: 11.01831442704469 and parameters: {'lambda_l1': 0.09188982768913816, 'lambda_l2': 1.5770537331866938, 'num_leaves': 85, 'feature_fraction': 0.7435213626348423, 'learning_rate': 0.05334988198425112, 'bagging_fraction': 0.9215109516684951, 'bagging_freq': 6, 'min_child_samples': 30, 'max_bin': 166}. Best is trial 31 with value: 10.482549487468033.\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[108]\tvalid_0's l1: 11.0183\n",
      "[I 2025-08-09 11:05:55,852] Trial 42 finished with value: 11.01831442704469 and parameters: {'lambda_l1': 0.09188982768913816, 'lambda_l2': 1.5770537331866938, 'num_leaves': 85, 'feature_fraction': 0.7435213626348423, 'learning_rate': 0.05334988198425112, 'bagging_fraction': 0.9215109516684951, 'bagging_freq': 6, 'min_child_samples': 30, 'max_bin': 166}. Best is trial 31 with value: 10.482549487468033.\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[182]\tvalid_0's l1: 10.8046\n",
      "[I 2025-08-09 11:05:56,556] Trial 43 finished with value: 10.804641959879856 and parameters: {'lambda_l1': 0.23625267551927737, 'lambda_l2': 1.7558907978575395, 'num_leaves': 74, 'feature_fraction': 0.6657534887518416, 'learning_rate': 0.03828646458397878, 'bagging_fraction': 0.8357433150343524, 'bagging_freq': 10, 'min_child_samples': 34, 'max_bin': 121}. Best is trial 31 with value: 10.482549487468033.\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[182]\tvalid_0's l1: 10.8046\n",
      "[I 2025-08-09 11:05:56,556] Trial 43 finished with value: 10.804641959879856 and parameters: {'lambda_l1': 0.23625267551927737, 'lambda_l2': 1.7558907978575395, 'num_leaves': 74, 'feature_fraction': 0.6657534887518416, 'learning_rate': 0.03828646458397878, 'bagging_fraction': 0.8357433150343524, 'bagging_freq': 10, 'min_child_samples': 34, 'max_bin': 121}. Best is trial 31 with value: 10.482549487468033.\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[260]\tvalid_0's l1: 10.4933\n",
      "[I 2025-08-09 11:05:57,404] Trial 44 finished with value: 10.49325445309575 and parameters: {'lambda_l1': 1.0969684153711727, 'lambda_l2': 1.1963424002174028, 'num_leaves': 65, 'feature_fraction': 0.7117160631273314, 'learning_rate': 0.03174363086954893, 'bagging_fraction': 0.8795741465288001, 'bagging_freq': 3, 'min_child_samples': 45, 'max_bin': 100}. Best is trial 31 with value: 10.482549487468033.\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[260]\tvalid_0's l1: 10.4933\n",
      "[I 2025-08-09 11:05:57,404] Trial 44 finished with value: 10.49325445309575 and parameters: {'lambda_l1': 1.0969684153711727, 'lambda_l2': 1.1963424002174028, 'num_leaves': 65, 'feature_fraction': 0.7117160631273314, 'learning_rate': 0.03174363086954893, 'bagging_fraction': 0.8795741465288001, 'bagging_freq': 3, 'min_child_samples': 45, 'max_bin': 100}. Best is trial 31 with value: 10.482549487468033.\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[235]\tvalid_0's l1: 10.8568\n",
      "[I 2025-08-09 11:05:58,752] Trial 45 finished with value: 10.85679581344107 and parameters: {'lambda_l1': 1.0918392446259202, 'lambda_l2': 1.1934256429421188, 'num_leaves': 115, 'feature_fraction': 0.6881303694529266, 'learning_rate': 0.030253003725649097, 'bagging_fraction': 0.8812111589691725, 'bagging_freq': 3, 'min_child_samples': 45, 'max_bin': 122}. Best is trial 31 with value: 10.482549487468033.\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[235]\tvalid_0's l1: 10.8568\n",
      "[I 2025-08-09 11:05:58,752] Trial 45 finished with value: 10.85679581344107 and parameters: {'lambda_l1': 1.0918392446259202, 'lambda_l2': 1.1934256429421188, 'num_leaves': 115, 'feature_fraction': 0.6881303694529266, 'learning_rate': 0.030253003725649097, 'bagging_fraction': 0.8812111589691725, 'bagging_freq': 3, 'min_child_samples': 45, 'max_bin': 122}. Best is trial 31 with value: 10.482549487468033.\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[856]\tvalid_0's l1: 10.5289\n",
      "[I 2025-08-09 11:06:00,915] Trial 46 finished with value: 10.528899390145236 and parameters: {'lambda_l1': 1.0977759735440717, 'lambda_l2': 0.9128523956658485, 'num_leaves': 60, 'feature_fraction': 0.76554640635376, 'learning_rate': 0.011294548070060919, 'bagging_fraction': 0.7889908568110097, 'bagging_freq': 1, 'min_child_samples': 47, 'max_bin': 100}. Best is trial 31 with value: 10.482549487468033.\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[856]\tvalid_0's l1: 10.5289\n",
      "[I 2025-08-09 11:06:00,915] Trial 46 finished with value: 10.528899390145236 and parameters: {'lambda_l1': 1.0977759735440717, 'lambda_l2': 0.9128523956658485, 'num_leaves': 60, 'feature_fraction': 0.76554640635376, 'learning_rate': 0.011294548070060919, 'bagging_fraction': 0.7889908568110097, 'bagging_freq': 1, 'min_child_samples': 47, 'max_bin': 100}. Best is trial 31 with value: 10.482549487468033.\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[415]\tvalid_0's l1: 11.0188\n",
      "[I 2025-08-09 11:06:02,255] Trial 47 finished with value: 11.018831981198664 and parameters: {'lambda_l1': 1.1374312906999657, 'lambda_l2': 0.9300324238430788, 'num_leaves': 63, 'feature_fraction': 0.7644210225123247, 'learning_rate': 0.01315678122035428, 'bagging_fraction': 0.7582121346425141, 'bagging_freq': 2, 'min_child_samples': 48, 'max_bin': 213}. Best is trial 31 with value: 10.482549487468033.\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[415]\tvalid_0's l1: 11.0188\n",
      "[I 2025-08-09 11:06:02,255] Trial 47 finished with value: 11.018831981198664 and parameters: {'lambda_l1': 1.1374312906999657, 'lambda_l2': 0.9300324238430788, 'num_leaves': 63, 'feature_fraction': 0.7644210225123247, 'learning_rate': 0.01315678122035428, 'bagging_fraction': 0.7582121346425141, 'bagging_freq': 2, 'min_child_samples': 48, 'max_bin': 213}. Best is trial 31 with value: 10.482549487468033.\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[569]\tvalid_0's l1: 10.941\n",
      "[I 2025-08-09 11:06:05,160] Trial 48 finished with value: 10.940973213564586 and parameters: {'lambda_l1': 1.4730499251162954, 'lambda_l2': 1.1170161056444827, 'num_leaves': 149, 'feature_fraction': 0.7228182403873563, 'learning_rate': 0.010299785393896296, 'bagging_fraction': 0.7969152375102575, 'bagging_freq': 1, 'min_child_samples': 46, 'max_bin': 151}. Best is trial 31 with value: 10.482549487468033.\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[569]\tvalid_0's l1: 10.941\n",
      "[I 2025-08-09 11:06:05,160] Trial 48 finished with value: 10.940973213564586 and parameters: {'lambda_l1': 1.4730499251162954, 'lambda_l2': 1.1170161056444827, 'num_leaves': 149, 'feature_fraction': 0.7228182403873563, 'learning_rate': 0.010299785393896296, 'bagging_fraction': 0.7969152375102575, 'bagging_freq': 1, 'min_child_samples': 46, 'max_bin': 151}. Best is trial 31 with value: 10.482549487468033.\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[297]\tvalid_0's l1: 11.0869\n",
      "[I 2025-08-09 11:06:06,550] Trial 49 finished with value: 11.086908624891974 and parameters: {'lambda_l1': 1.3119237733221312, 'lambda_l2': 1.00702568847409, 'num_leaves': 90, 'feature_fraction': 0.7933280677297339, 'learning_rate': 0.02019436520001453, 'bagging_fraction': 0.7124914807531391, 'bagging_freq': 4, 'min_child_samples': 41, 'max_bin': 184}. Best is trial 31 with value: 10.482549487468033.\n",
      "\n",
      "âœ… OptimizaciÃ³n completada!\n",
      "ğŸ† Mejor MAE encontrado: 10.4825\n",
      "\n",
      "ğŸ”§ HIPERPARÃMETROS OPTIMIZADOS OBTENIDOS:\n",
      "============================================================\n",
      "   lambda_l1:        0.1436\n",
      "   lambda_l2:        1.2583\n",
      "   num_leaves:       77\n",
      "   feature_fraction: 0.8133\n",
      "   learning_rate:    0.0335\n",
      "   bagging_fraction: 0.8962\n",
      "   bagging_freq:     7\n",
      "   min_child_samples: 39\n",
      "   max_bin:          100\n",
      "============================================================\n",
      "\n",
      "ğŸ“Š Resumen de la optimizaciÃ³n:\n",
      "  Trials completados: 50\n",
      "  Mejor trial: 31\n",
      "  Tiempo total: 44.3 segundos\n",
      "Early stopping, best iteration is:\n",
      "[297]\tvalid_0's l1: 11.0869\n",
      "[I 2025-08-09 11:06:06,550] Trial 49 finished with value: 11.086908624891974 and parameters: {'lambda_l1': 1.3119237733221312, 'lambda_l2': 1.00702568847409, 'num_leaves': 90, 'feature_fraction': 0.7933280677297339, 'learning_rate': 0.02019436520001453, 'bagging_fraction': 0.7124914807531391, 'bagging_freq': 4, 'min_child_samples': 41, 'max_bin': 184}. Best is trial 31 with value: 10.482549487468033.\n",
      "\n",
      "âœ… OptimizaciÃ³n completada!\n",
      "ğŸ† Mejor MAE encontrado: 10.4825\n",
      "\n",
      "ğŸ”§ HIPERPARÃMETROS OPTIMIZADOS OBTENIDOS:\n",
      "============================================================\n",
      "   lambda_l1:        0.1436\n",
      "   lambda_l2:        1.2583\n",
      "   num_leaves:       77\n",
      "   feature_fraction: 0.8133\n",
      "   learning_rate:    0.0335\n",
      "   bagging_fraction: 0.8962\n",
      "   bagging_freq:     7\n",
      "   min_child_samples: 39\n",
      "   max_bin:          100\n",
      "============================================================\n",
      "\n",
      "ğŸ“Š Resumen de la optimizaciÃ³n:\n",
      "  Trials completados: 50\n",
      "  Mejor trial: 31\n",
      "  Tiempo total: 44.3 segundos\n"
     ]
    }
   ],
   "source": [
    "# ğŸ”§ OptimizaciÃ³n de hiperparÃ¡metros con Optuna\n",
    "print(\"OPTIMIZACIÃ“N DE HIPERPARÃMETROS CON OPTUNA\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "def objective(trial):\n",
    "    \"\"\"FunciÃ³n objetivo para optimizaciÃ³n con Optuna\"\"\"\n",
    "    \n",
    "    # Sugerir SOLO los hiperparÃ¡metros especificados por el usuario\n",
    "    params = {\n",
    "        'objective': 'regression',\n",
    "        'metric': 'mae',\n",
    "        'boosting_type': 'gbdt',\n",
    "        'lambda_l1': trial.suggest_float('lambda_l1', 0.0, 2.0),\n",
    "        'lambda_l2': trial.suggest_float('lambda_l2', 0.0, 2.0),\n",
    "        'num_leaves': trial.suggest_int('num_leaves', 10, 150),\n",
    "        'feature_fraction': trial.suggest_float('feature_fraction', 0.4, 1.0),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3, log=True),\n",
    "        'bagging_fraction': trial.suggest_float('bagging_fraction', 0.4, 1.0),\n",
    "        'bagging_freq': trial.suggest_int('bagging_freq', 1, 10),\n",
    "        'min_child_samples': trial.suggest_int('min_child_samples', 5, 50),\n",
    "        'max_bin': trial.suggest_int('max_bin', 100, 500),\n",
    "        'verbose': -1,\n",
    "        'random_state': 42\n",
    "    }\n",
    "    \n",
    "    # Crear datasets de LightGBM\n",
    "    train_dataset = lgb.Dataset(X_train, label=y_train)\n",
    "    val_dataset = lgb.Dataset(X_val, label=y_val, reference=train_dataset)\n",
    "    \n",
    "    # Entrenar modelo con validaciÃ³n cruzada interna\n",
    "    model = lgb.train(\n",
    "        params,\n",
    "        train_dataset,\n",
    "        valid_sets=[val_dataset],\n",
    "        num_boost_round=1000,\n",
    "        callbacks=[\n",
    "            lgb.early_stopping(stopping_rounds=50),\n",
    "            lgb.log_evaluation(0)  # Silenciar logs\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    # Predecir en conjunto de validaciÃ³n\n",
    "    y_pred = model.predict(X_val, num_iteration=model.best_iteration)\n",
    "    \n",
    "    # Calcular MAE como mÃ©trica a minimizar\n",
    "    mae = mean_absolute_error(y_val, y_pred)\n",
    "    \n",
    "    return mae\n",
    "\n",
    "# Crear estudio de optimizaciÃ³n\n",
    "print(\"ğŸ” Iniciando optimizaciÃ³n de hiperparÃ¡metros...\")\n",
    "study = optuna.create_study(\n",
    "    direction='minimize',\n",
    "    sampler=optuna.samplers.TPESampler(seed=42),\n",
    "    pruner=optuna.pruners.MedianPruner(n_warmup_steps=10)\n",
    ")\n",
    "\n",
    "# Ejecutar optimizaciÃ³n\n",
    "n_trials = 50  # NÃºmero de pruebas (ajustar segÃºn tiempo disponible)\n",
    "print(f\"ğŸš€ Ejecutando {n_trials} trials de optimizaciÃ³n...\")\n",
    "\n",
    "study.optimize(objective, n_trials=n_trials, show_progress_bar=True)\n",
    "\n",
    "# Mostrar mejores parÃ¡metros\n",
    "print(f\"\\nâœ… OptimizaciÃ³n completada!\")\n",
    "print(f\"ğŸ† Mejor MAE encontrado: {study.best_value:.4f}\")\n",
    "print(f\"\\nğŸ”§ HIPERPARÃMETROS OPTIMIZADOS OBTENIDOS:\")\n",
    "best_params = study.best_params\n",
    "print(\"=\"*60)\n",
    "print(f\"   lambda_l1:        {best_params['lambda_l1']:.4f}\")\n",
    "print(f\"   lambda_l2:        {best_params['lambda_l2']:.4f}\")\n",
    "print(f\"   num_leaves:       {best_params['num_leaves']}\")\n",
    "print(f\"   feature_fraction: {best_params['feature_fraction']:.4f}\")\n",
    "print(f\"   learning_rate:    {best_params['learning_rate']:.4f}\")\n",
    "print(f\"   bagging_fraction: {best_params['bagging_fraction']:.4f}\")\n",
    "print(f\"   bagging_freq:     {best_params['bagging_freq']}\")\n",
    "print(f\"   min_child_samples: {best_params['min_child_samples']}\")\n",
    "print(f\"   max_bin:          {best_params['max_bin']}\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Agregar parÃ¡metros fijos\n",
    "best_params.update({\n",
    "    'objective': 'regression',\n",
    "    'metric': 'mae',\n",
    "    'boosting_type': 'gbdt',\n",
    "    'verbose': 0,\n",
    "    'random_state': 42\n",
    "})\n",
    "\n",
    "print(f\"\\nğŸ“Š Resumen de la optimizaciÃ³n:\")\n",
    "print(f\"  Trials completados: {len(study.trials)}\")\n",
    "print(f\"  Mejor trial: {study.best_trial.number}\")\n",
    "print(f\"  Tiempo total: {sum(t.duration.total_seconds() for t in study.trials if t.duration):.1f} segundos\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e067db2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ENTRENAMIENTO DEL MODELO LIGHTGBM CON OPTUNA - POR PRODUCTO\n",
      "======================================================================\n",
      "ğŸ”§ PARÃMETROS OPTIMIZADOS QUE SE USARÃN PARA EL MODELO FINAL:\n",
      "======================================================================\n",
      "   lambda_l1:        0.1436\n",
      "   lambda_l2:        1.2583\n",
      "   num_leaves:       77\n",
      "   feature_fraction: 0.8133\n",
      "   learning_rate:    0.0335\n",
      "   bagging_fraction: 0.8962\n",
      "   bagging_freq:     7\n",
      "   min_child_samples: 39\n",
      "   max_bin:          100\n",
      "======================================================================\n",
      "\n",
      "ğŸ¯ Iniciando entrenamiento con parÃ¡metros optimizados...\n",
      "ğŸ“Š Features utilizadas: 29\n",
      "ğŸ­ Productos en entrenamiento: 718\n",
      "Training until validation scores don't improve for 150 rounds\n",
      "[100]\ttrain's l1: 12.003\teval's l1: 11.3344\n",
      "[100]\ttrain's l1: 12.003\teval's l1: 11.3344\n",
      "[200]\ttrain's l1: 10.1055\teval's l1: 10.5298\n",
      "[200]\ttrain's l1: 10.1055\teval's l1: 10.5298\n",
      "[300]\ttrain's l1: 9.18668\teval's l1: 10.5458\n",
      "[300]\ttrain's l1: 9.18668\teval's l1: 10.5458\n",
      "Early stopping, best iteration is:\n",
      "[236]\ttrain's l1: 9.74586\teval's l1: 10.4825\n",
      "âœ… Modelo optimizado entrenado exitosamente!\n",
      "ğŸ“Š NÃºmero de Ã¡rboles finales: 236\n",
      "\n",
      "ğŸ“ˆ MÃ‰TRICAS EN VALIDACIÃ“N (MODELO OPTIMIZADO - POR PRODUCTO):\n",
      "  MAE:  10.4825\n",
      "  RMSE: 32.4590\n",
      "  MAPE: 240.33%\n",
      "\n",
      "ğŸ“Š ESTADÃSTICAS POR PRODUCTO (MODELO OPTIMIZADO):\n",
      "Productos evaluados: 780\n",
      "Promedio de perÃ­odos por producto: 4.9\n",
      "Early stopping, best iteration is:\n",
      "[236]\ttrain's l1: 9.74586\teval's l1: 10.4825\n",
      "âœ… Modelo optimizado entrenado exitosamente!\n",
      "ğŸ“Š NÃºmero de Ã¡rboles finales: 236\n",
      "\n",
      "ğŸ“ˆ MÃ‰TRICAS EN VALIDACIÃ“N (MODELO OPTIMIZADO - POR PRODUCTO):\n",
      "  MAE:  10.4825\n",
      "  RMSE: 32.4590\n",
      "  MAPE: 240.33%\n",
      "\n",
      "ğŸ“Š ESTADÃSTICAS POR PRODUCTO (MODELO OPTIMIZADO):\n",
      "Productos evaluados: 780\n",
      "Promedio de perÃ­odos por producto: 4.9\n"
     ]
    }
   ],
   "source": [
    "# ğŸš€ Entrenar modelo LightGBM con parÃ¡metros optimizados - GRANULARIDAD POR PRODUCTO\n",
    "print(\"ENTRENAMIENTO DEL MODELO LIGHTGBM CON OPTUNA - POR PRODUCTO\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Usar los mejores parÃ¡metros encontrados por Optuna\n",
    "lgb_params = best_params.copy()\n",
    "\n",
    "print(\"ğŸ”§ PARÃMETROS OPTIMIZADOS QUE SE USARÃN PARA EL MODELO FINAL:\")\n",
    "print(\"=\"*70)\n",
    "print(f\"   lambda_l1:        {lgb_params['lambda_l1']:.4f}\")\n",
    "print(f\"   lambda_l2:        {lgb_params['lambda_l2']:.4f}\")\n",
    "print(f\"   num_leaves:       {lgb_params['num_leaves']}\")\n",
    "print(f\"   feature_fraction: {lgb_params['feature_fraction']:.4f}\")\n",
    "print(f\"   learning_rate:    {lgb_params['learning_rate']:.4f}\")\n",
    "print(f\"   bagging_fraction: {lgb_params['bagging_fraction']:.4f}\")\n",
    "print(f\"   bagging_freq:     {lgb_params['bagging_freq']}\")\n",
    "print(f\"   min_child_samples: {lgb_params['min_child_samples']}\")\n",
    "print(f\"   max_bin:          {lgb_params['max_bin']}\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Crear datasets de LightGBM\n",
    "train_dataset = lgb.Dataset(X_train, label=y_train)\n",
    "val_dataset = lgb.Dataset(X_val, label=y_val, reference=train_dataset)\n",
    "\n",
    "print(f\"\\nğŸ¯ Iniciando entrenamiento con parÃ¡metros optimizados...\")\n",
    "print(f\"ğŸ“Š Features utilizadas: {len(feature_columns)}\")\n",
    "print(f\"ğŸ­ Productos en entrenamiento: {productos_train}\")\n",
    "\n",
    "# Entrenar el modelo con mÃ¡s iteraciones para el modelo final\n",
    "model_optimized = lgb.train(\n",
    "    lgb_params,\n",
    "    train_dataset,\n",
    "    valid_sets=[train_dataset, val_dataset],\n",
    "    valid_names=['train', 'eval'],\n",
    "    num_boost_round=2000,       # MÃ¡s iteraciones para el modelo final\n",
    "    callbacks=[\n",
    "        lgb.early_stopping(stopping_rounds=150),  # MÃ¡s paciencia para el modelo final\n",
    "        lgb.log_evaluation(period=100)\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(f\"âœ… Modelo optimizado entrenado exitosamente!\")\n",
    "print(f\"ğŸ“Š NÃºmero de Ã¡rboles finales: {model_optimized.num_trees()}\")\n",
    "\n",
    "# Predicciones en validaciÃ³n con modelo optimizado\n",
    "y_pred_val_opt = model_optimized.predict(X_val, num_iteration=model_optimized.best_iteration)\n",
    "\n",
    "# MÃ©tricas de evaluaciÃ³n del modelo optimizado\n",
    "mae_opt = mean_absolute_error(y_val, y_pred_val_opt)\n",
    "rmse_opt = np.sqrt(mean_squared_error(y_val, y_pred_val_opt))\n",
    "mape_opt = np.mean(np.abs((y_val - y_pred_val_opt) / y_val)) * 100\n",
    "\n",
    "print(f\"\\nğŸ“ˆ MÃ‰TRICAS EN VALIDACIÃ“N (MODELO OPTIMIZADO - POR PRODUCTO):\")\n",
    "print(f\"  MAE:  {mae_opt:.4f}\")\n",
    "print(f\"  RMSE: {rmse_opt:.4f}\")\n",
    "print(f\"  MAPE: {mape_opt:.2f}%\")\n",
    "\n",
    "# Comparar con modelo base (si existe)\n",
    "if 'mae' in locals():\n",
    "    print(f\"\\nğŸ“Š COMPARACIÃ“N CON MODELO BASE:\")\n",
    "    print(f\"  Mejora en MAE:  {((mae - mae_opt) / mae * 100):+.2f}%\")\n",
    "    print(f\"  Mejora en RMSE: {((rmse - rmse_opt) / rmse * 100):+.2f}%\")\n",
    "    print(f\"  Mejora en MAPE: {(mape - mape_opt):+.2f} puntos porcentuales\")\n",
    "\n",
    "# EstadÃ­sticas adicionales por producto\n",
    "print(f\"\\nğŸ“Š ESTADÃSTICAS POR PRODUCTO (MODELO OPTIMIZADO):\")\n",
    "val_data_with_pred_opt = train_data.loc[~train_mask].copy()\n",
    "val_data_with_pred_opt['pred_optimized'] = y_pred_val_opt\n",
    "product_metrics_opt = val_data_with_pred_opt.groupby('product_id').agg({\n",
    "    'target': ['mean', 'std', 'count'],\n",
    "    'pred_optimized': ['mean', 'std']\n",
    "}).round(3)\n",
    "\n",
    "print(f\"Productos evaluados: {len(product_metrics_opt)}\")\n",
    "print(f\"Promedio de perÃ­odos por producto: {product_metrics_opt[('target', 'count')].mean():.1f}\")\n",
    "\n",
    "# Actualizar variables para usar en celdas siguientes\n",
    "model = model_optimized\n",
    "y_pred_val = y_pred_val_opt\n",
    "mae = mae_opt\n",
    "rmse = rmse_opt\n",
    "mape = mape_opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "33bd8359",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ANÃLISIS DE IMPORTANCIA DE FEATURES\n",
      "==================================================\n",
      "ğŸ” Top 10 features mÃ¡s importantes:\n",
      "                feature    importance\n",
      "20    tn_rolling_mean_6  1.933250e+09\n",
      "25     total_request_tn  7.404889e+08\n",
      "19    tn_rolling_mean_3  6.689767e+08\n",
      "16                  mes  5.970255e+07\n",
      "3              tn_lag_6  4.803076e+07\n",
      "7   num_customers_lag_3  2.607700e+07\n",
      "6   num_customers_lag_2  2.311939e+07\n",
      "24    total_request_qty  2.075636e+07\n",
      "23        num_customers  2.003750e+07\n",
      "21     tn_rolling_std_3  1.920101e+07\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ¯ ANÃLISIS DE PREDICCIONES:\n",
      "Predicciones mÃ­nimas: 0.08\n",
      "Predicciones mÃ¡ximas: 1411.56\n",
      "Predicciones promedio: 39.30\n",
      "Valores reales promedio: 38.72\n",
      "Predicciones negativas: 0 (0.0%)\n",
      "Predicciones mÃ­nimas: 0.08\n",
      "Predicciones mÃ¡ximas: 1411.56\n",
      "Predicciones promedio: 39.30\n",
      "Valores reales promedio: 38.72\n",
      "Predicciones negativas: 0 (0.0%)\n"
     ]
    }
   ],
   "source": [
    "# ğŸ“Š AnÃ¡lisis de importancia de features\n",
    "print(\"ANÃLISIS DE IMPORTANCIA DE FEATURES\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Obtener importancia de features\n",
    "feature_importance = model.feature_importance(importance_type='gain')\n",
    "feature_names = feature_columns\n",
    "\n",
    "# Crear DataFrame con importancias\n",
    "importance_df = pd.DataFrame({\n",
    "    'feature': feature_names,\n",
    "    'importance': feature_importance\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "print(\"ğŸ” Top 10 features mÃ¡s importantes:\")\n",
    "print(importance_df.head(10))\n",
    "\n",
    "# Visualizar importancia\n",
    "plt.figure(figsize=(10, 8))\n",
    "top_features = importance_df.head(15)\n",
    "plt.barh(range(len(top_features)), top_features['importance'])\n",
    "plt.yticks(range(len(top_features)), top_features['feature'])\n",
    "plt.xlabel('Importancia')\n",
    "plt.title('Top 15 Features - Importancia LightGBM')\n",
    "plt.gca().invert_yaxis()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# AnÃ¡lisis de predicciones\n",
    "print(f\"\\nğŸ¯ ANÃLISIS DE PREDICCIONES:\")\n",
    "print(f\"Predicciones mÃ­nimas: {y_pred_val.min():.2f}\")\n",
    "print(f\"Predicciones mÃ¡ximas: {y_pred_val.max():.2f}\")\n",
    "print(f\"Predicciones promedio: {y_pred_val.mean():.2f}\")\n",
    "print(f\"Valores reales promedio: {y_val.mean():.2f}\")\n",
    "\n",
    "# Verificar predicciones negativas\n",
    "negative_preds = (y_pred_val < 0).sum()\n",
    "print(f\"Predicciones negativas: {negative_preds} ({negative_preds/len(y_pred_val)*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "127060bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GENERACIÃ“N DE PREDICCIONES FINALES\n",
      "==================================================\n",
      "ğŸ“Š Productos para predicciÃ³n: 780\n",
      "ğŸ“… PerÃ­odo base para predicciÃ³n: periodo\n",
      "201912    780\n",
      "Name: count, dtype: int64\n",
      "ğŸ” Shape de datos de predicciÃ³n: (780, 29)\n",
      "ğŸ” Valores nulos en predicciÃ³n: 0\n",
      "\n",
      "ğŸ”§ CONFIRMACIÃ“N: Predicciones generadas con hiperparÃ¡metros optimizados:\n",
      "=================================================================\n",
      "   lambda_l1:        0.1436\n",
      "   lambda_l2:        1.2583\n",
      "   num_leaves:       77\n",
      "   feature_fraction: 0.8133\n",
      "   learning_rate:    0.0335\n",
      "   bagging_fraction: 0.8962\n",
      "   bagging_freq:     7\n",
      "   min_child_samples: 39\n",
      "   max_bin:          100\n",
      "=================================================================\n",
      "âœ… Predicciones generadas para 780 productos\n",
      "\n",
      "ğŸ“Š EstadÃ­sticas de predicciones:\n",
      "  Promedio: 35.22\n",
      "  Mediana:  7.98\n",
      "  MÃ­nimo:   0.32\n",
      "  MÃ¡ximo:   1010.16\n",
      "  Std:      86.05\n",
      "\n",
      "Primeras 10 predicciones:\n",
      "   product_id           tn\n",
      "0       20001   888.677174\n",
      "1       20002  1010.155906\n",
      "2       20003   789.907956\n",
      "3       20004   741.301926\n",
      "4       20005   697.096955\n",
      "5       20006   386.132096\n",
      "6       20007   387.613584\n",
      "7       20008   272.291464\n",
      "8       20009   399.209420\n",
      "9       20010   339.556663\n"
     ]
    }
   ],
   "source": [
    "# ğŸ”® Generar predicciones finales para febrero 2020\n",
    "print(\"GENERACIÃ“N DE PREDICCIONES FINALES\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Preparar datos para predicciÃ³n (Ãºltimos datos disponibles de cada producto)\n",
    "# Necesitamos los datos mÃ¡s recientes para predecir 2 perÃ­odos adelante\n",
    "\n",
    "# Obtener Ãºltimo perÃ­odo disponible para cada producto\n",
    "ultimo_periodo = data_combined.groupby('product_id')['fecha'].max().reset_index()\n",
    "ultimo_periodo.columns = ['product_id', 'ultima_fecha']\n",
    "\n",
    "# Unir con datos completos para obtener features mÃ¡s recientes\n",
    "datos_prediccion = pd.merge(data_combined, ultimo_periodo, on='product_id')\n",
    "datos_prediccion = datos_prediccion[datos_prediccion['fecha'] == datos_prediccion['ultima_fecha']].copy()\n",
    "\n",
    "print(f\"ğŸ“Š Productos para predicciÃ³n: {len(datos_prediccion)}\")\n",
    "print(f\"ğŸ“… PerÃ­odo base para predicciÃ³n: {datos_prediccion['periodo'].value_counts().head()}\")\n",
    "\n",
    "# Preparar features para predicciÃ³n\n",
    "X_pred = datos_prediccion[feature_columns].copy()\n",
    "X_pred = X_pred.fillna(0)\n",
    "\n",
    "print(f\"ğŸ” Shape de datos de predicciÃ³n: {X_pred.shape}\")\n",
    "print(f\"ğŸ” Valores nulos en predicciÃ³n: {X_pred.isnull().sum().sum()}\")\n",
    "\n",
    "# Generar predicciones\n",
    "predicciones = model.predict(X_pred, num_iteration=model.best_iteration)\n",
    "\n",
    "print(f\"\\nğŸ”§ CONFIRMACIÃ“N: Predicciones generadas con hiperparÃ¡metros optimizados:\")\n",
    "print(\"=\"*65)\n",
    "print(f\"   lambda_l1:        {lgb_params['lambda_l1']:.4f}\")\n",
    "print(f\"   lambda_l2:        {lgb_params['lambda_l2']:.4f}\")\n",
    "print(f\"   num_leaves:       {lgb_params['num_leaves']}\")\n",
    "print(f\"   feature_fraction: {lgb_params['feature_fraction']:.4f}\")\n",
    "print(f\"   learning_rate:    {lgb_params['learning_rate']:.4f}\")\n",
    "print(f\"   bagging_fraction: {lgb_params['bagging_fraction']:.4f}\")\n",
    "print(f\"   bagging_freq:     {lgb_params['bagging_freq']}\")\n",
    "print(f\"   min_child_samples: {lgb_params['min_child_samples']}\")\n",
    "print(f\"   max_bin:          {lgb_params['max_bin']}\")\n",
    "print(\"=\"*65)\n",
    "\n",
    "# Crear DataFrame de resultados\n",
    "resultado_lgbm = pd.DataFrame({\n",
    "    'product_id': datos_prediccion['product_id'].values,\n",
    "    'tn': predicciones\n",
    "})\n",
    "\n",
    "# Asegurar que no hay predicciones negativas (reemplazar con 0)\n",
    "resultado_lgbm['tn'] = np.maximum(resultado_lgbm['tn'], 0)\n",
    "\n",
    "print(f\"âœ… Predicciones generadas para {len(resultado_lgbm)} productos\")\n",
    "print(f\"\\nğŸ“Š EstadÃ­sticas de predicciones:\")\n",
    "print(f\"  Promedio: {resultado_lgbm['tn'].mean():.2f}\")\n",
    "print(f\"  Mediana:  {resultado_lgbm['tn'].median():.2f}\")\n",
    "print(f\"  MÃ­nimo:   {resultado_lgbm['tn'].min():.2f}\")\n",
    "print(f\"  MÃ¡ximo:   {resultado_lgbm['tn'].max():.2f}\")\n",
    "print(f\"  Std:      {resultado_lgbm['tn'].std():.2f}\")\n",
    "\n",
    "print(f\"\\nPrimeras 10 predicciones:\")\n",
    "print(resultado_lgbm.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a348fa53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GUARDADO DE PREDICCIONES Y RESUMEN - POR PRODUCTO\n",
      "============================================================\n",
      "ğŸ“Š Productos esperados: 780\n",
      "ğŸ“ˆ Productos predichos: 780\n",
      "âœ… Predicciones guardadas en: data/pred_lgbm_v2__revisa_hiperparametrosproducto.csv\n",
      "\n",
      "ğŸ¯ RESUMEN FINAL DEL MODELO LGBM - GRANULARIDAD POR PRODUCTO:\n",
      "ğŸ“Š Total productos predichos: 780\n",
      "ğŸ“ˆ MÃ©tricas de validaciÃ³n:\n",
      "   MAE:  10.4825\n",
      "   RMSE: 32.4590\n",
      "   MAPE: 240.33%\n",
      "ğŸ”§ Features utilizadas: 29\n",
      "ğŸŒ³ NÃºmero de Ã¡rboles: 236\n",
      "ğŸ“… PredicciÃ³n objetivo: 2 perÃ­odos a futuro (Feb 2020)\n",
      "ğŸ­ Granularidad: POR PRODUCTO (agregando clientes)\n",
      "\n",
      "ğŸ“Š ESTADÃSTICAS DE PREDICCIONES POR PRODUCTO:\n",
      "   Promedio por producto: 35.22\n",
      "   Mediana por producto:  7.98\n",
      "   Std por producto:      86.05\n",
      "   Min por producto:      0.32\n",
      "   Max por producto:      1010.16\n",
      "\n",
      "ğŸ“‹ Top 5 features mÃ¡s importantes para granularidad por producto:\n",
      "   tn_rolling_mean_6: 1933250382\n",
      "   total_request_tn: 740488931\n",
      "   tn_rolling_mean_3: 668976734\n",
      "   mes: 59702548\n",
      "   tn_lag_6: 48030756\n",
      "\n",
      "ğŸ”§ RESUMEN DE HIPERPARÃMETROS OPTIMIZADOS:\n",
      "============================================================\n",
      "âœ… Los siguientes 9 hiperparÃ¡metros fueron optimizados con Optuna:\n",
      "   1. lambda_l1:        0.1436\n",
      "   2. lambda_l2:        1.2583\n",
      "   3. num_leaves:       77\n",
      "   4. feature_fraction: 0.8133\n",
      "   5. learning_rate:    0.0335\n",
      "   6. bagging_fraction: 0.8962\n",
      "   7. bagging_freq:     7\n",
      "   8. min_child_samples: 39\n",
      "   9. max_bin:          100\n",
      "============================================================\n",
      "\n",
      "âœ… Modelo LightGBM completado exitosamente con granularidad POR PRODUCTO!\n",
      "Archivo: data/pred_lgbm_v2__revisa_hiperparametrosproducto.csv\n",
      "\n",
      "ğŸ¯ HIPERPARÃMETROS FINALES UTILIZADOS EN LAS PREDICCIONES:\n",
      "=================================================================\n",
      "   lambda_l1:        0.1436\n",
      "   lambda_l2:        1.2583\n",
      "   num_leaves:       77\n",
      "   feature_fraction: 0.8133\n",
      "   learning_rate:    0.0335\n",
      "   bagging_fraction: 0.8962\n",
      "   bagging_freq:     7\n",
      "   min_child_samples: 39\n",
      "   max_bin:          100\n",
      "=================================================================\n",
      "âœ… Predicciones generadas usando estos valores optimizados por Optuna!\n",
      "\n",
      "ğŸ” VerificaciÃ³n archivo guardado:\n",
      "   Filas: 780\n",
      "   Columnas: ['product_id', 'tn']\n",
      "   Primeras 3 filas:\n",
      "   product_id           tn\n",
      "0       20001   888.677174\n",
      "1       20002  1010.155906\n",
      "2       20003   789.907956\n",
      "\n",
      "ğŸ“ˆ Resumen de predicciones por producto:\n",
      "   Total de toneladas predichas: 27474.44\n",
      "   Productos con predicciÃ³n > 0: 780\n",
      "   Productos con predicciÃ³n = 0: 0\n"
     ]
    }
   ],
   "source": [
    "# ğŸ’¾ Guardar predicciones y resumen final - GRANULARIDAD POR PRODUCTO\n",
    "print(\"GUARDADO DE PREDICCIONES Y RESUMEN - POR PRODUCTO\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Verificar que tenemos todos los productos objetivo\n",
    "productos_esperados = set(productos_objetivo)\n",
    "productos_predichos = set(resultado_lgbm['product_id'])\n",
    "\n",
    "print(f\"ğŸ“Š Productos esperados: {len(productos_esperados)}\")\n",
    "print(f\"ğŸ“ˆ Productos predichos: {len(productos_predichos)}\")\n",
    "\n",
    "# Verificar productos faltantes\n",
    "productos_faltantes = productos_esperados - productos_predichos\n",
    "if productos_faltantes:\n",
    "    print(f\"âš ï¸ Productos faltantes: {len(productos_faltantes)}\")\n",
    "    print(f\"Primeros 5 faltantes: {list(productos_faltantes)[:5]}\")\n",
    "    \n",
    "    # Crear predicciones por defecto para productos faltantes\n",
    "    predicciones_default = pd.DataFrame({\n",
    "        'product_id': list(productos_faltantes),\n",
    "        'tn': [resultado_lgbm['tn'].median()] * len(productos_faltantes)\n",
    "    })\n",
    "    \n",
    "    resultado_lgbm = pd.concat([resultado_lgbm, predicciones_default], ignore_index=True)\n",
    "    print(f\"âœ… Agregadas predicciones por defecto para productos faltantes\")\n",
    "\n",
    "# Ordenar por product_id\n",
    "resultado_lgbm = resultado_lgbm.sort_values('product_id').reset_index(drop=True)\n",
    "\n",
    "# Guardar archivo\n",
    "import os\n",
    "os.makedirs('data', exist_ok=True)\n",
    "archivo_salida = 'data/pred_lgbm_v2__revisa_hiperparametrosproducto.csv'\n",
    "resultado_lgbm.to_csv(archivo_salida, index=False)\n",
    "\n",
    "print(f\"âœ… Predicciones guardadas en: {archivo_salida}\")\n",
    "\n",
    "# Resumen final del modelo por producto\n",
    "print(f\"\\nğŸ¯ RESUMEN FINAL DEL MODELO LGBM - GRANULARIDAD POR PRODUCTO:\")\n",
    "print(f\"ğŸ“Š Total productos predichos: {len(resultado_lgbm)}\")\n",
    "print(f\"ğŸ“ˆ MÃ©tricas de validaciÃ³n:\")\n",
    "print(f\"   MAE:  {mae:.4f}\")\n",
    "print(f\"   RMSE: {rmse:.4f}\")\n",
    "print(f\"   MAPE: {mape:.2f}%\")\n",
    "print(f\"ğŸ”§ Features utilizadas: {len(feature_columns)}\")\n",
    "print(f\"ğŸŒ³ NÃºmero de Ã¡rboles: {model.num_trees()}\")\n",
    "print(f\"ğŸ“… PredicciÃ³n objetivo: 2 perÃ­odos a futuro (Feb 2020)\")\n",
    "print(f\"ğŸ­ Granularidad: POR PRODUCTO (agregando clientes)\")\n",
    "\n",
    "# EstadÃ­sticas de predicciones por producto\n",
    "print(f\"\\nğŸ“Š ESTADÃSTICAS DE PREDICCIONES POR PRODUCTO:\")\n",
    "print(f\"   Promedio por producto: {resultado_lgbm['tn'].mean():.2f}\")\n",
    "print(f\"   Mediana por producto:  {resultado_lgbm['tn'].median():.2f}\")\n",
    "print(f\"   Std por producto:      {resultado_lgbm['tn'].std():.2f}\")\n",
    "print(f\"   Min por producto:      {resultado_lgbm['tn'].min():.2f}\")\n",
    "print(f\"   Max por producto:      {resultado_lgbm['tn'].max():.2f}\")\n",
    "\n",
    "print(f\"\\nğŸ“‹ Top 5 features mÃ¡s importantes para granularidad por producto:\")\n",
    "for i, row in importance_df.head(5).iterrows():\n",
    "    print(f\"   {row['feature']}: {row['importance']:.0f}\")\n",
    "\n",
    "print(f\"\\nğŸ”§ RESUMEN DE HIPERPARÃMETROS OPTIMIZADOS:\")\n",
    "print(\"=\"*60)\n",
    "print(f\"âœ… Los siguientes 9 hiperparÃ¡metros fueron optimizados con Optuna:\")\n",
    "print(f\"   1. lambda_l1:        {lgb_params['lambda_l1']:.4f}\")\n",
    "print(f\"   2. lambda_l2:        {lgb_params['lambda_l2']:.4f}\")\n",
    "print(f\"   3. num_leaves:       {lgb_params['num_leaves']}\")\n",
    "print(f\"   4. feature_fraction: {lgb_params['feature_fraction']:.4f}\")\n",
    "print(f\"   5. learning_rate:    {lgb_params['learning_rate']:.4f}\")\n",
    "print(f\"   6. bagging_fraction: {lgb_params['bagging_fraction']:.4f}\")\n",
    "print(f\"   7. bagging_freq:     {lgb_params['bagging_freq']}\")\n",
    "print(f\"   8. min_child_samples: {lgb_params['min_child_samples']}\")\n",
    "print(f\"   9. max_bin:          {lgb_params['max_bin']}\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(f\"\\nâœ… Modelo LightGBM completado exitosamente con granularidad POR PRODUCTO!\")\n",
    "print(f\"Archivo: {archivo_salida}\")\n",
    "\n",
    "# Mostrar resumen final de hiperparÃ¡metros optimizados\n",
    "print(f\"\\nğŸ¯ HIPERPARÃMETROS FINALES UTILIZADOS EN LAS PREDICCIONES:\")\n",
    "print(\"=\"*65)\n",
    "print(f\"   lambda_l1:        {lgb_params['lambda_l1']:.4f}\")\n",
    "print(f\"   lambda_l2:        {lgb_params['lambda_l2']:.4f}\")\n",
    "print(f\"   num_leaves:       {lgb_params['num_leaves']}\")\n",
    "print(f\"   feature_fraction: {lgb_params['feature_fraction']:.4f}\")\n",
    "print(f\"   learning_rate:    {lgb_params['learning_rate']:.4f}\")\n",
    "print(f\"   bagging_fraction: {lgb_params['bagging_fraction']:.4f}\")\n",
    "print(f\"   bagging_freq:     {lgb_params['bagging_freq']}\")\n",
    "print(f\"   min_child_samples: {lgb_params['min_child_samples']}\")\n",
    "print(f\"   max_bin:          {lgb_params['max_bin']}\")\n",
    "print(\"=\"*65)\n",
    "print(f\"âœ… Predicciones generadas usando estos valores optimizados por Optuna!\")\n",
    "\n",
    "# Verificar archivo guardado\n",
    "if os.path.exists(archivo_salida):\n",
    "    verificacion = pd.read_csv(archivo_salida)\n",
    "    print(f\"\\nğŸ” VerificaciÃ³n archivo guardado:\")\n",
    "    print(f\"   Filas: {len(verificacion)}\")\n",
    "    print(f\"   Columnas: {list(verificacion.columns)}\")\n",
    "    print(f\"   Primeras 3 filas:\")\n",
    "    print(verificacion.head(3))\n",
    "    \n",
    "    print(f\"\\nğŸ“ˆ Resumen de predicciones por producto:\")\n",
    "    print(f\"   Total de toneladas predichas: {verificacion['tn'].sum():.2f}\")\n",
    "    print(f\"   Productos con predicciÃ³n > 0: {(verificacion['tn'] > 0).sum()}\")\n",
    "    print(f\"   Productos con predicciÃ³n = 0: {(verificacion['tn'] == 0).sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f60978d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“ˆ Resumen final de optimizaciÃ³n con Optuna\n",
      "RESUMEN FINAL DE OPTIMIZACIÃ“N CON OPTUNA\n",
      "============================================================\n",
      "ğŸ” Detalles de la optimizaciÃ³n:\n",
      "   MÃ©todo de optimizaciÃ³n: TPE (Tree-structured Parzen Estimator)\n",
      "   HiperparÃ¡metros optimizados: 9 parÃ¡metros especÃ­ficos\n",
      "   NÃºmero total de trials: 50\n",
      "   Trials exitosos: 50\n",
      "   Trials podados: 0\n",
      "\n",
      "ğŸ† Mejor configuraciÃ³n encontrada:\n",
      "   MAE en validaciÃ³n: 10.4825\n",
      "   Trial nÃºmero: 31\n",
      "\n",
      "ğŸ¯ VALORES FINALES DE LOS 9 HIPERPARÃMETROS OPTIMIZADOS:\n",
      "=================================================================\n",
      "   1. lambda_l1:        0.1436\n",
      "   2. lambda_l2:        1.2583\n",
      "   3. num_leaves:       77\n",
      "   4. feature_fraction: 0.8133\n",
      "   5. learning_rate:    0.0335\n",
      "   6. bagging_fraction: 0.8962\n",
      "   7. bagging_freq:     7\n",
      "   8. min_child_samples: 39\n",
      "   9. max_bin:          100\n",
      "=================================================================\n",
      "\n",
      "ğŸ”§ Impacto de la optimizaciÃ³n:\n",
      "   MAE optimizado vs base: +0.0000 (+0.00%)\n",
      "\n",
      "ğŸ“ˆ Top 3 trials mÃ¡s exitosos:\n",
      "   1. Trial 31: MAE = 10.4825\n",
      "   2. Trial 44: MAE = 10.4933\n",
      "   3. Trial 46: MAE = 10.5289\n",
      "\n",
      "ğŸ“‹ ParÃ¡metros mÃ¡s impactantes (por varianza):\n",
      "   1. max_bin: varianza = 787.8889\n",
      "   2. num_leaves: varianza = 401.0556\n",
      "   3. min_child_samples: varianza = 31.4097\n",
      "\n",
      "âœ… OptimizaciÃ³n Optuna completada exitosamente!\n",
      "ğŸ“ Predicciones finales guardadas en: data/pred_lgbm_v2__revisa_hiperparametrosproducto.csv\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\nğŸ“ˆ Resumen final de optimizaciÃ³n con Optuna\")\n",
    "print(\"RESUMEN FINAL DE OPTIMIZACIÃ“N CON OPTUNA\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Mostrar informaciÃ³n del estudio de optimizaciÃ³n\n",
    "print(f\"ğŸ” Detalles de la optimizaciÃ³n:\")\n",
    "print(f\"   MÃ©todo de optimizaciÃ³n: TPE (Tree-structured Parzen Estimator)\")\n",
    "print(f\"   HiperparÃ¡metros optimizados: 9 parÃ¡metros especÃ­ficos\")\n",
    "print(f\"   NÃºmero total de trials: {len(study.trials)}\")\n",
    "print(f\"   Trials exitosos: {len([t for t in study.trials if t.state == optuna.trial.TrialState.COMPLETE])}\")\n",
    "print(f\"   Trials podados: {len([t for t in study.trials if t.state == optuna.trial.TrialState.PRUNED])}\")\n",
    "\n",
    "print(f\"\\nğŸ† Mejor configuraciÃ³n encontrada:\")\n",
    "print(f\"   MAE en validaciÃ³n: {study.best_value:.4f}\")\n",
    "print(f\"   Trial nÃºmero: {study.best_trial.number}\")\n",
    "\n",
    "print(f\"\\nğŸ¯ VALORES FINALES DE LOS 9 HIPERPARÃMETROS OPTIMIZADOS:\")\n",
    "print(\"=\"*65)\n",
    "final_params = study.best_params\n",
    "print(f\"   1. lambda_l1:        {final_params['lambda_l1']:.4f}\")\n",
    "print(f\"   2. lambda_l2:        {final_params['lambda_l2']:.4f}\")\n",
    "print(f\"   3. num_leaves:       {final_params['num_leaves']}\")\n",
    "print(f\"   4. feature_fraction: {final_params['feature_fraction']:.4f}\")\n",
    "print(f\"   5. learning_rate:    {final_params['learning_rate']:.4f}\")\n",
    "print(f\"   6. bagging_fraction: {final_params['bagging_fraction']:.4f}\")\n",
    "print(f\"   7. bagging_freq:     {final_params['bagging_freq']}\")\n",
    "print(f\"   8. min_child_samples: {final_params['min_child_samples']}\")\n",
    "print(f\"   9. max_bin:          {final_params['max_bin']}\")\n",
    "print(\"=\"*65)\n",
    "\n",
    "print(f\"\\nğŸ”§ Impacto de la optimizaciÃ³n:\")\n",
    "if 'mae' in locals() and 'study' in locals():\n",
    "    mejora_absoluta = study.best_value - mae  # DeberÃ­a ser negativa si mejorÃ³\n",
    "    mejora_relativa = (mejora_absoluta / study.best_value) * 100\n",
    "    print(f\"   MAE optimizado vs base: {mejora_absoluta:+.4f} ({mejora_relativa:+.2f}%)\")\n",
    "\n",
    "print(f\"\\nğŸ“ˆ Top 3 trials mÃ¡s exitosos:\")\n",
    "sorted_trials = sorted(study.trials, key=lambda t: t.value if t.value is not None else float('inf'))\n",
    "for i, trial in enumerate(sorted_trials[:3]):\n",
    "    if trial.value is not None:\n",
    "        print(f\"   {i+1}. Trial {trial.number}: MAE = {trial.value:.4f}\")\n",
    "\n",
    "print(f\"\\nğŸ“‹ ParÃ¡metros mÃ¡s impactantes (por varianza):\")\n",
    "# Calcular varianza de parÃ¡metros en los mejores trials\n",
    "if len(study.trials) > 5:\n",
    "    top_trials = sorted_trials[:max(5, len(sorted_trials)//4)]\n",
    "    param_values = {}\n",
    "    \n",
    "    for trial in top_trials:\n",
    "        if trial.value is not None:\n",
    "            for param, value in trial.params.items():\n",
    "                if param not in param_values:\n",
    "                    param_values[param] = []\n",
    "                param_values[param].append(value)\n",
    "    \n",
    "    param_variance = {}\n",
    "    for param, values in param_values.items():\n",
    "        if len(values) > 1:\n",
    "            if all(isinstance(v, (int, float)) for v in values):\n",
    "                param_variance[param] = np.var(values)\n",
    "    \n",
    "    # Mostrar top 3 parÃ¡metros con mayor varianza\n",
    "    sorted_params = sorted(param_variance.items(), key=lambda x: x[1], reverse=True)\n",
    "    for i, (param, variance) in enumerate(sorted_params[:3]):\n",
    "        print(f\"   {i+1}. {param}: varianza = {variance:.4f}\")\n",
    "\n",
    "print(f\"\\nâœ… OptimizaciÃ³n Optuna completada exitosamente!\")\n",
    "print(f\"ğŸ“ Predicciones finales guardadas en: data/pred_lgbm_v2__revisa_hiperparametrosproducto.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ldi2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
